{"pages":[{"title":"Categories","date":"2019-06-27T09:26:09.601Z","path":"categories/index.html","text":""},{"title":"Tags","date":"2019-06-27T09:26:09.688Z","path":"tags/index.html","text":""},{"title":"About","date":"2016-10-24T02:24:00.000Z","path":"about/index.html","text":"基本信息姓名：姚应龙（可以叫我小姚或姚工） 性别&amp;年龄：男/1993（身份证1991与实际有出入） 工龄：Java开发，正式工作2年，大学期间公司实习近一年（中移在线一年，冰鉴一年仍在职） 教育背景学历：本科/西华大学/信息工程 时间：2013.09—2017.06 主修：计算机应用基础A、信息论与编码、通信原理、无线通信原理与移动网络、数字通信等。 由于读了一年高四，从二专到二本，艰辛的一年使我成长了很多学到了很多感悟了很多。大学第一年自然而然的当起了学霸，大一上学期后半段，有个很厉害的老师叫卿朝进，上了我们专业的一门叫信息工程概论的课，一节课下来大家新潮澎湃，并且想在我们这批人中找一些人组建实验室。一下在我找到了我的方向，我第一个去找了他，但是由于内向腼腆，说话声音发抖脸红冒汗，最终他没有看上我。最后我连续给他发了几次邮件，最终他收留了我。 大学四年基本是在实验室度过，第一个寒假开始在实验室学习数模电，大一下学期开始做一个小玩意简单的红外感应设备，花了整整一个学期整电路画PCB调试等，暑假老师接了一个四川省农业厅畜禽遗传资源动态监测平台的项目，什么都不懂开始硬上，整整一个暑假的煎熬一点一点的百度，才把整个项目的运行起来，最终把项目完成了，记忆尤新，从此打开了新世界的大门。 大二由于老师的资源，有幸参与了解联通报表的开发，开始接触Oracle，暑假到成都东叶舟科技有限公司实习。 大三由于同学的资源，自己接了两个小的系统开发，中途也参与了老师的一些项目。大三的暑假由于Nokia的公开日，有幸参观且进行模拟面试，最终有幸到Nokia实习了半年，这半年收获巨大，由衷感谢。 大四上半学期在Nokia实习，下半学期基本在找工作，中途有两家比较满意的公司HR给了口头offer，但最终都由于业务变动未能入职，对于一心想留在成都的我最终却没能留下来有点小失落，我知道不如意才使人成长，就当是一次锻炼，便坚定信念出发了。 实习经历大学期间总共参加过两次实习。分别是在Nokia成都六个月和东叶舟科技有限公司两个月。 第一次是大二的暑假2015.07—2015.09为期两个月在成都东叶舟科技有限公司，主要参与了渝富金融微信平台、笑山羊商店系统、新华网微信小游戏三个系统的开发，第一个项目是做后端开发，后两个是做前端开发，也是这次终于前端后端打通了。通过这次实习最大的收获是思维方式从一个学校学生到公司员工的转变，极大的增强了适应能力，当然技术上的收获也很大，后端技术加强了，新学会了前端开发。 第二次实习是大三的暑假2016.07到大四上学期结束2017.01为期六个月在Nokia成都，由于当时Nokia并不招收正式员工，以及找工作的原因并没有续实习。在Nokia就参与了一个内部项目Communication Matrix，刚开始花了一两天学了下Thymeleaf，然后做了大概一个月前端，然后开始做后端开发。这个项目简单的说是一个通用的Excel数据管理系统，当时主要是针对Nokia各个地区用到的网元配置的Excel文件。用的Spring全家桶（Spring Boot、Spring Security、Thymeleaf），这次实习可以说使我得到了一此质的提升，对框架的使用和理解有了巨大提升，最重要一点是Leader的技术很强，从他那学到了很多编程思想上的东西，即使是现在很多时候很多东西我还是在参照学习这个项目。这次实习让我不再畏惧英文文档，掌握了单元测试的思想能够灵活运用IT和UT，在RedHat上做MySQL的增量备份脚本，对Linux和MySQL有了更深入的认识。 工作经历到目前为止呆过两家公司，中移动在线服务有限公司和上海冰鉴信息科技有限公司。 中移动在线服务有限公司是国企中国移动旗下的一个专职子公司工作地点河南郑州，对于一个只想留在成都热衷技术的我，并不是我理想的地方，虽然项目经验相对于应届毕业生来说丰富，技术等各方面能力自认为不差，由于实习错过了很多好机会，以及两次本命年的玩笑，最终去了中移的实名制团队，该部门主要是做实名认证相关的业务，以及一些对外拓展业务。 一开始是进入的智能门禁组，为了熟悉和了解整个公司的技术、业务和环境，安排去维护实名认证企业平台，主要技术是SSM和Dubbo，主要的工作内容是BUG修复和一些功能的优化升级，技术含量不高。之后就是智能门禁项目的开发，主要技术还是SSM和Dubbo，刚开始熟悉项目Leader叫我对人脸识别接口进行压测，学会了JMeter的使用，之后就是一些常规开发。 由于人员调整，被调到集中交付中心小组（中途又有一次人员调整门禁组长想把我要回去，虽然没成功虽然我也想回门禁组)，主要是帮助省公司做线上售卡业务，以及认证激活，第一个功能就是挖异营销模块，相当于集中交付的主业务的一个缩影，就我一个人独立来完成设计和开发，由于需要用到身份证正反验证和视频认证激活，已有的流程中耦合了很多各式各样的业务逻辑，所以不能直接用而且没有注释全是一团乱麻，又将原来的身份证验证和视频认证的代码全部梳理出来了一套可读性较高逻辑简单重复代码少的新流程出来，因此我变成了整个小组最熟悉视频认证流程的两个人之一，像之后的集团购卡认证和新疆视频认证改造的这类比较大型复杂的需求都分到了我这。 在中移动体会到了大厂的系统环境的复杂性，以及各种权限把控的严格性，以及各种上线流程的复杂性。对git的使用以及分支的管理有比较深刻的理解，对Oracle的使用和体会更加深入，以及学会了JIRA的基础使用，学会了工作总结，我的工作技术总结，听说当时走的时候留给他们的总结组长还时长说起，还是比较自豪的。 之所以离开去冰鉴，并不是因为待遇问题，说实话冰鉴给的待遇和中移差不多，甚至严格的讲要差那么一丢丢，离开主要是因为中移是国企对于一个想走技术流的人来说并不理想，大家应该都懂；其二用的技术比较老，仅仅业务的复杂性很高，成长速度达不到我的预期；其三冰鉴是创业公司会很锻炼人，能够使我快熟成长；其四是我的一个师兄在冰鉴。 上海冰鉴信息科技有限公司我是18年4月中旬入职的成都分公司，周五离职中移从郑州回成都用了一天时间租房周一入职冰鉴虽略显匆忙，不管怎么说是我理想的工作地点。进公司做的是企业征信，用的Spring Cloud微服务架构，项目是使用SpringBoot、Mybatis、Redis、Kafka以及Docker等比较新的技术，是我比较理想的技术架构。中途由于系统出了些小故障，排查问题以及解决问题的过程中，通过JMeter对SpringMvc异步实现进行压测通过VisualVm工具对Tomcat参数调整监测，对Tomcat的工作原理有了一些理解和认识，以及对SpringMvc异步处理原理和实现以及异步线程池有了比较深入的理解，对压测工具JMeter使用更加熟练。之后又对分布式锁、Hystrix限流熔断降级做了一段时间的LoadRunner压测通过VisualVm工具观察，对VisualVm工具使用更加熟练，并学会了LoadRunner的使用。对JIRA的使用和理解更加深刻，对微服务架构的理解更加深入，对IT和UT的理解更加深入。而且对于这些内容我都一一做了总结并添加到了我的博客中。 中途人员调整，我被调到了数据平台，由于我个人比较严谨做事细致负责，之前合作时我的IT和UT写的比较好，工作效率比较高bug率比较低，以及个人之前系统之前出了几次故障，个人征信的组长把我要到了个人小组。到个人组主要做个人系统的重构开发，一开始主要负责模型服务的开发，借鉴PMML的思想来实现一套通过XML配置来描述模型的算法，模型服务通过解析XML来实现相关的算法。搭建SonarQube并应用到项目中。 个人简介本科信息工程，自学Java，在校期间参与过比较多的实际项目，自己单独接过外包项目，积极主动，大一暑假开始做实际的项目，大二暑假就在成都东页舟科技有限公司实习参加实习，大三结束到诺基亚西门子通信技术有限公司实习了半年，处理和解决实际问题的能力比较强，善于挑战，毕业设计自拟了一个大数据相关的题目，使用Python做新闻爬虫，MongoDB做数据库，Spark做新闻舆情情感分析，Redis做消息队列，这些技术在做之前都没有接触过。 自学能力强，目前用到的技术都是通过自学的；善于学习，工作之余看完了《图解TCP/IP》、《设计模式之禅》、《架构探险》、《Java高并发程序设计》、《深入理解Java虚拟机》、《Maven实战》等书；自律性比较强，会给自己指定一些学习计划；适应环境的能力强，能够很快的融入一个新环境，善于自我调节；善于总结工作效率高，工作中的一些问题及技术都进行总结，以便提高工作效率，有自己的博客 https://yaoyinglong.github.io 工作积极主动认真负责，考虑问题比较全面；做事严谨；有良好的编程风格，良好的团队协作能力； 技术栈熟悉MySQL、Oracle、MongoDB等数据库，实习以及自己的外包项目都用的MySQL，在Linux上做过MySQL增量备份，在中移用的Oracle，在冰鉴用的MySQL，毕业设计和冰鉴都有用MongoDB； 能够熟练使用Spring Cloud、Spring Boot、Spring MVC、Hystrix、Spring Security、Spring JPA、Hibernate、Thymeleaf、Struts、Mybatis等框架。这些框架在实际的项目中都使用过； 熟悉IT 和UT测试及Mockito测试框架，在Nokia实习时自己完成单元测试和集成测试，有写测试用例的习惯，冰鉴也要求单元测试且我是做的比较好的。 熟练掌握Vue、HTML、JSP、JQuery、JavaScript、CSS等前端技术，很多项目中都是自己独立完成前端代码的实现，冰鉴用的Vue由于前端人员不足偶尔也帮忙写一点前端功能。 Tomcat熟悉基础原理、并总结有相关博客。 能熟练使用SVN和Git版本控制工具，实习时使用的SVN，冰鉴和中移都使用的Git，并总结有相关博客。 熟悉多线程，对Spring中自定义线程池、Spring MVC异步线程池、Tomcat线程池都有相关的使用和压测调参，并有相关的总结博客。 了解Redis，在毕业设计中使用Redis做过消息队列，冰鉴和中移都有使用redis。 能熟练使用Intellij开发工具，熟悉掌握其使用技巧和绝大部分快捷键，常用快捷键和插件都有总结成博客。 熟悉基本的Linux操作命令，现在工作中使用Linux也比较频繁，比较多的用于查日志和监控。 熟悉Python能够独立完成简单爬虫，以及一些常用的工具，毕业设计《舆情分析》使用Python做的爬虫爬取网易新闻，在冰鉴也使用Python开发一些常用小工具。 熟悉Java虚拟机，刚在自己的博客中总结完了自动内存管理，以及部分Class文件结构，对JVM的内存垃圾收集和Class文件结构有较深入的了解，熟悉VisualVM在实际项目中使用该工具对压测进行JVM和MBean监控，以及远程主机调试等。 能熟练使用Maven构建项目、并对Maven的常用插件和日常使用有相关博客总结。 熟悉JMeter、LoadRunner等压测工具，并时常在实际项目中使用。 熟悉XML，在实际的项目中使用过自定义XSD，来完成特定的功能。 熟悉JIRA的使用，熟悉SonarQube，为公司搭建SonarQube并应用到实际的项目中。 熟悉微信公众平台的开发、熟悉了解Docker。 熟悉基本的数据结构和算法，自学过《大话数据结构》，研究过8大基本的排序算法"}],"posts":[{"title":"设计模式概览","date":"2020-08-24T16:00:00.000Z","path":"Blog/设计模式/设计模式概览/","text":"设计模式分类23种设计模式大体上可以分为三类： 创建型模式（5个）：对象实例化的模式，用于解耦对象的实例化过程； 结构型模式（7个）：把类或对象结合在一起形成一个更大的结构； 行为型模式（11个）：类和对象如何交互，及划分职责和算法； 各种模式的关键点创建型模式单例模式：某个类只能有一个实例，提供一个全局的访问点。 简单工厂：一个工厂类根据传入的参量决定创建出那一种产品类的实例。 工厂方法：定义一个创建对象的接口，让子类决定实例化那个类。 抽象工厂：创建相关或依赖对象的家族，而无需明确指定具体类。 建造者模式：封装一个复杂对象的构建过程，并可以按步骤构造。 原型模式：通过复制现有的实例来创建新的实例。 结构型模式适配器模式：将一个类的方法接口转换成客户希望的另外一个接口。 组合模式：将对象组合成树形结构以表示“”部分-整体“”的层次结构。 装饰模式：动态的给对象添加新的功能。 代理模式：为其他对象提供一个代理以便控制这个对象的访问。 亨元模式：通过共享技术来有效的支持大量细粒度的对象。 外观模式：对外提供一个统一的方法，来访问子系统中的一群接口。 桥接模式：将抽象部分和它的实现部分分离，使它们都可以独立的变化。 行为型模式模板模式：定义一个算法结构，而将一些步骤延迟到子类实现。 解释器模式：给定一个语言，定义它的文法的一种表示，并定义一个解释器。 策略模式：定义一系列算法，把他们封装起来，并且使它们可以相互替换。 状态模式：允许一个对象在其对象内部状态改变时改变它的行为。 观察者模式：对象间的一对多的依赖关系。 备忘录模式：在不破坏封装的前提下，保持对象的内部状态。 中介者模式：用一个中介对象来封装一系列的对象交互。 命令模式：将命令请求封装为一个对象，使得可以用不同的请求来进行参数化。 访问者模式：在不改变数据结构的前提下，增加作用于一组对象元素的新功能。 责任链模式：将请求的发送者和接收者解耦，使的多个对象都有处理这个请求的机会。 迭代器模式：一种遍历访问聚合对象中各个元素的方法，不暴露该对象的内部结构。 23种设计模式间的关系","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/tags/设计模式/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/"}]},{"title":"MySQL基础","date":"2020-08-24T16:00:00.000Z","path":"Blog/DB/MySQL基础/","text":"事务基本特征ACID四种隔离级别数据库三范式","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yaoyinglong.github.io/tags/MySQL/"}],"categories":[{"name":"DB","slug":"DB","permalink":"https://yaoyinglong.github.io/categories/DB/"}]},{"title":"JVM整体概览","date":"2020-08-24T16:00:00.000Z","path":"Blog/Java/JVM整体概览/","text":"","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"}]},{"title":"Spring知识点","date":"2020-08-23T16:00:00.000Z","path":"Blog/框架/Spring/Spring知识点/","text":"","tags":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/tags/Spring/"}],"categories":[{"name":"框架","slug":"框架","permalink":"https://yaoyinglong.github.io/categories/框架/"},{"name":"Spring","slug":"框架/Spring","permalink":"https://yaoyinglong.github.io/categories/框架/Spring/"}]},{"title":"IoC容器","date":"2020-08-15T16:00:00.000Z","path":"Blog/框架/Spring/IoC容器/","text":"IoC容器概述依赖反转的概念：依赖对象的获得被反转了，基于该结论为控制反转创造了一个更好听的名字：依赖注入。依赖控制反转的实现方式有很多种，Spring中IoC容器是实现该模式的载体，它可以在对象生成或初始化时直接将数据注入到对象中，也可以通过将对象引用注入到对象数据域中的方式来注入对方法调用的依赖。这种依赖注入是可以递归的，对象被逐层注入。 应用控制反转后，当对象被创建时，由一个调用系统内的所有对象的外界实体将其所依赖的对象的引用传递给它，控制反转是关于一个对象如何获取它所依赖的对象的引用，反转指的是责任的反转。 通过使用IoC容器，对象的依赖关系的管理被反转了或者说是把资源的获取方式反转了，对象之间的相互依赖关系由IoC容器进行管理，并由IoC容器完成对象的注入。注入的主要实现方式有：接口注入、setter注入、构造器注入。Spring中setter注入和构造器注入是主要的注入方式，使用Spring时setter注入是常见的注入方式。且Spring还提供了对特定依赖的检查。 Spring IoC提供了一个基本的JavaBean容器，通过IoC容器管理依赖关系，并通过依赖注入和AOP切面增强了为JavaBean这样的POJO对象赋予事务管理、生命周期管理等基本功能。 IoC容器的设计与实现Spring IoC容器的设计中，实现了BeanFactory接口的简单容器系列，该系列容器只实现了容器的最基本的功能；和容器的高级形态ApplicationContext应用上下文，两个主要的容器系列。BeanFactory是IoC容器具体实现的基本功能规范的设计表现。 对于使用者来说，可将BeanFactory和ApplicationContext看成容器的具体表现形式。通常所说的IoC容器实际上代表的是一系列功能各异的容器产品。Spring中有各种各样的IoC容器的实现。 在Spring提供的基本的IoC容器的接口定义和实现的基础上，Spring通过定义BeanDefinition来管理基本的Spring的应用中的各种对象以及它们之间的相互依赖关系。BeanDefinition抽象了对Bean的定义，是让容器起作用的主要数据类型。对于IoC容器来说，BeanDefinition就是对依赖反转模式中管理的对象依赖关系的数据抽象，也是容器实现依赖反转功能的核心数据结构，依赖反转功能都是围绕对BeanDefinition的处理来完成的。 BeanFactory接口定义了基本的IoC容器规范，从接口BeanFactory到HierarchicalBeanFactory再到ConfigurableBeanFactory是一条主要的BeanFactory设计路径。HierarchicalBeanFactory接口增加了getParentBeanFactory()的接口功能，使BeanFactory具备了双亲IoC容器的管理功能。ConfigurableBeanFactory接口主要定义了一些对BeanFactory的配置功能。可设置双亲IoC容器，配置Bean后置处理器等。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/tags/Spring/"},{"name":"IoC","slug":"IoC","permalink":"https://yaoyinglong.github.io/tags/IoC/"}],"categories":[{"name":"框架","slug":"框架","permalink":"https://yaoyinglong.github.io/categories/框架/"},{"name":"Spring","slug":"框架/Spring","permalink":"https://yaoyinglong.github.io/categories/框架/Spring/"}]},{"title":"Spring整体架构","date":"2020-08-11T16:00:00.000Z","path":"Blog/框架/Spring/Spring整体架构/","text":"Spring子项目Spring Framework（core）包含一系列Ioc容器的设计，提供了依赖反转的实现，集成了AOP，还包含了MVC、JDBC、事务处理模块的实现。 Spring Web Flow定义了一种特定的语言来描述工作流，同时高级的工作流控制引擎可以管理会话状态，支持AJAX来构建丰富的客户端体验，并提供JSF支持。其实际上是构建在Spring MVC的基础上的，相对于Spring Framework（core）独立发展的。 Spring BlazeDS Integration提供Spring于Adobe Flex技术集成的模块。 Spring Security基于Spring的认证和安全工具。 Spring Security OAuth为OAuth在Spring上集成提供支持，OAuth是一个第三方模块，提供一个开放协议的实现，通过改协议，前端桌面应用可以对Web应用进行简单而标准的安全调用。 Spring Dynamic Modules可以让Spring运行在OSGi平台上。 Spring Batch提供构建批处理应用和自动化操作的框架。 Spring Integration为企业数据集成提供了各种适配器，通过这些适配器来转换各种消息格式，并帮助Spring应用完成与企业应用系统的集成。 Spring AMQP为Spring应用更好地使用基于AMQP（高级消息队列协议）的消息服务而开发。 Spring Data为Spring应用提供使用费关系型数据的能力。 Spring设计目标​ 为开发者提供的是一个一站式的轻量级应用开发框架。其抽象了许多应用开发中遇到的共性问题。支持POJO和使用JavaBean的开发方式，使应用面向接口开发，充分支持OO（面向对象）的设计方法，使开发的入门、测试、应用部署都得到简化。 ​ 通过使用Spring的IoC容器，可以对应用开发中复杂的对象耦合关系实现一个文本化、外部化的工作，即通过一个或几个XML文件，可以方便地对应用的耦合关系进行浏览、修改和维护，很大程度上简化应用开发。通过Ioc容器实现的依赖反转，把依赖关系的管理从Java对象中解放出来，交给IoC容器来完成，从而完成了对象之间的解耦，将原来的对象—对象的关系，转化为对象—IoC容器—对象的关系。 ​ Spring即作为用户和机器之间的平台，同时也为用户使用底层的机器资源提供了应用开发环境。Spring关系的是一些企业应用资源的使用，如数据持久化、数据集成、事务管理、消息中间件、Web2.0应用、分布式计算等对高效可靠处理企业数据方法的技术抽象。 ​ Spring一方面通过IoC容器来管理POJO对象，以及它们相互之间的耦合关系，使企业的信息、数据、资源可以用简单得Java语言来抽象和描述；另一方面可通过AOP以动态和非侵入式的方式来增强服务的功能。 ​ IoC容器和AOP模块是平台实现的核心，代表了最为基础的底层抽象，同时也是Spring其他模块实现的基础。 Spring整体架构Spring IoC​ 包含了最基本的IoC容器BeanFactory接口的实现，也提供了一系列这个接口的实现。如：XmlBeanFactory、SimpleJndiBeanFactory、StaticListableBeanFactory等，为了让应用更方便得使用IoC容器，还在IoC容器的外围提供如Resource访问资源的抽象和定位等支持。Spring还设计了IoC容器的高级形态ApplicationContext应用上下文提供用户使用。 Spring AOP​ Spring核心模块，围绕AOP增强功能，Spring集成了AspectJ作为AOP的一个特定实现，还在JVM动态代理/CGLIB的基础上实现了一个AOP框架。 Spring MVC​ 以DispatcherServlet为核心的模块，实现了MVC模式，包括怎样与Web容器环境集成、Web请求的拦截、分发、处理、和ModelAndView数据的返回，以及如何集成各种UI视图展现和数据表现。 Spring JDBC/ORM​ Spring JDBC包提供了JdbcTemplate作为模板类，封装了基本的数据库操作方法，如数据查询、更新等。 ​ Spring还提供许多对ORM工具的封装。如Hibernate、iBatis等。可以把对这些工具的使用和Spring声明式事务处理结合起来。同时Spring还提供许多模板对象，如HibernateTemplate来实现对Hibernate的驱动。 Spring事务处理​ Spring事务处理是一个通过Spring AOP实现的自身功能增强的典型模块。通过AOP增强实现了声明式事务处理的功能，使应用只需要在IoC容器中对事务属性进行配置即可完成，同时这些事务处理的基本过程和具体的事务处理器实现是无关的，应用可以选择不同的具体的事务处理机制，使用了声明式事务处理，这些具体的事务处理机制会被纳入Spring事务处理的统一框架中完成，并完成与具体业务代码的解耦。 Spring远端调用​ 通过Spring的封装，为应用屏蔽了各种通信和调用细节的实现，通过这一层的封装，使应用可以通过选择各种不同的远端调用来实现。如HTTP调用器、第三方二进制同学实现Hessian/Burlap、RMI调用。 Spring应用场景​ 在Spring这个一站式应用平台或框架中，其中各个模块除了依赖IoC容器和AOP之外，相互之间没有很强的耦合性；Spring最重目标是简化应用开发的编程模型。其所提供的服务可贯穿应用道整个软件中，从最上层Web UI道底层数据操作，道其他企业信息数据集成，再到各种J2EE服务的使用。 ​ 可把Spring作为一个整体使用，也可以把Spring各个模块拿出来单独使用，因其本身是非常模块化的。Spring的价值： 非侵入性框架，其目标是使应用程序代码对框架的依赖最小化。 提供了一个一致的编程模型，使应用直接使用POJO开发，从而可以与运行环境隔离开。 推动应用的设计风格向面向对象及面向接口编程转变，提高代码的重用性和可测性。 改进了体系结构的选择，Spring可以帮助我们选择不同的技术实现。","tags":[{"name":"Spring","slug":"Spring","permalink":"https://yaoyinglong.github.io/tags/Spring/"}],"categories":[{"name":"框架","slug":"框架","permalink":"https://yaoyinglong.github.io/categories/框架/"},{"name":"Spring","slug":"框架/Spring","permalink":"https://yaoyinglong.github.io/categories/框架/Spring/"}]},{"title":"时间&空间复杂","date":"2020-07-31T16:00:00.000Z","path":"Blog/算法/时间&空间复杂/","text":"时间复杂度常见的时间复杂度：O(1)：常数复杂度，O(log n)：对数复杂度，O(n)：线性时间复杂度，O(n^2)：平方，O(n^3)：立方，O(2^n)：指数，O(n!)：阶乘。 O(log n)12for (int i = 0; i &lt; n; i++) &#123;&#125; O(n^2)1234for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; &#125;&#125; O(log n)12for (int i = 0; i &lt; n; i *= 2) &#123;&#125; O(k^n)123456private int Fibonacci(int n) throws Exception &#123; if(n &lt; 2)&#123; return n; &#125; return Fibonacci(n-1) + Fibonacci(n -2);&#125; O(n!)1234for (int i = 0; i &lt; n; i++) &#123; for (int j = i + 1; j &lt; n; j++) &#123; &#125;&#125; 空间复杂度","tags":[{"name":"算法","slug":"算法","permalink":"https://yaoyinglong.github.io/tags/算法/"}],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"二叉搜索树","date":"2020-07-27T16:00:00.000Z","path":"Blog/算法/二叉搜索树/","text":"左子树上所有节点的值均小于根节点的值，而右子树上所有结点的值均大于根节点的值。故二叉搜索树中序遍历是单调递增的。 插入的序列越接近有序，生成的二叉搜索树就越像一个链表，为了避免二叉搜索树变成链表，故引入了平衡二叉树，即让树的结构看起来尽量均匀，左右子树的节点数尽量一样多。 生成平衡二叉树时，先按照生成二叉搜索树的方法构造二叉树，再根据插入的导致二叉树不平衡的节点位置进行调整，有LL左旋、RR右旋、LR先左旋后右旋、RL先右旋后左旋四种调整方式。 验证二叉搜索树1234567891011121314151617181920212223242526272829303132333435public Integer min;public boolean isValidBST(TreeNode root) &#123; if (root == null) &#123; return true; &#125; boolean left = isValidBST(root.left); if (!left || min != null &amp;&amp; root.val &lt;= min) &#123; return false; &#125; min = root.val; return isValidBST(root.right);&#125;public boolean isValidBSTDfs(TreeNode root) &#123; if (root == null) &#123; return true; &#125; Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); TreeNode node = root; Integer min = null; while (node != null || !stack.isEmpty()) &#123; while (node != null) &#123; stack.add(node); node = node.left; &#125; node = stack.pop(); if (min != null &amp;&amp; node.val &lt;= min) &#123; return false; &#125; min = node.val; node = node.right; &#125; return true;&#125; 二叉搜索树插入1234567891011public TreeNode insertIntoBST(TreeNode root, int val) &#123; if (root == null) &#123; return new TreeNode(val); &#125; if (val &gt; root.val) &#123; root.right = insertIntoBST701(root.right, val); &#125; else &#123; root.left = insertIntoBST701(root.left, val); &#125; return root;&#125; 删除节点 若key &gt; root.val，说明要删除的节点在右子树，root.right = deleteNode(root.right, key)。 若key &lt; root.val，说明要删除的节点在左子树，root.left = deleteNode(root.left, key)。 若key == root.val，则该节点就是我们要删除的节点，则： 若该节点是叶子节点，直接删除：root = null。 若该节点不是叶子节点且有右节点，则用其后继节点值替代root.val = successor.val，然后删除后继节点。 若该节点不是叶子节点且只有左节点，则用它的前驱节点值替代root.val = predecessor.val，然后删除前驱节点。 123456789101112131415161718192021public TreeNode deleteNode(TreeNode root, int key) &#123; if (root == null) &#123; return null; &#125; if (key &gt; root.val) &#123; root.right = deleteNode(root.right, key); &#125; else if (key &lt; root.val) &#123; root.left = deleteNode(root.left, key); &#125; else &#123; if (root.left == null &amp;&amp; root.right == null) &#123; root = null; &#125; else if (root.right != null) &#123; root.val = successor(root); root.right = deleteNode(root.right, root.val); &#125; else &#123; root.val = predecessor(root); root.left = deleteNode(root.left, root.val); &#125; &#125; return root;&#125; 后继节点，中序遍历序列的下一个节点。即比当前节点大的最小节点，先取当前节点的右节点，然后一直取该节点的左节点，直到左节点为空，则最后指向的节点为后继节点。 1234567public int successor(TreeNode root) &#123; root = root.right; while (root.left != null) &#123; root = root.left; &#125; return root.val;&#125; 前驱节点，中序遍历序列的前一个节点。即比当前节点小的最大节点，先取当前节点的左节点，然后取该节点的右节点，直到右节点为空，则最后指向的节点为前驱节点。 1234567public int predecessor(TreeNode root) &#123; root = root.left; while (root.right != null) &#123; root = root.right; &#125; return root.val;&#125; 将树转换成链表cursor只是做一个引用传递，不断的将节点的right节点更新，然后将当前游标置为新节点。 123456789101112131415161718TreeNode cursor;public TreeNode increasingBST(TreeNode root) &#123; TreeNode ans = new TreeNode(0); cursor = ans; inorder(root); return ans.right;&#125;public void inorder(TreeNode node) &#123; if (node == null) &#123; return; &#125; inorder(node.left); node.left = null; cursor.right = node; cursor = node; inorder(node.right);&#125; 二叉搜索树降序遍历12345678public void convertBST(TreeNode root) &#123; if (root == null) &#123; return; &#125; convertBST(root.right); System.out.println(root); convertBST(root.left);&#125; 最近公共祖先1234567891011121314151617181920212223242526272829303132public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) &#123; if (root.val &lt; p.val &amp;&amp; root.val &lt; q.val) &#123; return lowestCommonAncestor(root.right, p, q); &#125; if (root.val &gt; p.val &amp;&amp; root.val &gt; q.val) &#123; return lowestCommonAncestor(root.left, p, q); &#125; return root;&#125;public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) &#123; // 保证 p.val &lt; q.val if (p.val &gt; q.val) &#123; TreeNode tmp = p; p = q; q = tmp; &#125; while (root != null) &#123; // p,q 都在 root 的右子树中 if (root.val &lt; p.val) &#123; // 遍历至右子节点 root = root.right; // p,q 都在 root 的左子树中 &#125; else if (root.val &gt; q.val) &#123; // 遍历至左子节点 root = root.left; &#125; else &#123; break; &#125; &#125; return root;&#125; 修剪二叉搜索树1234567891011121314public TreeNode trimBST(TreeNode root, int L, int R) &#123; if (root == null) &#123; return null; &#125; if (root.val &gt; R) &#123; return trimBST(root.left, L, R); &#125; if (root.val &lt; L) &#123; return trimBST(root.right, L, R); &#125; root.left = trimBST(root.left, L, R); root.right = trimBST(root.right, L, R); return root;&#125; 前序结果构建树12345678910111213141516171819202122public int index = 0;public TreeNode bstFromPreorder(int[] preorder) &#123; if (preorder == null || preorder.length == 0) &#123; return null; &#125; return generateTree(preorder, Integer.MIN_VALUE, Integer.MAX_VALUE);&#125;public TreeNode generateTree(int[] preorder, int lower, int upper) &#123; if (index == preorder.length) &#123; return null; &#125; int rootVal = preorder[index]; if (rootVal &gt; upper || rootVal &lt; lower) &#123; return null; &#125; index++; TreeNode root = new TreeNode(rootVal); root.left = generateTree(preorder, lower, rootVal); root.right = generateTree(preorder, rootVal, upper); return root;&#125; 后序结果构建树12345678910111213141516171819202122public int index = 0;public TreeNode bstFromPostorder(int[] postorder) &#123; if (postorder == null || postorder.length == 0) &#123; return null; &#125; return generateTree(postorder, Integer.MIN_VALUE, Integer.MAX_VALUE);&#125;public TreeNode generateTree(int[] postorder, int lower, int upper) &#123; if (index == postorder.length) &#123; return null; &#125; int rootVal = postorder[index]; if (rootVal &gt; upper || rootVal &lt; lower) &#123; return null; &#125; index++; TreeNode root = new TreeNode(rootVal); root.right = generateTree(postorder, rootVal, upper); root.left = generateTree(postorder, lower, rootVal); return root;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"https://yaoyinglong.github.io/tags/算法/"},{"name":"树","slug":"树","permalink":"https://yaoyinglong.github.io/tags/树/"},{"name":"AVL","slug":"AVL","permalink":"https://yaoyinglong.github.io/tags/AVL/"}],"categories":[{"name":"算法","slug":"算法","permalink":"https://yaoyinglong.github.io/categories/算法/"}]},{"title":"平衡二叉树","date":"2020-07-27T16:00:00.000Z","path":"Blog/算法/平衡二叉树/","text":"平衡二叉树是一种特殊的二叉排序树，每个节点左子树和右子树高度差至多等于1。 将二叉树上节点左子树深度减去右子树深度的值称为平衡因子BF，平衡二叉树上所有节点的平衡因子只可能是1，-1，0。 距离插入节点最近且平衡因子绝对值大于1的节点为根的子树，称为最小不平衡子树。 构建平衡二叉树时，每插入一个节点时，先检查是否因插入而破坏树的平衡性，若是则找出最小不平衡树，在保持二叉排序树特性的前提下，调整最小不平衡子树中各个节点之间的链接关系，进行相应的旋转，使之成为新的平衡子树。 右旋：最小不平衡子树的BF和它的子树BF符号相同且最小不平衡子树的BF大于0 左旋：最小不平衡子树的BF和它的子树BF符号相同且最小不平衡子树的BF小于零 左右旋：最小不平衡子树的BF与它的子树的BF符号相反时且最小不平衡子树的BF大于0时，需要对节点先进行一次向左旋使得符号相同后，在向右旋转一次完成平衡操作。 右左旋：最小不平衡子树的BF与它的子树的BF符号相反时且最小不平衡子树的BF小于0时，需要对节点先进行一次向右旋转使得符号相同时，在向左旋转一次完成平衡操作。 左旋LL 123456public TreeNode leftLeftRotation(TreeNode root) &#123; TreeNode left = root.left; root.left = left.right; left.right = root; return left;&#125; 右旋RR 123456public TreeNode rightRightRotation(TreeNode root) &#123; TreeNode right = root.right; root.right = right.left; right.left = root; return right;&#125; 左右旋LR 1234public TreeNode leftRightRotation(TreeNode root) &#123; root.left = rightRightRotation(root.left); return leftLeftRotation(root);&#125; 右左旋RL 1234public TreeNode rightLeftRotation(TreeNode root) &#123; root.right = leftLeftRotation(root.right); return rightRightRotation(root);&#125; 插入节点123456789101112131415161718192021222324252627282930public TreeNode insertAvl(TreeNode root, int val) &#123; if (root == null) &#123; return new TreeNode(val); &#125; if (val == root.val) &#123; throw new RuntimeException(\"不允许添加相同的节点\"); &#125; if (val &lt; root.val) &#123; root.left = insertAvl(root.left, val); // 插入节点后，若AVL树失去平衡，则进行相应的调节 if (maxDepth(root.left) - maxDepth(root.right) == 2) &#123; if (val &lt; root.left.val) &#123; return leftLeftRotation(root); &#125; else &#123; return leftRightRotation(root); &#125; &#125; &#125; else &#123; root.right = insertAvl(root.right, val); // 插入节点后，若AVL树失去平衡，则进行相应的调节 if (maxDepth(root.right) - maxDepth(root.left) == 2) &#123; if (val &gt; root.right.val) &#123; return rightRightRotation(root); &#125; else &#123; return rightLeftRotation(root); &#125; &#125; &#125; return root;&#125; 删除节点1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public TreeNode remove(TreeNode root, int val) &#123; if (root == null) &#123; return null; &#125; if (val &lt; root.val) &#123; root.left = remove(root.left, val); if (maxDepth(root.right) - maxDepth(root.left) == 2) &#123; if (maxDepth(root.right.left) &gt; maxDepth(root.right.right)) &#123; return rightLeftRotation(root); &#125; else &#123; return rightRightRotation(root); &#125; &#125; &#125; else if (val &gt; root.val) &#123; root.right = remove(root.right, val); if (maxDepth(root.left) - maxDepth(root.right) == 2) &#123; if (maxDepth(root.left.right) &gt; maxDepth(root.left.left)) &#123; return leftRightRotation(root); &#125; else &#123; return leftLeftRotation(root); &#125; &#125; &#125; else &#123; if (root.left != null &amp;&amp; root.right != null) &#123; if (maxDepth(root.left) &gt; maxDepth(root.right)) &#123; int maxVal = findMax(root.left); root.val = maxVal; root.left = remove(root.left, maxVal); &#125; else &#123; int minVal = findMin(root.right); root.val = minVal; root.right = remove(root.right, minVal); &#125; &#125; else &#123; return root.left != null ? root.left : root.right; &#125; &#125; return root;&#125;public int findMax(TreeNode root) &#123; if (root.left == null || root.right == null) &#123; return root.val; &#125; return findMax(root.right);&#125;public int findMin(TreeNode root) &#123; if (root.right == null || root.left == null) &#123; return root.val; &#125; return findMin(root.left);&#125; 有序数组转换成AVL123456789101112131415161718192021222324252627282930313233343536373839public TreeNode sortedArrayToBST(int[] nums) &#123; return toBstTraversalLeft(nums, 0, nums.length - 1);&#125;// 总是选择中间位置左边的数字作为根节点public TreeNode toBstTraversalLeft(int[] nums, int left, int right) &#123; if (left &gt; right) &#123; return null; &#125; int mid = (left + right) / 2; TreeNode root = new TreeNode(nums[mid]); root.left = toBstTraversalLeft(nums, left, mid - 1); root.right = toBstTraversalLeft(nums, mid + 1, right); return root;&#125;// 总是选择中间位置右边的数字作为根节点public TreeNode toBstTraversalRight(int[] nums, int left, int right) &#123; if (left &gt; right) &#123; return null; &#125; int mid = (left + right + 1) / 2; TreeNode root = new TreeNode(nums[mid]); root.left = toBstTraversalRight(nums, left, mid - 1); root.right = toBstTraversalRight(nums, mid + 1, right); return root;&#125;// 选择任意一个中间位置数字作为根节点public TreeNode toBstTraversalRandom(int[] nums, int left, int right) &#123; if (left &gt; right) &#123; return null; &#125; int mid = (left + right + new Random().nextInt(2)) / 2; TreeNode root = new TreeNode(nums[mid]); root.left = toBstTraversalRandom(nums, left, mid - 1); root.right = toBstTraversalRandom(nums, mid + 1, right); return root;&#125; 平衡二叉树判定对二叉树做后序遍历，从底至顶返回子树深度，若判定某子树不是平衡树则 直接向上返回： 123456789101112131415161718public boolean isBalanced(TreeNode treeNode) &#123; return recur(treeNode) != -1;&#125;public int recur(TreeNode treeNode) &#123; if (treeNode == null) &#123; return 0; &#125; int leftDepth = recur(treeNode.leftNode); if (leftDepth == -1) &#123; return -1; &#125; int rightDepth = recur(treeNode.rightNode); if (rightDepth == -1) &#123; return -1; &#125; return Math.abs(leftDepth - rightDepth) &lt; 2 ? Math.max(leftDepth, rightDepth) + 1 : -1;&#125; B树B树属于多叉树又名平衡多路查找树，数据库索引技术里大量使用者B树和B+树的数据结构。 红黑树红黑树是一种含有红黑结点并能自平衡的二叉查找树。主要用于存储有序数据，时间复杂度为O(lgn)。一棵含有n个节点的红黑树的高度至多为2log(n+1) 每个节点要么是黑色，要么是红色 根节点是黑色 每个空叶子节点是黑色 每个红色结点的两个子结点一定都是黑色 任意一结点到每个叶子结点的路径都包含数量相同的黑结点","tags":[{"name":"算法","slug":"算法","permalink":"https://yaoyinglong.github.io/tags/算法/"},{"name":"树","slug":"树","permalink":"https://yaoyinglong.github.io/tags/树/"},{"name":"AVL","slug":"AVL","permalink":"https://yaoyinglong.github.io/tags/AVL/"}],"categories":[{"name":"算法","slug":"算法","permalink":"https://yaoyinglong.github.io/categories/算法/"}]},{"title":"面试准备大纲","date":"2020-07-25T16:00:00.000Z","path":"Blog/Interview/大纲/","text":"Spring AOP IOC 源码 SpringBoot SpringCloud 数据库 常见面试笔试内容 算法 树（前序遍历、中序遍历、后序遍历、层序遍历） 二叉搜索树 平衡二叉树（AVL树） 红黑树 图（广度优先遍历BFS、深度优先遍历DFS） leetcode题（前期每周5道，中期每周10道，后期每周15道） 常见排序总结 复杂度分析：了解常见时间复杂度，建立复杂度和数据规模之间的概念，理解均摊复杂度分析 数组 双索引技术 对撞指针—浮动窗口 查找表 map set unordered_map unordered_set 链表 虚拟头结点 双指针 栈 非递归算法 深入系统栈，模拟系统递归调用 队列 广度优先遍历 回溯 回溯算法 排序问题-组合问题 Floodfill 动态规划 记忆化搜索 重叠子问题和问题的无后效性 背包问题 LIS，LCS问题分析 贪心算法：避过陷阱 设计模式 6大基本原则（一周） 23种设计模式（一周5个） 设计模式对比 Java基础 JVM 源码 多线程 消息队列 RabbitMQ 常见面试笔试内容 Reids 常见面试笔试内容 Linux 常用命令 Go 常见面试笔试内容 Maven 常见面试笔试内容 单元测试","tags":[],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"SOLID基本原则","date":"2020-07-25T16:00:00.000Z","path":"Blog/设计模式/SOLID基本原则/","text":"6大设计基本原则：单一职责原则、里氏替换原则、依赖倒置原则、接口隔离原则、迪米特法则、开闭原则 单一职责原则SRP​ 单一职责原则提出了一个编写程序的标准，用职责或变化原因来衡量接口或类设计得是否优良，但职责和变化原因都是不可度量得，因项目和环境而异。单一职责适用于接口、类、方法。 定义：应该有且仅有一个原因引起类的变更。 优点：类复杂性降低，实现职责清晰明确；可读性高；可维护性高；变更引起的风险低； 里氏替换原则LSP定义：每一个类型为S的对象s，都有类型为T的对象t，使得以T定义的所有程序P在所有的对象s都代替成t时，程序P的行为无变化，则类型S是类型T的子类；所有引用基类的地方必须能透明的使用其子类的对象。 子类必须完全实现父类的方法：若子类不能完全实现父类方法，或某些方法在子类种已发生畸变，建议断开父子继承关系。 子类可以有自己的个性：子类出现的地方父类未必能出现 覆盖或实现父类方法时输入参数可以被放大 覆写或实现父类的方法时输出结果可以被缩小 在类中调用其他类时务必使用父类或接口，否则即是违背LSP原则。 依赖倒置原则DIP​ 采用依赖倒置原则可以减少类间的耦合性，提高系统的稳定性，降低并行开发引起的风险，提高代码的可读性和可维护性。可以通过依赖倒置原则涉及的接口或抽象类对实现类进行约束，可减少需求变化引起的工作量剧增的情况，可让维护人员轻松地扩展和维护，是实现开闭原则的重要途径。TDD测试驱动开发模式就是依赖倒置原则的最高级应用。 定义：高层模块不应该依赖底层模块两者都应该依赖其抽象；抽象不应该依赖细节；细节应该依赖抽象； 表现：模块间依赖通过抽象发生，实现类之间不发生直接的依赖关系，其依赖关系是通过接口或抽象类产生；接口和抽象类不依赖于实现类；实现类依赖接口或抽象类； 依赖的三种写法： 构造函数传递依赖对象，也叫构造函数注入 Setter方法传递依赖对象，也叫Setter依赖注入 接口声明依赖对象，也叫接口注入 依赖倒置原则的本质就是通过抽象（接口或抽象类）使各个类或模块的实现彼此独立，不互相影响，实现模块间的松耦合。 每个类尽量都有接口或抽象类，或抽象类和接口两者都具备 变量的表面类型尽量是接口或抽象类 任何类都不应该从具体类派生 尽量不要覆写基类的方法 结合里氏替换原则使用 接口隔离原则ISP定义：客户端不应该依赖它不需要的接口；类间的依赖关系应该建立在最小的接口上。建立单一的接口，不要建立臃肿庞大的接口； 接口尽量小 接口要高内聚：提高接口、类、模块的处理能力，减少对外的交互 定制服务，单独为一个个体提供优良的服务 接口设计要有限度 根据接口隔离原则拆分接口时，首先必须满足单一职责原则。接口和类尽量使用原子接口或原子类来组装。 一个接口只服务玉一个子模块或业务 通过业务逻辑压缩接口中的public方法 已经被污染的接口，尽量去修改，若变更风险较大，则采用适配器模式进行转化处理 了解环境，拒绝盲从 迪米特法则LD也称最少知识原则：一个对象应该对其他对象有最少的了解，对需要耦合或调用的类知道越少越好。 只和朋友交流：类与类间的关系是建立在类之间而不是方法间，一个方法尽量不引入一个类中不存在的对象 朋友间也是有距离的：尽量不对外公布太多public方法和非静态得public变量，尽量内敛 是自己的就是自己的：若一个方法放在本类中，即不增加类间关系，也对本类不产生负面影响，那就放置在本类中。 谨慎使用Serializable 两个对象之间的耦合就成为朋友关系，朋友关系类型很多如组合、聚合、依赖等。 注：朋友类的定义，出现在成员变量、方法输入输出参数中的类称为成员朋友类，出现在方法体内部的类不属于朋友类。 迪米尔法则要求类羞涩一点，尽量不对外公布太多public方法和非静态得public变量，尽量内敛，多使用private、package-private、protected等访问权限。类公开的public属性或方法越多，修改时涉及得面也就越大，变更引起得风险扩散也就越大。迪米特法则核心观念是类间解耦、弱耦合。 缺点：会产生大量中转或跳转类，导致系统的复杂性提高，同时也为维护带来了难度。使用时请反复权衡，既做到让结构清晰，又做到高内聚底耦合。 开闭原则OCP一个软件实体如类、模块和函数应该对扩展开放，对修改关闭。应该通过扩展来实现变化，而不是通过修改已有代码来实现变化。 开闭原则对扩展开放，对修改关闭，并不意味着不做任何修改，底层模块的变更，必然要有更高层模块进行耦合。 可把变化大致分为三类： 逻辑变化：可以通过修改原有类中的方法来完成，前提是所有依赖或者关联类都按照相同的逻辑处理。 子模块变化：底层模块变化必然引起高层模块变化，因此通过扩展完成变化时，高层模块修改是必然的。 可见视图变化 开闭原则是最基础的一个原则，前五个原则都是开闭原则的具体形态，前五个原则就是指导设计的工具和方法，而开闭原则才是精神领袖。 开闭原则对测试的影响在比较重要的方法，测试方法都会很多，可能测试逻辑都很复杂，若要通过修改修改一个方法或多个方法来完成变化，基本上测试用例都得重新写。所以需要通过扩展来实现业务逻辑而不是修改。 开闭原则可以提高复用性在面向对象设计中，所有的逻辑都是从原子逻辑组合而来，而不是在一个类中独立实现一个业务逻辑。颗粒度越小，被复用的可能性就越大。避免相同的逻辑分撒在多个角落，缩小颗粒度，直到一个逻辑不可再拆分为止。 开闭原则可以提高可维护性面向对象开发的要求开闭原则应用抽象约束通过接口或抽象类可以约束一组可能变化的行为，并且能够实现对扩展开放： 通过接口或抽象类约束扩展，对扩展边界限定，不允许出现在接口或抽象类中不存在的public方法 参数类型、引用对象尽量使用接口或抽象类，而不是实现类 抽象层尽量保持稳定 元数据（metadata）控制模块行为尽量使用元数据来控制程序行为，减少重复开发，如login方法中提供的先检查IP地址是否在允许访问的列表中，然后在确定是否需要到数据库中验证密码，表达的极致其实就是控制反转，如Spring的IoC容器。 注：元数据是用来描述环境和数据的数据，通俗的说就是配置参数。 制定项目章程对于项目来说约定优于配置。 封装变化对变化的封装：将相同的变化封装到一个接口或抽象类中，将不同的变化封装到不同的接口或抽象类中，不应该有两个不同的变化出现在同一个接口或抽象类中。 封装变化，也就是受保护的变化，找出预计有变化或不稳定的点。","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/tags/设计模式/"}],"categories":[{"name":"设计模式","slug":"设计模式","permalink":"https://yaoyinglong.github.io/categories/设计模式/"}]},{"title":"HBase依赖冲突","date":"2020-07-05T16:00:00.000Z","path":"Blog/框架/常见问题/HBase依赖冲突/","text":"远程连接maven依赖： 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt; &lt;artifactId&gt;hbase-client&lt;/artifactId&gt; &lt;version&gt;2.2.0&lt;/version&gt;&lt;/dependency&gt; 连接代码： 123456789101112131415161718@Beanpublic Connection hbaseConnection() throws IOException &#123; org.apache.hadoop.conf.Configuration conf = HBaseConfiguration.create(); conf.set(\"hbase.zookeeper.quorum\", \"127.0.0.1\"); conf.set(\"hbase.zookeeper.property.clientPort\", \"2181\"); conf.set(\"zookeeper.znode.parent\", \"/hbase-unsecure\"); Connection connection = ConnectionFactory.createConnection(conf); return connection;&#125;public String query(String tableName, String familyName, String columnName, String qualifier) throws Exception &#123; TableName name = TableName.valueOf(tableName); Table table = hbaseConnection.getTable(name); Get get = new Get(qualifier.getBytes()); get.addColumn(Bytes.toBytes(familyName), Bytes.toBytes(columnName)); Result rs = table.get(get); return Bytes.toString(rs.value());&#125; hive依赖包冲突在项目中同时存在hive和hbase时，hive中引用的guava与hbase中引用的guava版本冲突，从而导致执行hbase查询时报错。 1org.apache.hadoop.hbase.DoNotRetryIOException: java.lang.IllegalAccessError: tried to access method com.google.common.base.Stopwatch.&lt;init&gt;()V from class org.apache.hadoop.hbase.zookeeper.MetaTableLocator Stopwatch在google的guava包下，hbase1.1.2只在guava12-16下能正常运行。guava17开始，出现以上异常。尝试着将guava版本降低，后启动项目后报如下错误： 123An attempt was made to call the method com.google.common.base.Splitter.splitToList(Ljava/lang/CharSequence;)Ljava/lang/List; but it does not exist. Its class, com.google.common.base.Splitter, is available from the following locations: jar:file:/mvnRespo/org/apache/hive/hive-exec/1.2.1/hive-exec-1.2.1.jar!/com/google/common/base/Splitter.class jar:file:/mvnRespo/com/google/guava/guava/16.0/guava-16.0.jar!/com/google/common/base/Splitter.class 由此可见hive必须依赖高版本的guava才行，然后就尝试着将hbase的依赖版本升级到1.3.0，问题得到了解决。 tablestore依赖包冲突12345678910111213141516171819202122232425262728@Value(value = \"$&#123;aliyun.endpoint:http&#125;\")private String endPoint;@Value(value = \"$&#123;aliyun.accessKeyId:test&#125;\")private String accessKeyId;@Value(value = \"$&#123;aliyun.accessSecret:test&#125;\")private String accessSecret;@Value(value = \"$&#123;aliyun.instanceName:test&#125;\")private String instanceName;private SyncClient syncClient;@PostConstructpublic void init() &#123; syncClient = new SyncClient(endPoint, accessKeyId, accessSecret, instanceName);&#125;public String query(String key, String value, String tableName, String columnName) &#123; PrimaryKeyBuilder primaryKeyBuilder = PrimaryKeyBuilder.createPrimaryKeyBuilder(); primaryKeyBuilder.addPrimaryKeyColumn(key, PrimaryKeyValue.fromString(value)); PrimaryKey primaryKey = primaryKeyBuilder.build(); GetRowRequest request = new GetRowRequest(); SingleRowQueryCriteria singleRowQueryCriteria = new SingleRowQueryCriteria(tableName, primaryKey); singleRowQueryCriteria.setMaxVersions(1); request.setRowQueryCriteria(singleRowQueryCriteria); GetRowResponse response = syncClient.getRow(request); Row row = response.getRow(); return row.getLatestColumn(columnName).getValue().asString();&#125; 在项目中同时存在tablestore和hbase时，tablestore中引用的protobuf版本2.4.1与hbase中引用的protobuf版本2.5.0版本冲突，从而导致执行hbase查询时报错。 1Caused by: java.lang.VerifyError: class org.apache.hadoop.hbase.protofuf.generated.ClientProtos$Result overrides final method getUnknownFields.()Lcom/google/protobuf/UnknownFieldSet; 首先想到的是引入高版本的protobuf。但是引入高版本的protobuf后查询阿里的彩虹表tablestore时会报另外的错误。 1java.lang.UnsupportedOperationException: This is supposed to be overridden by subclasses. 尝试着将hbase的版本升高到2.2.0，然后发现问题解决了，然后继续查看了一下protobuf依赖冲突版本，发现多了一个hbase-shaded-protobuf,原来在该版本中使用了hbase-shaded , 用来更改hbase中的一些报名，解决protobuf的冲突问题。","tags":[{"name":"HBase","slug":"HBase","permalink":"https://yaoyinglong.github.io/tags/HBase/"}],"categories":[{"name":"框架","slug":"框架","permalink":"https://yaoyinglong.github.io/categories/框架/"},{"name":"常见问题","slug":"框架/常见问题","permalink":"https://yaoyinglong.github.io/categories/框架/常见问题/"}]},{"title":"Maven编译后文件损坏","date":"2020-07-05T16:00:00.000Z","path":"Blog/框架/常见问题/Maven编译后文件损坏/","text":"在一般Maven项目中的build标签下通常会有如下配置： 123456789101112131415161718192021&lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.yml&lt;/include&gt; &lt;include&gt;**/*.*&lt;/include&gt; &lt;/includes&gt; &lt;excludes&gt; &lt;exclude&gt;application-test.yml&lt;/exclude&gt; &lt;/excludes&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt;&lt;/resources&gt; 以上的配置本身是没有问题的，但在某些需要需要将一些文件存放在项目中直接提供下载时，以上配置就回有问题，如果是将文件放到resources目录下，由于filtering设置为true，开启了过滤，会用指定的参数替换directory下的文件中的参数(eg. ${name})。从而导致文件可能会损坏。 若配置文件需要传参数将filtering设置为false显然是不行的。使用exclude排除想下载的文件打包时都不会将文件打到jar包中，显然也是不行的。然后尝试做了如下调整，但并没有生效： 1234567891011121314151617181920&lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.yml&lt;/include&gt; &lt;include&gt;**/*.*&lt;/include&gt; &lt;/includes&gt; &lt;excludes&gt; &lt;exclude&gt;application-test.yml&lt;/exclude&gt; &lt;exclude&gt;src/main/resources/download&lt;/exclude&gt; &lt;/excludes&gt; &lt;filtering&gt;true&lt;/filtering&gt;&lt;/resource&gt;&lt;resource&gt; &lt;directory&gt;src/main/resources/download&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.*&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt;&lt;/resource&gt; 最终只能将下载的文件单独放到其他目录，然后做如下配置： 12345678910111213141516171819202122232425262728&lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.properties&lt;/include&gt; &lt;include&gt;**/*.yml&lt;/include&gt; &lt;include&gt;**/*.*&lt;/include&gt; &lt;/includes&gt; &lt;excludes&gt; &lt;exclude&gt;application-test.yml&lt;/exclude&gt; &lt;/excludes&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;download&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.*&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/java&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.xml&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt;&lt;/resources&gt;","tags":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/tags/Maven/"}],"categories":[{"name":"框架","slug":"框架","permalink":"https://yaoyinglong.github.io/categories/框架/"},{"name":"常见问题","slug":"框架/常见问题","permalink":"https://yaoyinglong.github.io/categories/框架/常见问题/"}]},{"title":"Go基础","date":"2020-07-02T16:00:00.000Z","path":"Blog/Go/Go基础/","text":"Go语言是静态类型语言，所有的内存在 Go 中都是经过初始化的，当一个变量被声明之后，系统自动赋予它该类型的零值：int 为 0，float 为 0.0，bool 为 false，string 为空字符串，指针为 nil 等。 只有两个相同类型的值才可以进行比较，如果值的类型是接口（interface），那么它们也必须都实现了相同的接口。&amp;&amp;的优先级比||高（&amp;&amp; 对应逻辑乘法，|| 对应逻辑加法，乘法比加法优先级要高）。 变量、函数、常量名称如果首字母大写，则表示它可被其它的包访问；如果首字母小写，则表示它只能在本包中使用。 nil 不是关键字或保留字且不能比较。 数据类型Go语言的基本类型有： bool string int、int8、int16、int32、int64 uint、uint8、uint16、uint32、uint64、uintptr（只有在底层编程时才需要） byte （uint8 的别名） rune （int32 的别名 代表一个 Unicode 码点） float32、float64 complex64、complex128 尽管在某些特定的运行环境下 int、uint 和 uintptr 的大小可能相等，但是它们依然是不同的类型，在需要把 int 类型当做 int32 类型使用的时候必须显示的对类型进行转换。 1234567891011121314const num1 int = 1var num1, num2, num3 = 1, 2, 3var num1, num2, num3 = 1, \"2\", 3.5var ( num1 int num2 string num3 float64)var ( num1 = 1 num2 = \"2\" num3 = 3.5) Go是一门静态类型语言，每个变量都有一个在编译时就确定的静态类型。虽然a和b的的基本类型相同，但静态类型不同，无类型转换的情况下无法相互赋值。虽然在运行时中，接口变量存储的值也许会变，但接口变量的类型是不会变的。 1234type MyInt intvar a intvar b MyInt 容器Go语言常用容器有数组，切片，Map，List。map和切片是不可以用==直接被比较的。 数组的长度必须是常量表达式，若数组长度的位置出现...省略号，则表示数组的长度是根据初始化值的个数来计算。数组的长度是数组类型的一个组成部分，若两个数组类型相同（包括数组的长度，数组中元素的类型），可直接通过较运算符==和!=来判断两个数组是否相等，不能比较两个类型不同的数组，且不能相互赋值，否则程序将无法完成编译。 1234var numArr = [3]int&#123;2, 3, 4,&#125;strArr := [3]int&#123;\"2\", \"3\", \"4\"&#125;array := [5]int&#123;1:10, 3:30&#125; 切片（slice）是对数组的一个连续片段的引用，所以切片是一个引用类型，终止索引标识的项不包括在切片内。切片的内部结构包含地址、大小和容量，切片一般用于快速地操作一块数据集合。切片在扩容时，容量的扩展规律是按容量的 2 倍数进行扩充。在切片开头添加元素一般都会导致内存的重新分配，而且会导致已有元素全部被复制 1 次。make函数创建切片时若只指定长度，则切片的长度和容量相等，不允许创建长度大于容量的切片。 123456789101112131415161718192021222324252627var numbers = [4]int&#123;1, 2&#125;var arr = [...]int&#123;1, 2, 3, 4, 5,&#125;slice := arr[:]slice := arr[1:3]slice := arr[1:]slice := arr[:3]var slice []intslice = append(slice, 1)var slice = make([]int, 2, 5)slice = append(slice, 1, 2, 3, 4)slice = append(slice, []int&#123;5, 6, 7&#125;...)slice = append([]int&#123;-3, -2, -1&#125;, slice...)slice := []int&#123;1, 2, 3, 4&#125;slice = append(slice[:2], append([]int&#123;6, 7&#125;, slice[2:]...)...)sliceA := []int&#123;1, 2, 3, 4, 5&#125;sliceB := []int&#123;6, 7, 8&#125;copyCount := copy(sliceA, sliceB)sliceB := []int&#123;1, 2, 3, 4, 5&#125;sliceA := []int&#123;6, 7, 8&#125;copyCount := copy(sliceA, sliceB)// 创建容量和长度都是100的切片slice := []int&#123;99:0&#125; 计算切片的长度和容量，若底层数组容量k的切片slice[i:j]，长度为j-i，容量为k-i。也可以通过第三个索引来控制新切片的容量。若底层数组容量k的切片slice[i:j:s]，长度为j-i，容量为s-i，s&lt;=K。 map 是引用类型，可动态增长，未初始化的 map 的值是 nil，使用函数 len() 可以获取 map 中 pair 的数目。map不能使用cap()函数。定义map时可现实指定容量，当 map 增长到容量上限的时候，如果再增加新的 key-value，map 的大小会自动加 1。map可以存函数。map是无序的。切片、函数以及包含切片的结构类型由于具有引用语意不能作为map的键。 1234567891011121314151617181920212223242526var mapLit = map[int]string&#123;&#125;var mapLit map[int]stringvar mapLit = make(map[int]string, 16)mapLit := map[int]string&#123;1: \"a\", 2: \"b\"&#125;mapLit[3] = \"c\"for key, value := range mapLit &#123; fmt.Println(\"key value:\", key, value)&#125;delete(mapLit, 1)mapLit := map[string]int&#123; \"hello\": 100, \"world\": 200,&#125;if value, isExist := mapLit[\"hello\"]；isExist： fmt.Println(\"value:\", value)skill := map[string]func()&#123; \"fire\": func() &#123; fmt.Println(\"chicken fire\") &#125;,&#125;f, ok := skill[\"fire\"] 列表是一种非连续的存储容器，由多个节点组成，节点通过一些变量记录彼此之间的关系。 123456789lit := list.New()lit.PushBack(\"AA\")lit.PushFront(\"BB\")element := lit.PushFront(\"CC\")lit.InsertBefore(\"DD\", element)for i := lit.Front(); i != nil; i = i.Next() &#123; fmt.Println(\"lit value:\", i.Value)&#125;lit.Remove(element) Go语言线程安全的sync.Map，Range返回为false时将不再往下遍历。 12345678var syncMap sync.MapsyncMap.Store(1, \"a\")syncMap.Store(2, \"b\")value, ok := syncMap.Load(2)syncMap.Range(func(key, value interface&#123;&#125;) bool &#123; fmt.Println(\"key, value\", key, value) return true&#125;) 流程控制Go 语言常用流程控制有 if 和 for，而 switch 和 goto 主要是为了简化代码、降低重复代码而生的结构，属于扩展类的流程控制。 if-else分支结构，可结合goto使用。 123456789if index := 12; index &gt; 10 &#123;&#125; else &#123;&#125;if index := 10; index == 10 &#123; goto onExit&#125;onExit:fmt.Println(\"exit\") go中只有for循环结构，不支持 while 和 do-while 结构；for range 可以遍历数组、切片、字符串、map 及通道（channel）；其中用到的range 返回的是每个元素的副本，而不是直接返回对该元素的引用。字符串的遍历是一个个rune 字符。 1234567891011121314151617181920212223242526272829JLoop:for j := 0; j &lt; 5; j++ &#123; for i := 0; i &lt; 10; i++ &#123; if i &gt; 5 &#123; break JLoop &#125; &#125;&#125;var index intfor index &lt; 10 &#123; index++&#125;str := \"12456789\"for pos, char := range str &#123; fmt.Println(\"pos, char:\", pos, char)&#125;channel := make(chan int)go func() &#123; channel &lt;- 1 channel &lt;- 2 channel &lt;- 3 close(channel)&#125;()for value := range channel &#123; fmt.Println(\"channel value:\", value)&#125; switch表达式不需要为常量，甚至不需要为整数，case 按照从上到下的顺序进行求值，直到找到匹配的项，若switch 没有表达式，则对 true 进行匹配。fallthrough会紧接着执行下一个 case。 12345678910111213141516str := \"kk\"switch str &#123;case \"hello\", \"kk\": fmt.Println(1) fallthroughcase \"world\": fmt.Println(2)default: fmt.Println(1)&#125;r := 11switch &#123;case r &gt; 10 &amp;&amp; r &lt; 20: fmt.Println(r)&#125; 函数Go 语言支持普通函数、匿名函数和闭包。函数间传递变量总是以值得方式传递，数组传递会完整复制并传递给函数，最好只传入指向数组的指针。函数间传递切片和map，只会复制切片和map本身，不会涉及底层数据。 123456789101112131415161718192021222324252627282930313233343536373839404142func funcA() (a, b int) &#123; a = 1 b = 2 return&#125;a, b := funcA()func funcB() (int, int) &#123; return 3, 4&#125;a, b := funcB()f := funcBa, b := f()func funcC() (a, b string, c int) &#123; return \"a1\", \"b2\", 5&#125;a, b, c := funcC()func funcD(arr []int, f func(int)) &#123; for _, value := range arr &#123; f(value) &#125;&#125;funcD([]int&#123;1, 2, 3, 4&#125;, func(data int) &#123; fmt.Println(\"this value:\", data)&#125;)// 函数变量var f func() (int, int)f = funcAa, b := f()// 匿名函数func(data int) &#123; fmt.Println(\"inner func:\", data)&#125;(100)f := func(data int) &#123; fmt.Println(\"inner func:\", data)&#125;f(500) 闭包是引用了自由变量的函数，被引用的自由变量和函数一同存在，即使已经离开了自由变量的环境也不会被释放或者删除。被捕获到闭包中的变量让闭包本身拥有了记忆效应。 12345678910func accumulate(value int) func() int &#123; return func() int &#123; value++ return value &#125;&#125;accumulator := accumulate(1)fmt.Println(accumulator()) // 2fmt.Println(accumulator()) // 3 可变参数和任意类型的可以变参数，用 interface{} 传递任意类型数据，可变参数变量是一个包含所有参数的切片，如果要将这个含有可变参数的变量传递给下一个可变参数函数，可以在传递时给可变参数变量后面添加...，这样就可以将切片中的元素进行传递，而不是传递可变参数变量本身。 1234567891011121314151617181920212223242526func notFixedParam(args ...int) &#123;&#125;func notFixedParamV2(format string, args ...interface&#123;&#125;) &#123; for _, arg := range args &#123; switch arg.(type) &#123; case int: case string: case int64: default: &#125; &#125;&#125;notFixedParam(1, 2)notFixedParamV2(\"kk\", 1, 234, \"hello\", 3.14)func rawPrint(rawList ...interface&#123;&#125;) &#123; for _, raw := range rawList &#123; fmt.Println(raw) &#125;&#125;func print(slist ...interface&#123;&#125;) &#123; rawPrint(slist...)&#125; defer 语句会将其后面跟随的语句进行延迟处理，在 defer 归属的函数即将返回时，将延迟处理的语句按 defer 的逆序进行执行。类似java的finally语句块。可与宕机panic 一起使用，宕机前会优先执行defer。提供recover 用于宕机恢复，且仅在延迟函数 defer 中有效。正常的执行过程中，调用 recover 会返回 nil 并且没有其他任何效果，调用 recover 可以捕获到 panic 的输入值，并且恢复正常的执行。recover 的宕机恢复机制就对应其他语言中的 try/catch 机制。 12defer fmt.Println(\"宕机后要做的事情\")panic(\"宕机\") 结构体结构体的定义只是一种内存布局的描述，只有当结构体实例化时，才会真正地分配内存。使用new或&amp;构造的类型实例的类型是类型的指针。Go语言的类型或结构体没有构造函数的功能. 使用.来访问结构体的成员变量，访问结构体指针的成员变量时可以继续使用.，Go使用了语法糖（Syntactic sugar）技术，将 ins.Name 形式转换为 (*ins).Name；对结构体进行&amp;取地址操作时，视为对该类型进行一次 new 的实例化操作； 1234567891011121314151617181920212223242526272829303132333435type Color struct &#123; R, G, B byte&#125;color := new(Color)(*color).R = 12color.G = 16color := &amp;Color&#123;&#125;(*color).R = 12color.G = 16type Command struct &#123; Name string Var *int Comment string&#125;version := 1// 使用键值对填充结构体cmd := &amp;Command&#123; Name: \"version\", Var: &amp;version, Comment: \"show version\",&#125;fmt.Println(\"cmd, Name, Var, Comment:\", *cmd, cmd.Name, *cmd.Var, cmd.Comment)// 使用多个值的列表初始化结构体cmd := Command&#123; \"version\", &amp;version, \"show version\",&#125;fmt.Println(\"cmd, Name, Var, Comment:\", cmd, cmd.Name, *cmd.Var, cmd.Comment) 匿名结构体没有类型名称，无须通过 type 关键字定义就可以直接使用。 12345678910111213141516171819202122232425ins := struct &#123; Name string Var *int Comment string&#125;&#123; \"version\", &amp;version, \"show version\",&#125;func printMsg (msg *struct&#123; id int data string&#125;)&#123; fmt.Println(\"msg\", msg)&#125;msg := &amp;struct &#123; id int data string&#125;&#123; 1024, \"hello\",&#125;printMsg(msg) 结构体可以包含一个或多个匿名（或内嵌）字段，没有显式的名字，只有字段的类型，此时类型也就是字段的名。在一个结构体中对于每一种数据类型只能有一个匿名字段。结构体可以包含内嵌结构体，内嵌结构体甚至可以来自其他包。 结构体实例访问任意一级的嵌入结构体成员时都只用给出字段名，而无须像传统结构体字段一样，通过一层层的结构体字段访问到最终的字段。内嵌结构体字段仍然可以使用详细的字段进行一层层访问，内嵌结构体的字段名就是它的类型名。 1234567891011121314151617181920212223type innerS struct &#123; in1 int in2 int&#125;type outerS struct &#123; b int c float32 in1 int int innerS&#125;outer := new(outerS)outer.b = 6outer.c = 7.5outer.int = 60outer.in1 = 20outer.innerS.in1 = 5outer.in2 = 10fmt.Println(\"outer1 :\", *outer)outer2 := outerS&#123;6, 7.5, 20, 60, innerS&#123;5, 10&#125;&#125;fmt.Println(\"outer2 :\", outer2) 结构体标签是对结构体字段的额外信息标签，由一个或多个键值对组成；键与值使用冒号分隔，值用双引号括起来；键值对之间使用一个空格分隔。标签内容是静态的，无须实例化结构体，可以通过反射从结构体中获取标签内容。 123456789type Ins struct &#123; in1 int `key1:\"value1\" key2:\"value2\"` in2 int `key1:\"value1\" key2:\"value2\"`&#125;typeOfIns := reflect.TypeOf(Ins&#123;&#125;)if catType, ok := typeOfIns.FieldByName(\"in2\"); ok &#123; fmt.Println(catType.Tag.Get(\"key1\"))&#125; 方法能给用户定义的类型添加新的行为，实际上也是函数，仅仅是在申明时，在关键字func和方法名间增加了一个参数，该参数称为接收者（值接收者、指针接收者），有接收者为方法，无接收者为函数。值接收者调用时会使用这个值的副本来执行，如下所示changeEmailV2方法是无效的。 123456789101112type cusUser struct &#123; name string email string&#125;func (u *cusUser) changeEmailV1(email string) &#123; u.email = email&#125;func (u cusUser) changeEmailV2(email string) &#123; u.email = email&#125; 若要创建一个新值，该类型的方法使用值接收者，若要修改当前值，使用指针接收者。 接口Go无类和继承的概念，Go语言的接口在命名时，一般会在单词后面添加 er；当方法名首字母大写时，且该接口类型名首字母也大写时，该方法可被接口所在的包之外的代码访问。 接口被实现必须满足，接口的方法与实现接口的类型方法格式一致，接口中所有方法均被现实。类型和接口之间有一对多和多对一的关系。一个类型可以同时实现多个接口，一个接口的方法，不一定需要由一个类型完全实现。 一个接口可以包含一个或多个其他的接口，这相当于直接将这些内嵌接口的方法列举在外层接口中一样。只要接口的所有方法被实现，则这个接口中的所有嵌套接口的方法均可以被调用。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556type DataWriter interface &#123; WriteData(data interface&#123;&#125;) error CanWriter() bool&#125;type Closer interface &#123; WriterClose() error&#125;type FileWriter struct &#123;&#125;type NetWriter struct &#123; FileWriter&#125;func(d *FileWriter) WriteData(data interface&#123;&#125;) error &#123; fmt.Println(\"WriteData:\", data) return nil&#125;func(d *FileWriter) WriterClose() error &#123; fmt.Println(\"FileWriter Close\") return nil&#125;func(d *NetWriter) CanWriter() bool &#123; fmt.Println(\"CanWrite\") return false&#125;fileWriter := new(FileWriter)fileWriter.WriterClose()fileWriter.WriteData(\"FileWriter\")netWriter := new(NetWriter)netWriter.WriterClose()netWriter.WriteData(\"NetWriter\")netWriter.CanWriter()f := new(NetWriter)var writer DataWriterwriter = fwriter.WriteData(\"NetWriter2\")writer.CanWriter()var writer DataWriter = new(NetWriter)writer = fwriter.WriteData(\"NetWriter3\")writer.CanWriter()var writeCloser DataWriteCloser = new(NetWriter)writeCloser.WriterClose()writeCloser.WriteData(\"writeCloser\")writeCloser.CanWriter() 将接口转换为其他接口，若不写ok接收是否为实现该类型，若rw没有完全实现接口，将触发宕机。 123var writeCloser DataWriteCloser = new(NetWriter)rw, ok := writeCloser.(Closer)fmt.Println(ok, \";\", rw.WriterClose()) 将接口转换为其他类型时，接口内保存的实例对应的类型指针，必须是要转换的对应的类型指针。 123var writeCloser DataWriteCloser = new(NetWriter)rw, ok := writeCloser.(*NetWriter)fmt.Println(ok, \";\", rw.WriterClose(), rw.WriteData(\"*NetWriter\"), rw.CanWriter()) 接口在底层的实现有type 和 data两个部分。显式地将 nil 赋值给接口时，接口的 type 和 data 都将为 nil，此时接口与 nil 值判断是相等的。将带有类型的 nil 赋值给接口时，只有 data 为 nil，而type 不为 nil，此时接口与 nil 判断将不相等。 12345678910111213141516type insImpl struct &#123;&#125;func (ins *insImpl) String() string &#123; return \"hi\"&#125;func GetStringer() fmt.Stringer&#123; var ins *insImpl = nil return ins&#125;// falsefmt.Println(GetStringer() == nil)// truevar ins *insImpl = nilfmt.Println(ins == nil) 包Go的源码复用建立在包package的基础上，入口 main() 函数所在的包（package）叫 main。包与文件夹一一对应，一般包的名称就是其源文件所在目录的名称，所有与包相关的操作，必须依赖于工作目录GOPATH。包可以定义在很深的目录中，包名的定义是不包括目录路径的，但是包在引用时一般使用全路径引用。 包的习惯用法： 包名一般小写，使用简短且有意义的名称。 包名一般和所在目录同名，也可不同，包名中不能包含-等特殊符号。 包一般使用域名作为目录名称，能保证包名的唯一性。 包名为 main 的包为应用程序的入口包，编译不包含 main 包的源码文件时不会得到可执行文件。 一个文件夹下的所有源码文件只能属于同一个包，同样属于同一个包的源码文件不能放在多个文件夹下。 包的引用路径分为全路径导入和相对路径导入。可以自定义别名引用包；也可用.省略引用格式，相当于把 包直接合并到当前程序中，在使用 包内的方法是可以不用加前缀直接引用；若只执行包初始化的 init 函数，不使用包内部的数据可使用匿名引用格式； 12345678910// 全路径导入：源码位于GOPATH/src/lab/test目录下import \"lab/test\"// 相对路径导入：源码位GOPATH/src/lab/a目录下import \"../a\"// 自定义别名引用包import F \"fmt\"// 省略引用格式import . \"fmt\"// 匿名引用格式import _ \"fmt\" 一个包可有多个 init 函数，包加载时会执行全部 init 函数，但不能保证执行顺序；包不能出现环形引用；包允许重复引用；包初始化程序从 main 函数引用的包开始，逐级查找包的引用，直到找到没有引用其他包的包，最终生成一个包引用的有向无环图；编译器会将有向无环图转换为一棵树，然后从树的叶子节点开始逐层向上对包进行初始化；单个包的初始化先初始化常量，然后是全局变量，最后执行包的 init 函数。 并发Go 的并发通过 goroutine特性完成。goroutine 类似于线程，但是可根据需要创建多个 goroutine 并发工作。goroutine 是由 Go 运行时调度完成，而线程是由操作系统调度完成。 Go 提供 channel在多个 goroutine 间进行通信，channel是类型相关的语言级别得goroutine间的进程内的通信方式。必须使用 make 创建 channel；可以通过通道共享内置类型、命名类型、结构类型和引用类型的值或者指针。 123456789101112ch := make(chan int)go func() &#123; ch &lt;- 1 &#125;()ch := make(chan interface&#123;&#125;)go func() &#123; ch &lt;- \"hi\" &#125;()type Equip struct &#123; a int b int&#125;ch := make(chan *Equip)go func() &#123; ch &lt;- &amp;Equip&#123;a: 1, b: 2&#125; &#125;() 通道使用&lt;-操作符发送和接收数据；把数据往通道中发送时，若接收方一直未接收，发送操作将持续阻塞；通道的收发操作在不同的两个 goroutine 间进行；接收将持续阻塞直到发送方发送数据；每次接收一个元素；被关闭的通道不会被置为 nil。对已经关闭的通道进行发送，将会触发宕机。从已关闭的通道接收数据或者正在接收数据时，将会接收到通道类型的零值，然后停止阻塞并返回。 1234567891011121314// 阻塞接收数据data := &lt;-ch// 非阻塞接收数据，可能造成高CPU占用，很少使用，若ok未false表示通道ch已关闭data, ok := &lt;-ch// 接收任意数据，忽略接收数据&lt;- ch// 声明一个只能发送的通道类型var chSendOnly = make(chan&lt;- int)// 声明一个只能接收的通道类型var chRecvOnly = make(&lt;-chan int)// 关闭通道close(chSendOnly)// 带缓冲的通道，缓冲通道被填满时，发送数据时发生阻塞，带缓冲通道为空时，接收数据时发生阻塞ch := make(chan int, 3) 协程有独立的栈空间，共享堆空间，调度由用户自己控制，本质上类似于用户级线程，这些用户级线程的调度也是自己实现的。一个线程上可以跑多个协程，协程是轻量级的线程。 使用 go 关键字创建 goroutine 时，被调用函数的返回值会被忽略。若要在 goroutine 中返回数据，通过通道把数据从 goroutine 中作为返回值传出。 123go func(param1, param2 int) &#123; fmt.Println(\"param3, param4:\", param1, param2)&#125;(3, 4) Go未为channel专门设置超时处理机制，但可通过select来设置超时。select用法与switch很类似，但select中只要其中一个case已经完成，程序就会继续往下执行，而不会考虑其他case情况，且每个case语句里必须是一个IO操作，select是按顺序从头至尾评估。若无语句可执行，则执行default语句，否则被阻塞。 12345678910ch := make(chan int)quit := make(chan bool)select &#123;case num := &lt;-ch: fmt.Println(\"num:\", num)case &lt;-time.After(3 * time.Second): fmt.Println(\"timeout\") quit &lt;- true&#125; Go的sync包中提供互斥锁sync.Mutex和读写互斥锁sync.RWMutex。同时提供了等待组sync.WaitGroup进行多个任务的同步，每个 sync.WaitGroup 值在内部维护着一个计数，保证在并发环境中完成指定数量的任务，若WaitGroup的值大于0，Wait方法就会被阻塞。同时提供原子访问atomic。 12345678910111213141516171819202122var rw sync.Mutexrw.Lock()defer rw.Unlock()var rw sync.RWMutexrw.RLock()defer rw.RUnlock()rw.Lock()defer rw.Unlock()var wg sync.WaitGroupwg.Add(1)go func()&#123; defer wg.Done() &#125;()wg.Wait()atomic.AddInt32(&amp;counter, 1)// 安全的写整型值atomic.StoreInt64(&amp;counter, 1)// 安全的读整型值atomic.LoadInt64(&amp;counter) 死锁发生条件： 互斥条件 请求和保持条件 不剥夺条件 环路等待 解决办法： 并发范文多个表，约定访问顺序 同一事物中，尽可能一次锁定获取所需资源 容易死锁业务场景，尝试升级锁颗粒度 采用分布式事务锁或乐观锁 反射reflect 包定义了两个重要的类型 Type 和 Value 任意接口值在反射中都可以理解为由 reflect.Type 和 reflect.Value 两部分组成；提供了reflect.TypeOf 和reflect.ValueOf 两个函数来获取任意对象的 Value 和 Type。 反射中分类型Type和种类Kind，当需要区分一个大品种的类型时用Kind，Kind方法描述的是基础类型；如需统一判断类型中的指针时。而Type是指系统原生数据类型，以及使用type关键字定义的类型。通过 reflect.Elem() 方法获取该指针指向的元素类型。Elem方法能够对指针进行解引用，然后将结果存储到反射 Value 类型对象 中。 反射可以将接口类型变量转换为反射类型对象，反射可以将反射类型对象转换为接口类型变量，若要修改反射类型对象其值必须是可写的。可通过 CanSet 方法检查reflect.Value类型变量的可写性。对于不具有可写性的 Value 类型变量，调用 Set 方法会报错。 1234567891011121314151617181920212223242526272829303132333435type T struct &#123; A int B string&#125;t := &amp;T&#123;&#125;typeOfT := reflect.TypeOf(t)// Name: ,Kind:ptrfmt.Println(\"name:\", typeOfT.Name(), \"kind:\", typeOfT.Kind())// 通过 reflect.Elem() 方法获取这个指针指向的元素类型typeOfT = typeOfT.Elem()// Name: T,Kind: structfmt.Println(\"name:\", typeOfT.Name(), \"kind:\", typeOfT.Kind())typeOfT.Field(0).SetInt(99)typeOfT.Field(1).SetString(\"Sunset Strip\")t := T&#123;23, \"skidoo\"&#125;typeOfA := reflect.TypeOf(t)// Name: T,Kind: structfmt.Println(\"name:\", typeOfA.Name(), \"kind:\", typeOfA.Kind())type MyInt intvar x MyInt = 7tof := reflect.TypeOf(x)// Name: MyInt,Kind: intfmt.Println(\"name:\", tof.Name(), \"kind:\", tof.Kind())vof := reflect.ValueOf(x)// 不能是intref := vof.Interface().(MyInt)fmt.Println(\"can set:\", vof.CanSet()) // falsevof2 := reflect.ValueOf(&amp;x)fmt.Println(\"can set:\", vof2.CanSet()) // falsevof3 := vof2.Elem()fmt.Println(\"can set:\", vof3.CanSet()) // truevof3.SetInt(25)fmt.Println(\"ref:\", vof3) // 25 Map、Slice、Chan 属于引用类型，使用起来类似于指针，但是在种类常量定义中仍然属于独立的种类Kind，不属于 Ptr。所有通过reflect.ValueOf(x) 返回的reflect.Value都不可以取地址，通过指针间接地获取的reflect.Value都可以取地址，即使开始的是一个不可取地址的Value。当reflect.Value不可寻址时，使用 Addr() 方法也无法取到值的地址。 已知reflect.Type时，可动态地创建这个类型的实例，实例的类型为指针。 12345var a inttypeOfA := reflect.TypeOf(a)aIns := reflect.New(typeOfA)// name: *int, kind: ptrfmt.Println(\"name:\", aIns.Type(), \"kind:\", aIns.Kind()) 使用反射调用函数时，需将参数使用反射值对象的切片[]reflect.Value构造后传入Call()方法中，调用完成时，函数的返回值通过[]reflect.Value返回。 123456funcVal := reflect.ValueOf(func(a, b int) int &#123; return a + b&#125;)paramList := []reflect.Value&#123;reflect.ValueOf(10), reflect.ValueOf(24)&#125;retList := funcVal.Call(paramList)fmt.Println(\"result:\", retList[0].Int()) Test 测试用例文件不会参与正常源码的编译，不会被包含到可执行文件中； 测试用例的文件名必须以_test.go结尾； 需要使用 import 导入 testing 包； 测试函数的名称要以Test或Benchmark开头，后面可以跟任意字母组成的字符串，但第一个字母必须大写，例如 TestAbc()，一个测试用例文件中可以包含多个测试函数； 单元测试则以(t *testing.T)作为参数，性能测试以(t *testing.B)做为参数； 测试用例文件使用go test命令来执行，源码中不需要 main() 函数作为入口，所有以_test.go结尾的源码文件内以Test开头的函数都会自动执行。 SetFinalizerGo语言自带垃圾回收机制，GC 是自动进行的，可以使用 runtime.GC() 函数手动 GC。 finalizer（终止器）是通过 runtime.SetFinalizer 来设置与对象关联的一个函数，若某对象定义了 finalizer，当它被 GC 时候，该finalizer 将被调用。 1func SetFinalizer(x, f interface&#123;&#125;) 参数x 必须是一个指向通过 new 申请的对象的指针，或者通过对复合字面值取址得到的指针，参数 f 必须是一个函数。SetFinalizer 函数将 x 的终止器设置为 f，当垃圾收集器发现 x 不能再直接或间接访问时，则清理 x 并调用 f(x)，终止器会在 x 不能直接或间接访问后的任意时间被调用执行，不保证终止器会在程序退出前执行，因此一般终止器只用于在长期运行的程序中释放关联到某对象的非内存资源。*x 的大小为 0 字节，也不保证终止器会执行。也可以使用SetFinalizer(x, nil)来清理绑定到 x 上的终止器。 1234567891011121314151617type Road intfunc findRoad(r *Road) &#123; log.Println(\"road:\", *r)&#125;func entry() &#123; var rd = Road(999) r := &amp;rd runtime.SetFinalizer(r, findRoad)&#125;entry()for i := 0; i &lt; 10; i++ &#123; time.Sleep(time.Second) runtime.GC()&#125;","tags":[{"name":"Go","slug":"Go","permalink":"https://yaoyinglong.github.io/tags/Go/"}],"categories":[{"name":"Go","slug":"Go","permalink":"https://yaoyinglong.github.io/categories/Go/"}]},{"title":"亲密关系","date":"2020-06-26T16:00:00.000Z","path":"Blog/自度/亲密关系/","text":"很多时候问题不能解决，是因为我们在非常有限的知识来源中寻找答案，却不懂得运用我们的想象力和直觉来突破问题的框架。 要解决问题，必须先跳脱问题的框架 所有问题，其实都是经过伪装的礼物和宝贵的经验 你所看到的每件事，都是你内心世界的投影 每个人都有能力为自己生活中遇到的事百分百负责 自由并非来自答案，而是来自问题 没有什么问题是大道爱无法解决的","tags":[],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"情商","date":"2020-06-24T16:00:00.000Z","path":"Blog/自度/情商/","text":"提高情商是把不可控情绪的部分变为可控制情绪，从而增强理解他人及与他人相处的能力。 低情商特点 说话做事时无意识顾及别人的感受 下意识地推卸责任、散发负面情绪 感知力差，收不到他人的情绪反馈 缺乏安全感，渴望得到他人的关注 惯性泼冷水，没有赞美他人的天性 情商五要素 了解自我 自我情绪 自我激励 识别他人情绪 情商即是认识自己也是认识他人，认识自己包括自我定位、自我管理、自我激励；认识他人包括洞察情绪、同理心、学会沟通。","tags":[],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"树基础","date":"2020-06-21T16:00:00.000Z","path":"Blog/算法/树基础/","text":"特点 每个节点有零个或多个子节点； 没有父节点的节点称为根节点； 每个非根节点有且仅有一个父节点； 除了根节点以外，每个子节点都可分为多个不相交的子树； 术语 节点的度：一个节点含有的子树的个数称为该节点的度，二叉树的度为2； 树的度：一棵树中，最大的节点的度称为树的度； 叶节点或终端节点：度为零的节点； 父节点：若一个节点含有子节点，则这个节点称为其子节点的父节点； 子节点：一个节点含有的子树的根节点称为该节点的子节点； 兄弟节点：具有相同父节点的节点互称为兄弟节点； 节点的层次：从根开始定义起，根为第1层，根的子节点为第2层，以此类推； 树的高度或深度：树中节点的最大层次； 堂兄弟节点：父节点在同一层的节点互为堂兄弟； 节点的祖先：从根到该节点所经分支上的所有节点； 子孙：以某节点为根的子树中任一节点都称为该节点的子孙。 森林：由m（m&gt;=0）棵互不相交的树的集合称为森林； 分类 无序树：树中任意节点的子节点之间没有顺序关系，这种树称为无序树，也称为自由树； 有序树：树中任意节点的子节点之间有顺序关系，这种树称为有序树； 二叉树：每个节点最多含有两个子树的树称为二叉树； 完全二叉树：对于一颗二叉树，假设其深度为d(d&gt;1)。除了第d层外，其它各层的节点数目均已达最大值，且第d层所有节点从左向右连续地紧密排列，这样的二叉树被称为完全二叉树，其中满二叉树的定义是所有叶节点都在最底层的完全二叉树; 平衡二叉树（AVL树，红黑树是该树的一种）：当且仅当任何节点的两棵子树的高度差不大于1的二叉树，SGI/STL的set/map底层都是用红黑树实现的； 排序二叉树（二叉查找树（英语：Binary Search Tree），也称二叉搜索树、有序二叉树）； 霍夫曼树（用于信息编码）：带权路径最短的二叉树称为哈夫曼树或最优二叉树； B树：一种对读写操作进行优化的自平衡的二叉查找树，能够保持数据有序，拥有多余两个子树。 二叉树的遍历​ 二叉树的遍历分为广度优先遍历和深度优先遍历，广度优先遍历又叫层序遍历，从上往下每一层从左到右依次访问节点；深度优先遍历可细分为先序遍历、中序遍历、后续遍历； 12345public class TreeNode &#123; int value; TreeNode leftNode; TreeNode rightNode;&#125; 前序遍历对任一子树，先访问根，然后遍历其左子树，最后遍历其右子树。前序遍历的形式总是：[ 根节点, [左子树的前序遍历结果], [右子树的前序遍历结果] ] 1234567891011121314151617181920212223public void preorder(TreeNode treeNode) &#123; if (treeNode == null) &#123; return; &#125; System.out.println(treeNode); preorder(treeNode.leftNode); preorder(treeNode.rightNode);&#125;public void preOrderDfs(TreeNode root) &#123; Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); stack.push(root); while (!stack.isEmpty()) &#123; TreeNode tree = stack.pop(); System.out.println(tree); if (tree.rightNode != null) &#123; stack.push(tree.rightNode); &#125; if (tree.leftNode != null) &#123; stack.push(tree.leftNode); &#125; &#125;&#125; 中序遍历对任一子树，先遍历其左子树，然后访问根，最后遍历其右子树。中序遍历的形式总是：[ [左子树的中序遍历结果], 根节点, [右子树的中序遍历结果] ] 123456789101112131415161718192021public void inorder(TreeNode treeNode) &#123; if (treeNode == null) &#123; return; &#125; inorder(treeNode.leftNode); System.out.println(treeNode); inorder(treeNode.rightNode);&#125;public void inOrderDfs(TreeNode root) &#123; Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); while (root != null || !stack.isEmpty()) &#123; while (root != null) &#123; stack.push(root); root = root.left; &#125; root = stack.pop(); System.out.print(root.val); root = root.right; &#125;&#125; 后序遍历对任一子树，先遍历其左子树，然后遍历其右子树，最后访问根。 123456789101112131415161718192021222324252627282930public void backorder(TreeNode treeNode) &#123; if (treeNode == null) &#123; return; &#125; backorder(treeNode.leftNode); backorder(treeNode.rightNode); System.out.println(treeNode);&#125;public void backOrderDfs(TreeNode root) &#123; Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); while (root != null || !stack.isEmpty()) &#123; while (root != null) &#123; stack.push(root); root = root.left; &#125; root = stack.pop(); TreeNode right = null; while (root.right == null || root.right == right) &#123; System.out.print(root.val); right = root; if (stack.isEmpty()) &#123; return; &#125; root = stack.pop(); &#125; stack.push(root); root = root.right; &#125;&#125; 层序遍历|广度优先遍历12345678910111213141516171819public List&lt;Integer&gt; bfs(TreeNode root) &#123; List&lt;Integer&gt; lists = new ArrayList&lt;Integer&gt;(); if (root == null) &#123; return lists; &#125; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); while (!queue.isEmpty()) &#123; TreeNode tree = queue.poll(); if (tree.leftNode != null) &#123; queue.offer(tree.leftNode); &#125; if (tree.rightNode != null) &#123; queue.offer(tree.rightNode); &#125; lists.add(tree.value); &#125; return lists;&#125; 二叉树的深度计算二叉树的深度可以通过后序遍历和层序遍历计算二叉树的深度。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public int maxDepth(TreeNode root) &#123; if (root == null) &#123; return 0; &#125; return Math.max(maxDepth(root.leftNode), maxDepth(root.rightNode)) + 1;&#125;public int maxDepthBfs(TreeNode root) &#123; if (root == null) &#123; return 0; &#125; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); int maxDepth = 0; queue.add(root); while (!queue.isEmpty()) &#123; maxDepth++; int len = queue.size(); for (int i = 0; i &lt; len; i++) &#123; TreeNode treeNode = queue.poll(); if (treeNode.leftNode != null) &#123; queue.add(treeNode.leftNode); &#125; if (treeNode.rightNode != null) &#123; queue.add(treeNode.rightNode); &#125; &#125; &#125; return maxDepth;&#125;public int minDepth(TreeNode root) &#123; if (root == null) &#123; return 0; &#125; int left = minDepth(root.left); int right = minDepth(root.right); if (left == 0) &#123; return right + 1; &#125; if (right == 0) &#123; return left + 1; &#125; return Math.min(left, right) + 1;&#125;public int minDepthBfs(TreeNode root) &#123; if (root == null) &#123; return 0; &#125; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); int minDepth = 0; while (!queue.isEmpty()) &#123; int len = queue.size(); for (int i = 0; i &lt; len; i++) &#123; TreeNode node = queue.poll(); if (node.left == null &amp;&amp; node.right == null) &#123; return minDepth + 1; &#125; if (node.left != null) &#123; queue.offer(node.left); &#125; if (node.right != null) &#123; queue.offer(node.right); &#125; &#125; minDepth++; &#125; return minDepth;&#125; 二叉树的直径123456789101112131415int diameter = 0;public int diameter(TreeNode root) &#123; depth(root); return diameter;&#125;public int depth(TreeNode treeNode) &#123; if (treeNode == null) &#123; return 0; &#125; int left = depth(treeNode.leftNode); int right = depth(treeNode.rightNode); diameter = Math.max(left + right, diameter); return Math.max(left, right) + 1;&#125; 镜像二叉树转换123456789101112131415161718192021222324252627282930public TreeNode mirrorTree(TreeNode root) &#123; if (root == null) &#123; return null; &#125; TreeNode tmp = root.left; root.left = mirrorTree(root.right); root.right = mirrorTree(tmp); return root;&#125;public TreeNode mirrorTree(TreeNode root) &#123; if (root == null) &#123; return null; &#125; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); while (!queue.isEmpty()) &#123; TreeNode treeNode = queue.poll(); if (treeNode.right != null) &#123; queue.offer(treeNode.right); &#125; if (treeNode.left != null) &#123; queue.offer(treeNode.left); &#125; TreeNode tmp = treeNode.left; treeNode.left = treeNode.right; treeNode.right = tmp; &#125; return root;&#125; 对称二叉树判断12345678910111213public boolean isSymmetric(TreeNode root) &#123; return check(root, root);&#125;public boolean check(TreeNode p, TreeNode q) &#123; if (p == null &amp;&amp; q == null) &#123; return true; &#125; if (p == null || q == null || p.val != q.val) &#123; return false; &#125; return check(p.left, q.right) &amp;&amp; check(p.right, q.left);&#125; 合并二叉树123456789101112public TreeNode mergeTrees(TreeNode t1, TreeNode t2) &#123; if (t1 == null) &#123; return t2; &#125; if (t2 == null) &#123; return t1; &#125; t1.val += t2.val; t1.left = mergeTrees(t1.left, t2.left); t1.right = mergeTrees(t1.right, t2.right); return t1;&#125; 最长相同直径12345678910111213141516171819202122public int longest = 0;public int longestUnivaluePath(TreeNode root) &#123; traversal(root); return longest;&#125;public int traversal(TreeNode root) &#123; if (root == null) &#123; return 0; &#125; int left = traversal(root.left); int right = traversal(root.right); int arrowLeft = 0, arrowRight = 0; if (root.left != null &amp;&amp; root.left.val == root.val) &#123; arrowLeft += left + 1; &#125; if (root.right != null &amp;&amp; root.right.val == root.val) &#123; arrowRight += right + 1; &#125; longest = Math.max(longest, arrowLeft + arrowRight); return Math.max(arrowLeft, arrowRight);&#125; 最近公共祖先根据 left 和 right ，可展开为四种情况； 当left和right同时为空 ：说明root的左 / 右子树中都不包含 p,q，返回 null； 当left和right同时不为空 ：说明 p, q分列在root的 异侧 ，因此 root为最近公共祖先，返回 root； 当left为空 ，right 不为空 ：p,q都不在 root的左子树中，直接返回 right。具体可分为两种情况： p,q其中一个在root的 右子树中，此时right指向p； p,q两节点都在 root的 右子树中，此时的 right指向最近公共祖先节点 ； 当 left不为空 ， right为空 同理； 1234567891011121314public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) &#123; if(root == null || root == p || root == q) &#123; return root; &#125; TreeNode left = lowestCommonAncestor(root.left, p, q); TreeNode right = lowestCommonAncestor(root.right, p, q); if(left == null) &#123; return right; &#125; if(right == null) &#123; return left; &#125; return root;&#125; 通过前序中序创建树123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public TreeNode buildTree(int[] preorder, int[] inorder) &#123; if (preorder == null || inorder == null || preorder.length == 0 || preorder.length != inorder.length) &#123; return null; &#125; Map&lt;Integer, Integer&gt; indexMap = new HashMap&lt;&gt;(); for (int i = 0; i &lt; inorder.length; i++) &#123; indexMap.put(inorder[i], i); &#125; return buildTrav(preorder, 0, preorder.length - 1, 0, indexMap);&#125;public TreeNode buildTrav(int[] preorder, int preLeft, int preRight, int inLeft, Map&lt;Integer, Integer&gt; indexMap) &#123; if (preLeft &gt; preRight) &#123; return null; &#125; TreeNode root = new TreeNode(preorder[preLeft]); if (preLeft == preRight) &#123; return root; &#125; int rootIndex = indexMap.get(preorder[preLeft]); int leftNodes = rootIndex - inLeft; root.left = buildTrav(preorder, preLeft + 1, leftNodes + preLeft, inLeft, indexMap); root.right = buildTrav(preorder, preLeft + leftNodes + 1, preRight, rootIndex + 1, indexMap); return root;&#125;public TreeNode buildTree(int[] preorder, int[] inorder) &#123; if (preorder == null || inorder == null || preorder.length == 0 || preorder.length != inorder.length) &#123; return null; &#125; TreeNode root = new TreeNode(preorder[0]); Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;(); stack.push(root); int inorderIndex = 0; for (int i = 1; i &lt; preorder.length; i++) &#123; int preorderVal = preorder[i]; TreeNode node = stack.peek(); if (node.val != inorder[inorderIndex]) &#123; node.left = new TreeNode(preorderVal); stack.push(node.left); &#125; else &#123; while (!stack.isEmpty() &amp;&amp; stack.peek().val == inorder[inorderIndex]) &#123; node = stack.pop(); inorderIndex++; &#125; node.right = new TreeNode(preorderVal); stack.push(node.right); &#125; &#125; return root;&#125; 通过中序后序创建树123456789101112131415161718192021222324public int postIndex;public TreeNode buildTree(int[] inorder, int[] postorder) &#123; if (inorder == null || postorder == null || inorder.length == 0 || inorder.length != postorder.length) &#123; return null; &#125; postIndex = inorder.length - 1; Map&lt;Integer, Integer&gt; indexMap = new HashMap&lt;&gt;(); for (int i = 0; i &lt; inorder.length; i++) &#123; indexMap.put(inorder[i], i); &#125; return buildTreeTrav(postorder, 0, postIndex, indexMap);&#125;public TreeNode buildTreeTrav(int[] postorder, int inLeft, int inRight, Map&lt;Integer, Integer&gt; indexMap) &#123; if (inLeft &gt; inRight) &#123; return null; &#125; TreeNode root = new TreeNode(postorder[postIndex]); postIndex--; int rootIndex = indexMap.get(root.val); root.right = buildTreeTrav(postorder, rootIndex + 1, inRight, indexMap); root.left = buildTreeTrav(postorder, inLeft, rootIndex - 1, indexMap); return root;&#125; 通过前序后序创建树12345678910111213141516171819202122public TreeNode constructFromPrePost(int[] pre, int[] post) &#123; return constructFromPrePostTrav(pre, post, 0, 0, pre.length);&#125;public TreeNode constructFromPrePostTrav(int[] pre, int[] post, int preLeft, int preRight, int N) &#123; if (N == 0) &#123; return null; &#125; TreeNode root = new TreeNode(pre[preLeft]); if (N == 1) &#123; return root; &#125; int L = 1; for (; L &lt; N; ++L) &#123; if (post[preRight + L - 1] == pre[preLeft + 1]) &#123; break; &#125; &#125; root.left = constructFromPrePostTrav(pre, post, preLeft + 1, preRight, L); root.right = constructFromPrePostTrav(pre, post, preLeft + L + 1, preRight + L, N-L-1); return root;&#125; 完全二叉树123456789101112131415161718192021222324public boolean isCompleteTree(TreeNode root) &#123; if (root == null) &#123; return true; &#125; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;(); queue.offer(root); int k = 0; while (!queue.isEmpty()) &#123; int len = queue.size(); for (int i = 0; i &lt; len; i++) &#123; TreeNode node = queue.poll(); if (node == null) &#123; k = 1; continue; &#125; if (k == 1 &amp;&amp; node != null) &#123; return false; &#125; queue.offer(node.left); queue.offer(node.right); &#125; &#125; return true;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"https://yaoyinglong.github.io/tags/算法/"},{"name":"树","slug":"树","permalink":"https://yaoyinglong.github.io/tags/树/"}],"categories":[{"name":"算法","slug":"算法","permalink":"https://yaoyinglong.github.io/categories/算法/"}]},{"title":"图基础","date":"2020-06-21T16:00:00.000Z","path":"Blog/算法/图基础/","text":"​ 图可分为有向图和无向图，一般用G=(V,E)来表示图，V表示顶点，E表示通过图的边，常用邻接矩阵或者邻接表来描述一副图。图的遍历算法，根据访问节点的顺序，可分为广度优先搜索（BFS：Breadth First Search）和深度优先搜索（DFS：Depth First Search），图的存储常用邻接矩阵和邻接表。 ​ 邻接矩阵是指用矩阵来表示图。它是采用矩阵来描述图中顶点之间的关系（及弧或边的权），通常采用两个数组来实现邻接矩阵：一个一维数组用来保存顶点信息，一个二维数组来用保存边的信息，邻接矩阵的缺点就是比较耗费空间。 ​ 邻接表是图的一种链式存储表示方法。它是改进后的邻接矩阵，它的缺点是不方便判断两个顶点之间是否有边，但是相对邻接矩阵来说更省空间。 ​ 一条边上的两个顶点叫做邻接点，有向图有入边（以该点为终点的边）和出边（以该点为起点的边）的概念。无向图中，某个顶点的度是邻接到该顶到的边的数目。有向图有入度和出度之分。 简单路径：一条路径上顶点不重复出现 简单回路：第一个顶点和最后一个顶点相同，其它各顶点都不重复的回路则是简单回路 连通图：对无向图而言，任意两顶点之间存在一条无向路径，则称该无向图为连通图。 对有向图而言，若图中任意两个顶点之间存在一条有向路径，则称该有向图为强连通图。 连通分量：非连通图中的各个连通子图称为该图的连通分量。 广度优先搜索（BFS）​ 广度优先搜索在进一步遍历图中顶点之前，先访问当前顶点的所有邻接结点。 首先选择一个顶点作为起始结点 将起始结点放入队列中 从队列首部选出一个顶点，并找出所有与之邻接的结点，将找到的邻接结点放入队列尾部 按照同样的方法处理队列中的下一个结点 深度优先搜索（DFS）​ 深度优先搜索在搜索过程中访问某个顶点后，需要递归地访问此顶点的所有未访问过的相邻顶点，和树的遍历比较类似，若初始状态是图中所有顶点均未被访问，则从某个顶点v出发，首先访问该顶点，然后依次从它的各个未被访问的邻接点出发深度优先搜索遍历图，直至图中所有和v有路径相通的顶点都被访问到。 若此时尚有其他顶点未被访问到，则另选一个未被访问的顶点作起始点，重复上述过程，直至图中所有顶点都被访问到为止。DFS在环监测和拓扑排序中都有不错的应用。","tags":[{"name":"图，算法","slug":"图，算法","permalink":"https://yaoyinglong.github.io/tags/图，算法/"}],"categories":[{"name":"算法","slug":"算法","permalink":"https://yaoyinglong.github.io/categories/算法/"}]},{"title":"幽默感","date":"2020-06-20T16:00:00.000Z","path":"Blog/自度/幽默感/","text":"","tags":[],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"数据库常面问题","date":"2020-06-18T16:00:00.000Z","path":"Blog/Interview/数据库常面问题/","text":"B+树的定义 InnoDB中的“页” InnoDB中主键索引生成过程 InnoDB中联合索引生成过程 索引实战与优化","tags":[],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"Spring常面问题","date":"2020-06-18T16:00:00.000Z","path":"Blog/Interview/Spring常面问题/","text":"1、Spring Boot、Spring MVC、Spring之间的区别？（Spring Boot本质是什么？） 2、Spring Boot Starter是什么？ 3、如何自定义Spring Boot Starter？（如何扩展Spring Boot） 4、Spring Boot的自动装配原理是什么？（源码分析哦） 5、Spring Boot的启动流程是什么？ 6、有没有看过Spring Boot源码？你觉得最神奇的地方是什么？ 7、Spring为什么用“三级缓存”去解决循环依赖？ 8、Spring中Bean的生命周期有哪些步骤？ 9、什么是BeanDefinition？它为什么非常重要？ 10、什么是Bean的后置处理器？ 11、什么是Bean工厂的后置处理器？ 12、什么是BeanFactory？它与ApplicationContext的区别？ 13、什么是FactoryBean？它与BeanFactory的区别？ 14、@Import、@Component、@Bean的区别是什么？ 15、什么是ImportBeanDefinitionRegistrar？它的作用是什么？ 16、springboot零配置的原理 17、springboot如何做到内嵌tomcat 18、springboot启动流程原理 19、常见面试考点SPI规范讲解","tags":[],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"Excel文件数据抽取","date":"2020-06-18T16:00:00.000Z","path":"Blog/Python/Excel文件数据抽取/","text":"本文仅仅是对Excel中的数据进行了简单的读取抽出并统一输出到指定的地方，在读取老版本xls文件的时候可能会出现编码的问题导致文件读取失败：1UnicodeDecodeError: 'utf-16-le' codec can't decode byte 0x40 in position 104: truncated data 可以通过对报错的源码unpack_unicode代码进行try-except并将其赋值为空。 1234try: strg = unpack_unicode(data, 0, lenlen=2) except: strg = \"\" 以下代码仅仅是遍历指定目录下的所有文件，之所以多写一重判断循环文件，是为了将第一层的文件夹名称生成一个新的sheet，第一级文件夹下的所有文件的数据都统计到当前文件夹名称所对应的sheet中，且对实际情况进行了简单的数据过滤和处理，在此仅仅是存储一个简单的模板，后续有其他的需求可在该模板上持续修改优化。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798# -*- coding: UTF-8 -*-import osimport openpyxlimport pandas as pdimport xlrddef find_value(basePath): fileDirs = os.listdir(basePath) dataAllValue = pd.DataFrame() for fileDir in fileDirs: childFile = os.path.join('%s%s%s' % (basePath, \"\\\\\", fileDir)) if os.path.isfile(childFile): if fileDir.endswith(\"xls\") or fileDir.endswith(\"xlsx\") or fileDir.endswith(\"XLS\") or fileDir.endswith(\"XLSX\"): colunm_count, sheetDataFrameValue = read_excel(childFile) if sheetDataFrameValue.empty: continue if colunm_count == 1: continue dataAllValue = dataAllValue.append(sheetDataFrameValue) if os.path.isdir(childFile): childDataFrameValue = find_value(childFile) dataAllValue = dataAllValue.append(childDataFrameValue) return dataAllValuedef read_excel(childFile): try: FileObj = xlrd.open_workbook(childFile) # 打开处理的excel文件 sheetNames = FileObj.sheet_names() except: print(\"有问题的文件：\", childFile) return 1, pd.DataFrame() i = 0 for sheetName in sheetNames: sheet = FileObj.sheets()[i] # 获取第一个工作表 i += 1 row_count = sheet.nrows # 行数 colunm_count = 0 sheetDataFrameValue = pd.DataFrame() for element in range(2, row_count): row_values = [cell_value_clear(cell_value) for cell_value in sheet.row_values(element)] for keyValue in keyValues: if keyValue.lower() in row_values: findCon = sheet.row_values(element) not_empty = [i for i in findCon if i != ''] if len(not_empty) &lt; 3: continue columnDf = pd.DataFrame(findCon) columnDf.rename(columns=&#123;0: colunm_count&#125;, inplace=True) if sheetDataFrameValue.empty: sheetDataFrameValue = columnDf.join(sheetDataFrameValue) else: sheetDataFrameValue = sheetDataFrameValue.join(columnDf) colunm_count += 1 return colunm_count, sheetDataFrameValuedef cell_value_clear(cell_value): if cell_value is None: return '' return str(cell_value).replace(\" \", \"\").lower()def write_excel_xlsx(dataFrameValue1, sheetName, excelName): newExcel = pd.DataFrame(dataFrameValue1) writer = pd.ExcelWriter(excelName, engine='openpyxl') is_file_exists = os.path.exists(excelName) # 判断文件是否存在 if is_file_exists is True: book = openpyxl.load_workbook(writer.path) writer.book = book newExcel.to_excel(excel_writer=writer, sheet_name=sheetName, encoding=\"utf-8\", index=False) writer.save() writer.close() else: newExcel.to_excel(excel_writer=writer, sheet_name=sheetName, encoding=\"utf-8\", index=False) writer.save() writer.close()def run(basePath): pathDirs = os.listdir(basePath) for path in pathDirs: provinceDataPath = os.path.join('%s%s%s' % (basePath, \"\\\\\", path)) print(provinceDataPath) if os.path.isdir(provinceDataPath): dataAllValue = find_value(provinceDataPath) print(dataAllValue) if dataAllValue.empty: continue write_excel_xlsx(dataAllValue, path, excelName)if __name__ == '__main__': # 文件路径 basePath = r\"F:\\data\" keyValues = [\"指标1\", \"指标2\", \"指标3\", \"指标4\"] excelName = 'F:\\抽取数据\\数据统计总览.xlsx' # 文件保存的路径 run(basePath)","tags":[{"name":"Python","slug":"Python","permalink":"https://yaoyinglong.github.io/tags/Python/"}],"categories":[{"name":"Python","slug":"Python","permalink":"https://yaoyinglong.github.io/categories/Python/"}]},{"title":"后悔药","date":"2020-05-25T16:00:00.000Z","path":"Blog/自度/后悔药/","text":"挽回心态​ 没有一个好的挽回心态，任何技巧都等于零，挽回是一个长期的过程，是一次真正的自我成长和救赎，是不是自己确实掌握了经营好感情的能力、是不是已经真正的获得了成长、是不是你们之间的根本问题已经得到了解决、是不是他真的重新爱上你了、是不是以后你们真的能好好的在一起了； 心态建设 最重要的一点控制你的挽回需求感，难度越大的任务，动机因素反而越敏感 避免过度自责 稳住心态。 不要手贱 转移注意力 不要把全部心思放在挽回上 那样只会让自己更苦逼。 充实自己的生活 提升自己。 反撇：前期阶段进行讨好策略（是的你没看错），然后突然后撤表示放弃，从而激发起对方损失厌恶的心理，变被动为主动，变低位为高位 思维重塑打破思维墙原因分析技巧举例","tags":[],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"和女孩子相处","date":"2020-05-25T16:00:00.000Z","path":"Blog/自度/和女孩子相处/","text":"多问对方的意见或建议，尽量给选项，或者让她推荐 认真你就输了 菜单，歌单，账单 话题 分享音乐 自建 培养自己的决断力和勇气，别总是回答：随便、都可以、都挺好等 尽量体现自己的爱心，让自己有更多的爱心和耐心，控制脾气和情绪。 提升自己的吸引力、让对方获得更多的舒适感、让对方投资更多 禁忌 聊天时不要抱着解决问题的思维 约会中不能没有主见 没有话题不要强聊，适可而止 别每天都是磨磨唧唧的，动不动先情绪爆表，遇事女生还没怎么样，就先焦虑的不行 尽量多的拿主意，别总是成为跟随着 犹豫不决，磨磨唧唧，反复纠结的，不是一个有魅力男人的行为 谨慎的和对方发生争吵，避免自己的负面情绪，尽量让自己不那么邋遢，控制发生关系的频率，婚前减少同居维系新鲜感 活动 猫咖 电玩城 射箭馆 逛宜家 湖边喂鱼 水族馆 看电影（私人影院） VR 唱歌 逛公园（浣花溪公园）","tags":[],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"自度","date":"2020-05-25T16:00:00.000Z","path":"Blog/自度/自度/","text":"人生不如意事常八九，不爱了或者爱而不得才是人生常态 人在道理面前，总以为自己明白了，但是只有被真正教训过才会知道明白，就像之前我被天气教育那样，把伞放家里下班的时候下雨，把伞放公司上班的时候下雨，最终我买了两把伞。以前我总以为真诚相待才是相处的根本，被教训过才发现，并不是这样，人与人是不同的，你认知里的真诚在别人眼里或许是污言秽语恶意中伤。 总是在第一经历某种痛苦或者说苦难的时候，是最煎熬的，也才会学会不要轻易的寄托 人总是在逆境中快速成长，才会对人生有所感悟 我是一个平凡孤独平凡且无趣的人，没有伟大的梦想，尽量热爱生活 渐渐的就发现没有什么特别热爱的东西了 其实我觉得人生最好的状态就是无欲无求，对任何事都不抱什么什么特别的期待 其实有一群经常一起玩的好朋友是真的很幸福。","tags":[],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"有关于你","date":"2020-05-25T16:00:00.000Z","path":"Blog/自度/有关于你/","text":"​ 我知道我们性格不是很合，但是我会尽我最大可能改变自己，之前我们的每一次的不愉快，我都有用心努力的记下来然后调整我自己，一点一点的去让我能和你相处得更好，我知道在和你相处得时候很多时候，表现的没有主见，但我也不是真的没有主见，只是对在意的人什么都可以接受，什么都可以妥协，最后一次吃饭你叫我点菜，我是想点我喜欢的，但是我在考虑我点的是不是你喜欢的，所以犹豫了很久。和你相处的每一个小细节，我都尽量在用心的记下来，犯过的错，我都会尽量不犯。当时你穿的开叉的裙子，然而我并没有意识到，靠窗会走光的问题，但是你说了后我在心里想，我下次和你一起的时候一定要首先注意这些。我一直想的是我会用心慢慢的去了解你，然后慢慢改变我自己，我是一个很容易向自己在意的人妥协，即使当时即使当时不能立马妥协，但也会慢慢妥协。我一直在努力的让自己变得更好，但是你没有给我足够的时间就放弃我了。 ​ 这段时间看了一些书及一些知乎上的文章，没有谈过恋爱的我过于直男，以前真的不觉得自己很直，一直觉得自己是一个很敏感很细心的人，以为很多事情都知道该怎么做，但其实我错了，我连最根本的和女孩子相处应该多征求女孩子的意见和建议都没有搞明白，而且比较贪婪，想要更多跟你相处在一起，以便跟你相处在一起索取更多快乐，没有意识到顾及你的感受。然后对比与你相处的点点滴滴，犯了好多好多致命的错误，难怪你会觉得和我相处很累，可能我都还没有学会该如何好好的去爱一个人，在爱情方面太幼稚了，不能很好的把控自己的情绪和心态，让你和我相处累觉不爱。这段时间一直不断的想起我说的那些的话，对待你的一些不恰当的地方，总觉得自己的沟通力太差了，明明是很在意很喜欢的，却总是在不经意间伤害。刚开始的时候，汪鑫把你们的聊天给我看了一些，知道你有多么为我考虑，对我多么好，我真的好感动，从来没有一个人对我这么好过，觉得遇见你我好幸运。我想我一定要把我所有的好所有的温柔都给你，当时就在跟汪鑫讲，要尽我最大的努力不让你在我这受到伤害，但是却没有做到。 ​ 时间过去了这么久了，但我感觉仿佛还是昨天，坐在电脑旁的时候总是不由自主的想起你坐在我旁边的情景，在每一处你停留的地方经过总是不受控制的想起，你当时每一个细微的表情和动作。厨房里你调特制拌酱的场景、厕所的镜子中你整理你新刘海的样子、客厅里玩游戏时你捧着脸笑的样子、一起肩并肩从小区到我上班必经的三叉路口，每次上下班经过的时候总会不由自主的忘一眼，仿佛还能看见当时我在路灯下和你等车冲你的车屁股挥手道别是的画面、一起去北门买菜买烟、第一次牵你的手的感觉、在乒乓球台那一块停留的画面、还有你的拥抱，一遍又一遍越刻越深。有些人总是等到失去后，才追悔莫及，才懂得珍惜。 ​ 刚开始以为自己不会那么难受，但是我错了，我以为我可能还没有喜欢你到很深的程度，但是这么长一段时间过去了，对你的感觉不仅仅没有变淡反而越来越强烈，只是没有像刚开始在表面针扎的那么剧烈了，而是向内心深处扎根了越扎越深，有时痛得难以入眠。其实我是一个优柔寡断人，5月13号当天和你说了那些装作满不在乎故作洒脱的狠话后，都没有坚强到正常下班，然后接下来的两周害怕极了一个人独处，因为总是不断的回想起有关于你的一切，虽然我们总共算起来也只是见过四次面，从4月11号第一次见面到5月10号最后一次见面，时间也只有短短的一个月，但是我总是会不由自主的想起你出现在我视线里的所有画面，每天上班下班都会经过第一次你过来找我一起走过的那条路，脑海里都会浮现出你我们一起散步的情景，深夜滴滴载着你回去的背影，心中总是隐隐作痛。我尝试着去忘记，各种方式去转移注意力，但是刚刚还一点点的时候，又被撕开，如此往复。原来你在我心中已经占据了如此总要的分量，这段时间我的天空失去了颜色，做什么事情总会觉得没什么意义。 ​ 我以为时间的磨盘会抚平我心中的沟壑，但是这段时间我总是在闲下来的时候，不由自主的想起你，在夜深人静的时候想起你，在早晨一醒来还没睁开眼睛是第一个念头想到的也是你，所以总是忍不住去一遍又一遍的打开网易云音乐看看你最近听什么歌，然后一遍又一遍的听，有时候你好多天都没有更新，每次打开都有些小失落。一遍又一遍点开你朋友圈看看你有没有更新动态，我很少去看与你的聊天记录，害怕自己受不了而奔溃，实在是扛不住了，又会忍不住去翻看，然后又是长时间的自闭，或者通过微信去骚扰你。但每次找你心中有千言万语但却又不知道该说些什么好，而每次找你，隔着屏幕也能感觉到你不是很想理睬我，我也只敢每次简单强聊几句，但是也略微满足。 ​ 回想起第一次见面时的场景，对于你这个陌生人，而且在汪鑫说要将你介绍给我认识的前提下，我有点不自然，可能是源于我从小认识和接触的女性极少的缘故，所以第一次见面我表现的对你不理不睬满不在乎，其实总是在偷偷注意，在吃火锅的时候感觉你都没咋吃，然后又去上了一趟厕所，包括你要过苏苏手中的烟，问是什么牌子，然后KTV唱歌的时候偷偷关注你唱歌时的模样，然后后面的时候你出去了好多次，有一次时间还比较长，我还以为你走了呢，然后后面的时候你问我脖子上戴的是什么，让我有点小高兴，但还是故作冷漠和平静，第一次对你的印象感觉你是一个很文静斯文的人，而且说话也比较直爽，是我很喜欢的类型。 ​ 但我以为仅此而已，然后在他们的怂恿下我加了你的微信，看到你头像的时候我笑了，更加觉得你是一个真实直爽的人，当时虽然没有聊两句，但是聊起来很舒服，没多少刻意，但是即使那一刻我依然认为应该不怎么会有后续，因为我是一个不自信不主动的人，以为和之前朋友介绍的人一样，只是刚加微信的时候能唠几句，然后就没有然后了； ​ 但我没想到的是你居然主动找我，我高兴坏了。接下来的聊天是我从未有过的体验，那段时间几乎每天都会半夜不由自主的醒来，然后第一个念头就是你，然后久久难以平静下来再次入眠，那段时间毫不夸张的说真的是睡着都笑醒，你是我那段时间唯一的快乐源泉，跟你相处我是真的好开心，想要时时刻刻的靠近你。然后琪琪说我终于进入简单模式了，和你相处的时间，虽然很多时候只是隔着屏幕聊天，但是我能感受得到你总是很为我着想，很体贴，对我真的很好，我是一个很容易被感动的人，好多次想到你有点不由自主的泪光闪烁，然后将头仰起45度角，那时候我更加坚定不能伤害到你，但是最终我还是没有做到，至少说让你有时候很不开心。 ​ 第一次你过来找我的时候，我真的好开心好感动，不喜欢舟车劳顿的你，还这么远跑过来找我，和你玩游戏的时候我真的好开心，你好细心，其实当你说要给我买生日礼物的时候我就多少有点猜到你多半会买一把刀，但是没有想到你会买一个油壶，但是我又注意到你不是很喜欢油腻的食物，所以我那段时间也在尽量的想我应该做些什么不油腻又好吃的菜给你；最开心的是游戏结束后，他们说要走了，你说你留下来帮我洗碗，我还直男的赶你走，我因此懊恼了很久；下楼后我以为你也会马上走，结果你没有你说一起走一走，你不知道我有多开心，然后你还存了我的手机号码，那一天我真的好开心。 ​ 你第二次过来找我，是我最最最开心的了，你还给我买了小发糕，还和你一起做饭，饭后逛小区，在牵你手的那一刻我真的好开心你没有拒绝，感觉和你的亲密程度一下子拉近了好多。在看可娄的时候，你说的那句要吃鸭鸭，我是真的好喜欢，然后送出了我人生中的第一捧花，和第一次那么拥抱一个女孩，你真的好体贴，下楼等车的时候，有点冷你主动靠近我，帮我遮挡寒冷，那时候我冰冷很多年的心一瞬间熊熊燃烧了起来。但是现在想想我好后悔，如果我当时跟你告白是不是现在结局不一样了呢，真的很讨厌犹犹豫豫畏畏缩缩的自己。 ​ 然后接下来的接二连三的不愉快让我搓手不及，之前两次都是说的我周末去找你的，但是我没有明白你意思，你用你来找我换我用不找你，周末和他们去吃烧烤你没有来，我好失落，而且你也不让我去找你，这其实算是第一次和第二次不愉快的导火索，所以我总想着要去找你一次，才能对得起你大老远舟车劳顿过来找我，可能我有点大男子主义吧，我觉得我应该是主动去找你的那个人，因为感觉上是一直你在为我付出，我想我一定要比你付出的更多才对。然后第二次你又是用你来找我换我不用去找你，但是我还是没有明白你用意，所以又头铁了一把惹得你不开心。也是因为这个我没有坚定把车票退掉留下来和你一起过五一的原因，可能是我内心深处的一点点可笑的自尊和骄傲吧。然后我感觉五一回去后，感觉我们之间的距离一下就远了好多，这种反差让我很难受，所以怄气的我导致第三次不愉快。 ​ 其实在最后一次见面前的那次不愉快后，你说和我相处很累，我知道问题已经很严重了，那一次我感觉我仿佛真的要失去你了，晚上的时候我发了很多信息给你，那些信息是我哭着抱着恐惧的心理写下来的，我知道我有一些问题，那几天花得最多的时间是到知乎上去学习该怎么和女孩子相处，相处应该避免哪些，还买了几本书，准备好好学习学习，但是还没来得及……，你就放弃我了。我真的很气，为什么在我遇到你的时候，从来没有这么忙的工作，突然一下子特别忙，如果不是第一次自己头铁惹你生气，是不是不会有后面的几次不愉快，我多半也会毫不犹豫的把回家的票退掉留下来和你一起过五一，也不会出现最后一次的不愉快。一直在想要是多给我一点时间该多好。 ​","tags":[],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"排序算法","date":"2020-05-24T16:00:00.000Z","path":"Blog/算法/排序算法/","text":"十种常见的排序算法可分为比较类排序和非比较类排序。比较类排序通过比较来决定元素间的相对次序，由于其时间复杂度不能突破O(nlogn)，因此也称为非线性时间比较类排序；非比较类排序不通过比较来决定元素间的相对次序，可以突破基于比较排序的时间下界，也称为线性时间非比较类排序。 算法类比 排序算法 时间复杂度（平均） 时间复杂度（最坏） 时间复杂度（最好） 空间复杂度 稳定性 冒泡排序 O(n^2) O(n^2) O(n) O(1) 稳定 选择排序 O(n^2) O(n^2) O(n^2) O(1) 不稳定 快速排序 O(nlog2^n) O(n^2) O(nlog2^n) O(nlog2^n) 不稳定 插入排序 O(n^2) O(n^2) O(n) O(1) 稳定 希尔排序 O(n^1.3) O(n^2) O(n) O(1) 不稳定 堆排序 O(nlog2^n) O(nlog2^n) O(nlog2^n) O(1) 不稳定 归并排序 O(nlog2^n) O(nlog2^n) O(nlog2^n) O(n) 稳定 计数排序 O(n + k) O(n + k) O(n + k) O(n + k) 稳定 桶排序 O(n + k) O(n^2) O(n) O(n + k) 稳定 基数排序 O(n * k) O(n * k) O(n * k) O(n + k) 稳定 冒泡排序比较两个相邻的元素，将值大或者小的的元素交换到一边。 1234567891011121314public void bubblerSort(Integer[] arr) &#123; boolean flag = true; for (int i = 0; i &lt; arr.length &amp;&amp; flag; i++) &#123; flag = false; for (int j = arr.length - 1; j &gt; i; j--) &#123; if (arr[j - 1] &gt; arr[j]) &#123; int temp = arr[j]; arr[j] = arr[j - 1]; arr[j - 1] = temp; flag = true; &#125; &#125; &#125;&#125; 选择排序在待排序的一组数据中，选出最小（最大）的一个数与第一个位置的数交换，然后在剩下的数中，再找最小（最大）的数与第二个位置的数交换位置，依次类推，直到第N-1个元素与第N个元素交换位置，选择排序结束。 12345678910111213141516public void selectSort(Integer[] arr) &#123; int index; for (int i = 0; i &lt; arr.length; i++) &#123; index = i; for (int k = i + 1; k &lt; arr.length; k++) &#123; if (arr[index] &gt; arr[k]) &#123; index = k; &#125; &#125; if (i != index) &#123; int temp = arr[i]; arr[i] = arr[index]; arr[index] = temp; &#125; &#125;&#125; 快速排序随机找出一个数，可以随机取，也可以取固定位置，一般是取第一个或最后一个称为基准，比基准小的交换到左边，比基准大的交换到右边，交换完左边都是比基准小的，右边都是比较基准大的，这样就将一个数组分成了两个子数组，然后再按照同样的方法把子数组再分成更小的子数组，直到不能分解为止。 123456789101112131415161718public void quickSort(Integer[] arr, int left, int right) &#123; if (left &lt; right) &#123; int dl = left, dr = right, pivot = arr[left]; while (dl &lt; dr) &#123; while (dl &lt; dr &amp;&amp; arr[dr] &gt; pivot) dr--; if (dl &lt; dr) arr[dl++] = arr[dr]; while (dl &lt; dr &amp;&amp; arr[dl] &lt; pivot) dl++; if (dl &lt; dr) arr[dr--] = arr[dl]; &#125; arr[dl] = pivot; quickSort(arr, left, dl - 1); quickSort(arr, dl + 1, right); &#125;&#125; 插入排序把n个待排序的元素看成为一个有序表和一个无序表。开始时有序表中只包含1个元素，无序表中包含有n-1个元素，排序过程中每次从无序表中取出第一个元素，将它插入到有序表中的适当位置，使之成为新的有序表，重复n-1次可完成排序过程。 1234567891011121314151617public void insertSort(Integer[] arr) &#123; int j, k; for (int i = 1; i &lt; arr.length; i++) &#123; for (j = i - 1; j &gt;= 0; j--) &#123; if (arr[i] &gt; arr[j]) &#123; break; &#125; &#125; if (j != i - 1) &#123; int temp = arr[i]; for (k = i - 1; k &gt; j; k--) &#123; arr[k + 1] = arr[k]; &#125; arr[k + 1] = temp; &#125; &#125;&#125; 希尔排序希尔排序(Shell Sort)是插入排序的一种，它是针对直接插入排序算法的改进。该方法又称缩小增量排序。实质上是一种分组插入方法。 对于n个待排序的数列，取一个小于n的整数gap(gap被称为步长)将待排序元素分成若干个组子序列，所有距离为gap的倍数的记录放在同一个组中；对各组内的元素进行直接插入排序。 这一趟排序完成之后，每一个组的元素都是有序的。然后减小gap的值，并重复执行上述的分组和排序。重复这样的操作，当gap=1时，整个数列就是有序的。 123456789101112131415161718public void shellSort(Integer[] arr) &#123; int i, j, gap; for (gap = arr.length / 2; gap &gt; 0; gap /= 2) &#123; for (i = 0; i &lt; gap; i++) &#123; for (j = i + gap; j &lt; arr.length; j += gap) &#123; if (arr[j] &lt; arr[j - gap]) &#123; int temp = arr[j]; int k = j - gap; while (k &gt;= 0 &amp;&amp; arr[k] &gt; temp) &#123; arr[k + gap] = arr[k]; k -= gap; &#125; arr[k + gap] = temp; &#125; &#125; &#125; &#125;&#125; 堆排序初始化堆：将数列a[1…n]构造成最大堆。交换数据：将a[1]和a[n]交换，使a[n]是a[1…n]中的最大值；然后将a[1…n-1]重新调整为最大堆。 接着，将a[1]和a[n-1]交换，使a[n-1]是a[1…n-1]中的最大值；然后将a[1…n-2]重新调整为最大值。 依次类推，直到整个数列都是有序的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public void heapSortAsc(Integer[] arr, int n) &#123; for (int start = n / 2 - 1; start &gt;= 0; start--) &#123; maxHeapDown(arr, start, n - 1); &#125; for (int index = n - 1; index &gt; 0; index--) &#123; int temp = arr[0]; arr[0] = arr[index]; arr[index] = temp; maxHeapDown(arr, 0, index - 1); &#125;&#125;public void maxHeapDown(Integer[] arr, int start, int end) &#123; int left = 2 * start + 1; int tmp = arr[start]; for (; left &lt;= end; start = left, left = 2 * left + 1) &#123; if (left &lt; end &amp;&amp; arr[left] &lt; arr[left + 1]) &#123; left++; &#125; if (tmp &gt;= arr[left]) &#123; break; &#125; arr[start] = arr[left]; arr[left] = tmp; &#125;&#125;public void heapSortDesc(Integer[] arr, int n) &#123; for (int start = n / 2 - 1; start &gt;= 0; start--) &#123; minHeapDown(arr, start, n - 1); &#125; for (int index = n - 1; index &gt; 0; index--) &#123; int tmp = arr[0]; arr[0] = arr[index]; arr[index] = tmp; minHeapDown(arr, 0, index - 1); &#125;&#125;public void minHeapDown(Integer[] arr, int start, int end) &#123; int left = 2 * start + 1; int tmp = arr[start]; for (; left &lt;= end; start = left, left = 2 * left + 1) &#123; if (left &lt; end &amp;&amp; arr[left] &gt; arr[left + 1]) &#123; left++; &#125; if (tmp &lt;= arr[left]) &#123; break; &#125; arr[start] = arr[left]; arr[left] = tmp; &#125;&#125; 归并排序将两个的有序数列合并成一个有序数列，归并排序包括从上往下和从下往上两种方式。 从下往上：将待排序的数列分成若干个长度为1的子数列，然后将这些数列两两合并；得到若干个长度为2的有序数列，再将这些数列两两合并；得到若干个长度为4的有序数列，再将它们两两合并；直接合并成一个数列为止。 从上往下：它与从下往上在排序上是反方向的，它基本包括3步： 分解：将当前区间一分为二，即求分裂点 mid = (low + high)/2 求解：递归对两个子区间a[low...mid]和a[mid+1...high]归并排序。递归终结条件是子区间长度为1 合并：将已排序的两个子区间a[low...mid]和 a[mid+1...high]归并为一个有序的区间a[low...high] 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public void mergeSortUp2Down(Integer[] arr, int start, int end) &#123; if (arr == null || start &gt;= end) &#123; return; &#125; int mid = (start + end) / 2; mergeSortUp2Down(arr, start, mid); mergeSortUp2Down(arr, mid + 1, end); merge(arr, start, mid, end);&#125;public void mergeSortDown2Up(Integer[] arr, int len) &#123; if (arr == null || len &lt; 0) &#123; return; &#125; for (int n = 1; n &lt; len; n *= 2) &#123; mergeGroups(arr, len, n); &#125;&#125;void mergeGroups(Integer[] arr, int len, int gap) &#123; int i; for (i = 0; i + 2 * gap - 1 &lt; len; i += 2 * gap) &#123; merge(arr, i, i + gap - 1, i + 2 * gap - 1); &#125; if (i + gap - 1 &lt; len - 1) &#123; merge(arr, i, i + gap - 1, len - 1); &#125;&#125;public void merge(Integer[] arr, int start, int mid, int end) &#123; int[] temp = new int[end - start + 1]; int i = start; int j = mid + 1; int k = 0; while (i &lt;= mid &amp;&amp; j &lt;= end) &#123; if (arr[i] &lt;= arr[j]) &#123; temp[k++] = arr[i++]; &#125; else &#123; temp[k++] = arr[j++]; &#125; &#125; while (i &lt;= mid) &#123; temp[k++] = arr[i++]; &#125; while (j &lt;= end) &#123; temp[k++] = arr[j++]; &#125; for (i = 0; i &lt; k; i++) &#123; arr[start + i] = temp[i]; &#125;&#125; 桶排序将数组分到有限数量的桶子里。数组arr数据范围为[0, max)，创建容量为max的桶数组buckets，遍历数组arr将其值作为数组下标，再遍历桶数组得到有序数组。 1234567891011public void bucketSort(Integer[] arr, int n, int max) &#123; int[] buckets = new int[max]; for (int index = 0; index &lt; n; index++) &#123; buckets[arr[index]]++; &#125; for (int bucketIndex = 0, arrIndex = 0; bucketIndex &lt; max; bucketIndex++) &#123; while (buckets[bucketIndex]-- &gt; 0) &#123; arr[arrIndex++] = bucketIndex; &#125; &#125;&#125; 基数排序基数排序是桶排序的扩展，将整数按位数切割成不同的数字，然后按每个位数分别比较。将所有待比较数值统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后, 数列就变成一个有序序列。 12345678910111213141516171819202122232425262728293031323334353637public void radixSort(Integer[] arr) &#123; int max = getMax(arr); for (int exp = 1; max / exp &gt; 0; exp *= 10) &#123; countSort(arr, exp); &#125;&#125;public void countSort(Integer[] arr, int exp) &#123; int[] output = new int[arr.length]; int[] buckets = new int[10]; for (int index = 0; index &lt; arr.length; index++) &#123; buckets[arr[index] / exp % 10]++; &#125; for (int index = 1; index &lt; 10; index++) &#123; buckets[index] += buckets[index - 1]; &#125; for (int index = arr.length - 1; index &gt;= 0; index--) &#123; output[buckets[arr[index] / exp % 10] - 1] = arr[index]; buckets[arr[index] / exp % 10]--; &#125; for (int index = 0; index &lt; arr.length; index++) &#123; arr[index] = output[index]; &#125;&#125;public int getMax(Integer[] arr) &#123; int max = arr[0]; for (int i = 1; i &lt; arr.length; i++) &#123; if (arr[i] &gt; max) &#123; max = arr[i]; &#125; &#125; return max;&#125;","tags":[{"name":"算法，排序","slug":"算法，排序","permalink":"https://yaoyinglong.github.io/tags/算法，排序/"}],"categories":[{"name":"算法","slug":"算法","permalink":"https://yaoyinglong.github.io/categories/算法/"}]},{"title":"Java中调用Groovy脚本","date":"2019-12-24T16:00:00.000Z","path":"Blog/Java/工具/Java中调用Groovy脚本/","text":"Groovy是构建在JVM上的一个轻量级动态语言，其是Java实现的，与Java语法类是，能很好的与Java代码结合，及扩展现有代码。 Java在语音动态性方面只能通过反射，且参数传递格式很严格不是很灵活，而Groovy是构建在JVM上的一个轻量级动态语言，其是Java实现的，与Java语法类是，能很好的与Java代码结合，及动态扩展现有代码。 Java中可以通过GroovyScriptEngine、GroovyClassLoader、GroovyShell、ScriptEngineManager等方式调用Groovy，以及在实际项目中的运用。Maven依赖： 123456&lt;dependency&gt; &lt;groupId&gt;org.codehaus.groovy&lt;/groupId&gt; &lt;artifactId&gt;groovy-all&lt;/artifactId&gt; &lt;version&gt;$&#123;groovy.version&#125;&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt;&lt;/dependency&gt; GroovyScriptEngine从指定的位置（文件系统，URL，数据库等）加载Groovy脚本，并且随着脚本变化而重新加载。在相互关联的多个脚本情况下使用GroovyScriptEngine更好些。 1234567GroovyScriptEngine engine = new GroovyScriptEngine(\"src/test/resources/groovy/\");Map&lt;String, Object&gt; param = new HashMap&lt;&gt;();param.put(\"id\", \"KKKKKKKKKKKKKK\");param.put(\"aa\", 45);Binding binding = new Binding(param);Object result = engine.run(\"Mixed.groovy\", binding); GroovyClassLoaderGroovyClassLoader是一个定制的类装载器，负责解释加载Java类中用到的Groovy类。 123456789GroovyClassLoader loader = new GroovyClassLoader();Class aClass = loader.parseClass(new File(\"src/test/resources/groovy/Mixed.groovy\"));try &#123; GroovyObject instance = (GroovyObject) aClass.newInstance(); Object result = instance.invokeMethod(\"Mixed\", new Object[]&#123;\"KKKKKKKKKKKKKK\", 45&#125;); System.out.println(result);&#125; catch (Exception e) &#123; e.printStackTrace();&#125; GroovyShellGroovyShell允许在Java类甚至Groovy类中求任意Groovy表达式的值。可用Binding对象输入参数给表达式，并最终通过GroovyShell返回Groovy表达式的计算结果。多用于推求独立的脚本或表达式。 即使使用GroovyShell也有多种实现方式，使用invokeMethod方法调用： 12345678GroovyShell loader = new GroovyShell();Script script = loader.parse(new File(\"src/test/resources/groovy/Mixed.groovy\"));try &#123; Object result = script.invokeMethod(\"Mixed\", new Object[]&#123;\"KKKKKKKKKKKKKK\", 45&#125;); System.out.println(result);&#125; catch (Exception e) &#123; e.printStackTrace();&#125; 通过GroovyShell得evaluate方式直接调用脚本： 12345678910111213Map&lt;String, Object&gt; param = new HashMap&lt;&gt;();param.put(\"id\", \"KKKKKKKKKKKKKK\");param.put(\"aa\", 45);param.put(\"bb\", 55L);param.put(\"cc\", 9.9999);Binding binding = new Binding(param);GroovyShell loader = new GroovyShell(binding);try &#123; Object result = loader.evaluate(\"return id + (aa + bb + cc)\"); System.out.println(result);&#125; catch (Exception e) &#123; e.printStackTrace();&#125; 通过InvokerHelper类来调用： 123456789101112Map&lt;String, Object&gt; param = new HashMap&lt;&gt;();param.put(\"id\", \"KKKKKKKKKKKKKK\");param.put(\"aa\", 45);param.put(\"bb\", 55L);param.put(\"cc\", 9.9999);Binding binding = new Binding(param);GroovyShell shell = new GroovyShell();Script script = shell.parse(new File(\"src/test/resources/groovy/Mixed.groovy\"));Object result = InvokerHelper.createScript(script.getClass(), binding).run();System.out.println(result); 还可以通过GroovyShell来直接parse脚本内容： 123456789101112131415Map&lt;String, Object&gt; param = new HashMap&lt;&gt;();param.put(\"id\", \"KKKKKKKKKKKKKK\");param.put(\"aa\", 45);param.put(\"bb\", 55L);param.put(\"cc\", 9.9999);Binding binding = new Binding(param);GroovyShell shell = new GroovyShell();Script script = shell.parse(\"def Mixed(String id, int aa, Long bb, double cc) &#123;\\n\" + \" return id + (aa + bb + cc)\\n\" + \"&#125;\\n\" + \"Mixed(id, aa, bb, cc)\");Object result = InvokerHelper.createScript(script.getClass(), binding).run();System.out.println(result); ScriptEngineManager1234567891011ScriptEngineManager manager = new ScriptEngineManager();ScriptEngine engine = manager.getEngineByName(\"groovy\");Bindings binding = engine.createBindings();binding.put(\"id\", \"KKKKKKKKKKKKKK\");binding.put(\"aa\", 45);binding.put(\"bb\", 55L);binding.put(\"cc\", 9.9999);Object result = engine.eval(\"return id + (aa + bb + cc)\", binding);System.out.println(result); 集成常见问题使用GroovyShell的parse方法导致perm区爆满的问题若应用中内嵌Groovy引擎，会动态执行传入的表达式并返回执行结果，而Groovy每执行一次脚本，都会生成一个脚本对应的class对象，并new一个InnerLoader去加载这个对象，而InnerLoader和脚本对象都无法在gc的时候被回收运行一段时间后将perm占满，一直触发fullgc。 对于同一个Groovy脚本，Groovy执行引擎都会不同的命名，且命名与时间戳有关。当传入text时，class对象的命名规则为：&quot;script&quot; + System.currentTimeMillis() + Math.abs(text.hashCode()) + &quot;.groovy&quot;。这就导致就算Groovy脚本未发生任何变化，每次执行parse方法都会新生成一个脚本对应的class对象，且由GroovyClassLoader进行加载，不断增大perm区。 JVM中的Class只有满足以下三个条件，才能被GC回收，也就是该Class被卸载： 该类所有的实例都已经被GC，也就是JVM中不存在该Class的任何实例； 加载该类的ClassLoader已经被GC； 该类的java.lang.Class对象没有在任何地方被引用，如不能在任何地方通过反射访问该类的方法。 在GroovyClassLoader代码中有一个class对象的缓存，每次编译脚本时都会在Map中缓存这个对象，即：setClassCacheEntry(clazz)。每次groovy编译脚本后，都会缓存该脚本的Class对象，下次编译该脚本时，会优先从缓存中读取，这样节省掉编译的时间。这个缓存的Map由GroovyClassLoader持有，key是脚本的类名，这就导致每个脚本对应的class对象都存在引用，无法被GC清理掉。","tags":[{"name":"Groovy","slug":"Groovy","permalink":"https://yaoyinglong.github.io/tags/Groovy/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"工具","slug":"Java/工具","permalink":"https://yaoyinglong.github.io/categories/Java/工具/"}]},{"title":"国债逆回购","date":"2019-12-09T16:00:00.000Z","path":"Blog/理财/国债逆回购/","text":"购买技巧 每到年中，年底，长的节假日前，国债逆回购利息都会比较高 国债逆回购收益最高一般出现在节假日前的第二天，一般是周四，此时逆回购收益是最高的 每年1月初的市场资金面通常会比较宽松","tags":[],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"基金基本知识总结","date":"2019-12-05T16:00:00.000Z","path":"Blog/理财/基金基本知识总结/","text":"指数基金 上证 50：主要投资大型企业， 50 是代表它所投资企业的数量 沪深 300：主要投资中大型企业，是国内影响力最大、最重要的指数基金，沪深300是从上海和深圳两个交易所中挑选最大的300家大型企业 中证 500：主要投资中小型企业 创业版：主要投资小型企业，专门投资小型企业门槛更低的上市市场，一些当前规模不够大，盈利不够好，达不到主板上市的要求创业板 红利指数：主要投资高分红企业，现金分红：股票的股息，指业绩比较好的公司， 会每年从公司的净利润当中抽出一部分，以现金分红的方式回馈给股东通过持有几十只现金分红比较高的股票，来获取更高的收益.","tags":[],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"Maven加密JAR包","date":"2019-10-27T16:00:00.000Z","path":"Blog/Maven/Maven加密JAR包/","text":"在某些情况下可能会需要将JAR包提供给第三方使用，但又不想泄露源码，可以对架包进行加密处理。可以使用xjar-maven-plugin插件对生成得JAR进行加密，Maven配置如下： 1234567891011121314151617181920212223&lt;plugin&gt; &lt;groupId&gt;com.github.core-lib&lt;/groupId&gt; &lt;artifactId&gt;xjar-maven-plugin&lt;/artifactId&gt; &lt;version&gt;v2.0.6&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;goals&gt; &lt;goal&gt;build&lt;/goal&gt; &lt;/goals&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;configuration&gt; &lt;password&gt;7nBHK8bKB6&lt;/password&gt; &lt;includes&gt; &lt;include&gt;com/icloud/**&lt;/include&gt; &lt;/includes&gt; &lt;sourceDir&gt;$&#123;outputDirectory&#125;&lt;/sourceDir&gt; &lt;sourceJar&gt;$&#123;finalName&#125;.jar&lt;/sourceJar&gt; &lt;targetDir&gt;$&#123;assembly.outputDirectory&#125;&lt;/targetDir&gt; &lt;targetJar&gt;$&#123;finalName&#125;-encrypted.jar&lt;/targetJar&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 在执行JAR包时，需要在启动命令中加入--xjar.password=7nBHK8bKB6命令进行解密，否则JAR包将不能正常启动。","tags":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/tags/Maven/"},{"name":"加密","slug":"加密","permalink":"https://yaoyinglong.github.io/tags/加密/"}],"categories":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/categories/Maven/"}]},{"title":"Maven个性化打包","date":"2019-10-27T16:00:00.000Z","path":"Blog/Maven/Maven个性化打包/","text":"在某些场景下，比如有N个产品，经常需要从这N个产品中抽取M个产品打包运行。而且每个产品都会持续迭代。若是将每个产品都写成一个项目会出现大量得重复代码，而且打包时需要打成多个包，会对客户造成困扰。为了解决这种场景可以使用maven-assembly-plugin插件自定义打包结构及定制依赖项将需要得class打进包中即可。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt; &lt;mainClass&gt;com.icloud.CusMainApplication&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-jar&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt;&lt;!-- 只运行一次 --&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;skipAssembly&gt;false&lt;/skipAssembly&gt; &lt;appendAssemblyId&gt;false&lt;/appendAssemblyId&gt; &lt;finalName&gt;$&#123;assembly.finalName&#125;&lt;/finalName&gt; &lt;descriptors&gt; &lt;!--描述文件路径--&gt; &lt;descriptor&gt;$&#123;project.basedir&#125;/common_jar.xml&lt;/descriptor&gt; &lt;/descriptors&gt; &lt;outputDirectory&gt;$&#123;project.build.directory&#125;&lt;/outputDirectory&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;make-tar&lt;/id&gt; &lt;phase&gt;install&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt;&lt;!-- 只运行一次 --&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;skipAssembly&gt;false&lt;/skipAssembly&gt; &lt;appendAssemblyId&gt;false&lt;/appendAssemblyId&gt; &lt;finalName&gt;$&#123;assembly.finalName&#125;&lt;/finalName&gt; &lt;descriptors&gt; &lt;!--描述文件路径--&gt; &lt;descriptor&gt;$&#123;project.basedir&#125;/common_tar.xml&lt;/descriptor&gt; &lt;/descriptors&gt; &lt;outputDirectory&gt;$&#123;project.build.directory&#125;&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; make-jar是通过描述文件将项目打成JAR包，make-tar是为了将JAR包、配置文件、sh脚本等打成tar包。 common_jar.xml脚本示例： 123456789101112131415161718192021222324252627282930313233343536&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;assembly xmlns=\"http://maven.apache.org/ASSEMBLY/1.1.2\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/ASSEMBLY/1.1.2 http://maven.apache.org/xsd/assembly-1.1.2.xsd\"&gt; &lt;id&gt;TestAssembly&lt;/id&gt; &lt;formats&gt; &lt;format&gt;jar&lt;/format&gt; &lt;/formats&gt; &lt;!-- 改为false不会出现两层相同的目录 --&gt; &lt;includeBaseDirectory&gt;false&lt;/includeBaseDirectory&gt; &lt;fileSets&gt; &lt;!-- Main --&gt; &lt;fileSet&gt; &lt;directory&gt;$&#123;project.basedir&#125;\\..\\target\\classes&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;com\\icloud\\CusMainApplication.class&lt;/include&gt; &lt;/includes&gt; &lt;outputDirectory&gt;/&lt;/outputDirectory&gt; &lt;/fileSet&gt; &lt;!-- resources --&gt; &lt;fileSet&gt; &lt;directory&gt;$&#123;project.basedir&#125;\\..\\target\\classes&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;rs\\test_rs.csv&lt;/include&gt; &lt;/includes&gt; &lt;outputDirectory&gt;/&lt;/outputDirectory&gt; &lt;/fileSet&gt; &lt;/fileSets&gt; &lt;dependencySets&gt; &lt;dependencySet&gt; &lt;outputDirectory&gt;lib&lt;/outputDirectory&gt; &lt;useProjectArtifact&gt;true&lt;/useProjectArtifact&gt; &lt;unpack&gt;true&lt;/unpack&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependencySet&gt; &lt;/dependencySets&gt;&lt;/assembly&gt; common_tar.xml脚本示例： 1234567891011121314151617181920212223242526272829303132333435363738&lt;assembly xmlns=\"http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.2\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.2 http://maven.apache.org/xsd/assembly-1.1.2.xsd\"&gt; &lt;id&gt;bundle&lt;/id&gt; &lt;formats&gt; &lt;format&gt;tar.gz&lt;/format&gt; &lt;/formats&gt; &lt;includeBaseDirectory&gt;false&lt;/includeBaseDirectory&gt; &lt;fileSets&gt; &lt;fileSet&gt; &lt;directory&gt;$&#123;project.basedir&#125;/src/main/resources/&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;application.yml&lt;/include&gt; &lt;include&gt;application-prod.yml&lt;/include&gt; &lt;include&gt;log4j2-prod.xml&lt;/include&gt; &lt;/includes&gt; &lt;outputDirectory&gt;/config&lt;/outputDirectory&gt; &lt;/fileSet&gt; &lt;!-- scripts --&gt; &lt;fileSet&gt; &lt;directory&gt;$&#123;project.basedir&#125;/src/main/resources/&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;run.sh&lt;/include&gt; &lt;/includes&gt; &lt;fileMode&gt;0755&lt;/fileMode&gt; &lt;outputDirectory&gt;/&lt;/outputDirectory&gt; &lt;/fileSet&gt; &lt;!-- executable jar --&gt; &lt;fileSet&gt; &lt;directory&gt;$&#123;project.build.directory&#125;/&lt;/directory&gt; &lt;outputDirectory&gt;/&lt;/outputDirectory&gt; &lt;includes&gt; &lt;include&gt;$&#123;assembly.finalName&#125;.jar&lt;/include&gt; &lt;/includes&gt; &lt;fileMode&gt;0755&lt;/fileMode&gt; &lt;/fileSet&gt; &lt;/fileSets&gt;&lt;/assembly&gt; 若在SpringBoot项目中遇到使用Log4j2的情况，以上配置能完成打包，但是在运行的时候会出现由于日志配置文件解析不了导致项目启动失败。这时需要用到另一个插件maven-shade-plugin对架包种得Log4j2进行处理。 12345678910111213141516171819202122232425262728293031323334ERROR StatusLogger Unrecognized format specifier [d]ERROR StatusLogger Unrecognized conversion specifier [d] starting at position 16 in conversion pattern.ERROR StatusLogger Unrecognized format specifier [thread]ERROR StatusLogger Unrecognized conversion specifier [thread] starting at position 25 in conversion pattern.ERROR StatusLogger Unrecognized format specifier [level]ERROR StatusLogger Unrecognized conversion specifier [level] starting at position 35 in conversion pattern.ERROR StatusLogger Unrecognized format specifier [logger]ERROR StatusLogger Unrecognized conversion specifier [logger] starting at position 47 in conversion pattern.ERROR StatusLogger Unrecognized format specifier [msg]ERROR StatusLogger Unrecognized conversion specifier [msg] starting at position 54 in conversion pattern.ERROR StatusLogger Unrecognized format specifier [n]ERROR StatusLogger Unrecognized conversion specifier [n] starting at position 56 in conversion pattern.ERROR StatusLogger Unrecognized format specifier [d]ERROR StatusLogger Unrecognized conversion specifier [d] starting at position 16 in conversion pattern.ERROR StatusLogger Unrecognized format specifier [thread]ERROR StatusLogger Unrecognized conversion specifier [thread] starting at position 25 in conversion pattern.ERROR StatusLogger Unrecognized format specifier [level]ERROR StatusLogger Unrecognized conversion specifier [level] starting at position 35 in conversion pattern.ERROR StatusLogger Unrecognized format specifier [logger]ERROR StatusLogger Unrecognized conversion specifier [logger] starting at position 47 in conversion pattern.ERROR StatusLogger Unrecognized format specifier [msg]ERROR StatusLogger Unrecognized conversion specifier [msg] starting at position 54 in conversion pattern.ERROR StatusLogger Unrecognized format specifier [n]ERROR StatusLogger Unrecognized conversion specifier [n] starting at position 56 in conversion pattern. . ____ _ __ _ _ /\\\\ / ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot ::%d [%thread] %-5level %logger - %msg%n%d [%thread] %-5level %logger - %msg%n org.springframework.beans.factory.BeanDefinitionStoreException: Failed to process import candidates for configuration class [com.icloud.CusMainApplication]; nested exception is java.lang.IllegalArgumentException: No auto configuration classes found in META-INF/spring.factories. If you are using a custom packaging, make sure that file is correct. maven-shade-plugin插件配置如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;version&gt;2.4.1&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;shade&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;createDependencyReducedPom&gt;false&lt;/createDependencyReducedPom&gt; &lt;transformers&gt; &lt;transformer implementation=\"org.apache.maven.plugins.shade.resource.AppendingTransformer\"&gt; &lt;resource&gt;META-INF/spring.schemas&lt;/resource&gt; &lt;/transformer&gt; &lt;transformer implementation=\"org.apache.maven.plugins.shade.resource.AppendingTransformer\"&gt; &lt;resource&gt;META-INF/spring.handlers&lt;/resource&gt; &lt;/transformer&gt; &lt;transformer implementation=\"org.springframework.boot.maven.PropertiesMergingResourceTransformer\"&gt; &lt;resource&gt;META-INF/spring.factories&lt;/resource&gt; &lt;/transformer&gt; &lt;transformer implementation=\"org.apache.maven.plugins.shade.resource.ServicesResourceTransformer\"/&gt; &lt;transformer implementation=\"org.apache.maven.plugins.shade.resource.ManifestResourceTransformer\"&gt; &lt;mainClass&gt;com.icloud.CusMainApplication&lt;/mainClass&gt; &lt;/transformer&gt; &lt;transformer implementation=\"com.github.edwgiz.mavenShadePlugin.log4j2CacheTransformer.PluginsCacheFileTransformer\" /&gt; &lt;/transformers&gt; &lt;filters&gt; &lt;filter&gt; &lt;artifact&gt;*:*&lt;/artifact&gt; &lt;excludes&gt; &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt; &lt;/excludes&gt; &lt;/filter&gt; &lt;/filters&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.edwgiz&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin.log4j2-cachefile-transformer&lt;/artifactId&gt; &lt;version&gt;2.6.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/plugin&gt;","tags":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/tags/Maven/"},{"name":"assembly","slug":"assembly","permalink":"https://yaoyinglong.github.io/tags/assembly/"}],"categories":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/categories/Maven/"}]},{"title":"国密SM2","date":"2019-10-27T16:00:00.000Z","path":"Blog/Java/工具/国密SM2/","text":"SM2为非对称加密，基于ECC 椭圆曲线密码机制。该算法已公开。由于该算法基于ECC，故其签名速度与秘钥生成速度都快于RSA。ECC 256位（SM2采用的就是ECC 256位的一种）安全强度比RSA 2048位高，但运算速度快于RSA。 Maven配置： 1234&lt;dependency&gt; &lt;groupId&gt;org.bouncycastle&lt;/groupId&gt; &lt;artifactId&gt;bcpkix-jdk15on&lt;/artifactId&gt;&lt;/dependency&gt; 特别关注对于SM2加解密，需要注意三点，首先需要注意加密处理的密文顺序，关于密钥的使用，以及加解密的HEX转码问题。 加密处理的密文顺序 注意约定C1、C2、C3的拼装顺序（参照下面加密相关的代码内容，示例顺序为：C1+C2+C3） 密钥的使用 有的生成的公钥是带04前缀，有的是不带的。在使用时最对实际情况进行04的截取或补充（示例是带04的） 有的生成的私钥前缀带有00，有的是不带00的，在使用时最对实际情况进行00的截取或补充（示例是不带00的） HEX转码问题 SM2加解密过程中会多次进行HEX的编码何解码，调试时需要注意 在进行HEX编码时，注意中文的编码格式 相关代码Cipher代码: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182public class Cipher &#123; private int ct; private ECPoint p2; private SM3Digest sm3keybase; private SM3Digest sm3c3; private byte[] key; private byte keyOff; public Cipher() &#123; this.ct = 1; this.key = new byte[32]; this.keyOff = 0; &#125; private void Reset() &#123; this.sm3keybase = new SM3Digest(); this.sm3c3 = new SM3Digest(); byte[] publicKeyX = HexUtil.byteConvert32Bytes(p2.getX().toBigInteger()); this.sm3keybase.update(publicKeyX, 0, publicKeyX.length); this.sm3c3.update(publicKeyX, 0, publicKeyX.length); byte[] publicKeyY = HexUtil.byteConvert32Bytes(p2.getY().toBigInteger()); this.sm3keybase.update(publicKeyY, 0, publicKeyY.length); this.ct = 1; NextKey(); &#125; private void NextKey() &#123; SM3Digest sm3keycur = new SM3Digest(this.sm3keybase); sm3keycur.update((byte) (ct &gt;&gt; 24 &amp; 0xff)); sm3keycur.update((byte) (ct &gt;&gt; 16 &amp; 0xff)); sm3keycur.update((byte) (ct &gt;&gt; 8 &amp; 0xff)); sm3keycur.update((byte) (ct &amp; 0xff)); sm3keycur.doFinal(key, 0); this.keyOff = 0; this.ct++; &#125; public ECPoint Init_enc(SM2 sm2, ECPoint userKey) &#123; AsymmetricCipherKeyPair key = sm2.ecc_key_pair_generator.generateKeyPair(); ECPrivateKeyParameters ecpriv = (ECPrivateKeyParameters) key.getPrivate(); ECPublicKeyParameters ecpub = (ECPublicKeyParameters) key.getPublic(); BigInteger k = ecpriv.getD(); ECPoint c1 = ecpub.getQ(); this.p2 = userKey.multiply(k); Reset(); return c1; &#125; public void Encrypt(byte[] data) &#123; this.sm3c3.update(data, 0, data.length); for (int i = 0; i &lt; data.length; i++) &#123; if (keyOff == key.length) &#123; NextKey(); &#125; data[i] ^= key[keyOff++]; &#125; &#125; public void Init_dec(BigInteger userD, ECPoint c1) &#123; this.p2 = c1.multiply(userD); Reset(); &#125; public void Decrypt(byte[] data) &#123; for (int i = 0; i &lt; data.length; i++) &#123; if (keyOff == key.length) &#123; NextKey(); &#125; data[i] ^= key[keyOff++]; &#125; this.sm3c3.update(data, 0, data.length); &#125; public void Dofinal(byte[] c3) &#123; byte[] publicKeyY = HexUtil.byteConvert32Bytes(p2.getY().toBigInteger()); this.sm3c3.update(publicKeyY, 0, publicKeyY.length); this.sm3c3.doFinal(c3, 0); Reset(); &#125;&#125; SM2代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class SM2 &#123; public static String[] ECC_PARAM = &#123; \"FFFFFFFEFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF00000000FFFFFFFFFFFFFFFF\", \"FFFFFFFEFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF00000000FFFFFFFFFFFFFFFC\", \"28E9FA9E9D9F5E344D5A9E4BCF6509A7F39789F515AB8F92DDBCBD414D940E93\", \"FFFFFFFEFFFFFFFFFFFFFFFFFFFFFFFF7203DF6B21C6052B53BBF40939D54123\", \"32C4AE2C1F1981195F9904466A39C9948FE30BBFF2660BE1715A4589334C74C7\", \"BC3736A2F4F6779C59BDCEE36B692153D0A9877CC62A474002DF32E52139F0A0\" &#125;; public final BigInteger ecc_p; public final BigInteger ecc_a; public final BigInteger ecc_b; public final BigInteger ecc_n; public final BigInteger ecc_gx; public final BigInteger ecc_gy; public final ECCurve ecc_curve; public final ECPoint ecc_point_g; public final ECDomainParameters ecc_bc_spec; public final ECKeyPairGenerator ecc_key_pair_generator; public final ECFieldElement ecc_gx_fieldelement; public final ECFieldElement ecc_gy_fieldelement; public SM2() &#123; this.ecc_p = new BigInteger(ECC_PARAM[0], 16); this.ecc_a = new BigInteger(ECC_PARAM[1], 16); this.ecc_b = new BigInteger(ECC_PARAM[2], 16); this.ecc_n = new BigInteger(ECC_PARAM[3], 16); this.ecc_gx = new BigInteger(ECC_PARAM[4], 16); this.ecc_gy = new BigInteger(ECC_PARAM[5], 16); this.ecc_gx_fieldelement = new Fp(this.ecc_p, this.ecc_gx); this.ecc_gy_fieldelement = new Fp(this.ecc_p, this.ecc_gy); this.ecc_curve = new ECCurve.Fp(this.ecc_p, this.ecc_a, this.ecc_b); this.ecc_point_g = new ECPoint.Fp(this.ecc_curve, this.ecc_gx_fieldelement, this.ecc_gy_fieldelement); this.ecc_bc_spec = new ECDomainParameters(this.ecc_curve, this.ecc_point_g, this.ecc_n); ECKeyGenerationParameters ecc_ecgenparam; ecc_ecgenparam = new ECKeyGenerationParameters(this.ecc_bc_spec, new SecureRandom()); this.ecc_key_pair_generator = new ECKeyPairGenerator(); this.ecc_key_pair_generator.init(ecc_ecgenparam); &#125; public static SM2 Instance() &#123; return new SM2(); &#125;&#125; SM2Utils代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class SM2Utils &#123; //生成随机秘钥对 public static void generateKeyPair() &#123; SM2 sm2 = SM2.Instance(); AsymmetricCipherKeyPair key = sm2.ecc_key_pair_generator.generateKeyPair(); ECPrivateKeyParameters ecpriv = (ECPrivateKeyParameters) key.getPrivate(); ECPublicKeyParameters ecpub = (ECPublicKeyParameters) key.getPublic(); BigInteger privateKey = ecpriv.getD(); ECPoint publicKey = ecpub.getQ(); System.out.println(\"公钥: \" + ByteUtils.toHexString(publicKey.getEncoded())); System.out.println(\"私钥: \" + ByteUtils.toHexString(privateKey.toByteArray())); &#125; //数据加密 public static String encrypt(String publicKey, String plainText) &#123; if (StringUtils.isBlank(publicKey) || StringUtils.isBlank(plainText)) &#123; return null; &#125; byte[] publicKeyBytes = ByteUtils.fromHexString(publicKey); byte[] plainTextBytes = ByteUtils.fromHexString(plainText); byte[] source = new byte[plainTextBytes.length]; System.arraycopy(plainTextBytes, 0, source, 0, plainTextBytes.length); Cipher cipher = new Cipher(); SM2 sm2 = SM2.Instance(); ECPoint userKey = sm2.ecc_curve.decodePoint(publicKeyBytes); ECPoint c1 = cipher.Init_enc(sm2, userKey); cipher.Encrypt(source); byte[] c3 = new byte[32]; cipher.Dofinal(c3); //C1 C2 C3拼装成加密字串 return ByteUtils.toHexString(c1.getEncoded()) + ByteUtils.toHexString(source) + ByteUtils.toHexString(c3); &#125; //数据解密 public static byte[] decrypt(String privateKey, String cipherText) &#123; if (StringUtils.isBlank(privateKey) || StringUtils.isBlank(cipherText)) &#123; return null; &#125; byte[] privateKeyBytes = ByteUtils.fromHexString(privateKey); byte[] cipherTextBytes = ByteUtils.fromHexString(cipherText); //加密字节数组转换为十六进制的字符串 长度变为encryptedData.length * 2 String data = ByteUtils.toHexString(cipherTextBytes); /***分解加密字串 * （C1 = C1标志位2位 + C1实体部分128位 = 130） * （C3 = C3实体部分64位 = 64） * （C2 = encryptedData.length * 2 - C1长度 - C2长度） */ byte[] c1Bytes = ByteUtils.fromHexString(data.substring(0, 130)); int c2Len = cipherTextBytes.length - 97; byte[] c2 = ByteUtils.fromHexString(data.substring(130, 130 + 2 * c2Len)); byte[] c3 = ByteUtils.fromHexString(data.substring(130 + 2 * c2Len, 194 + 2 * c2Len)); SM2 sm2 = SM2.Instance(); BigInteger userD = new BigInteger(1, privateKeyBytes); //通过C1实体字节来生成ECPoint ECPoint c1 = sm2.ecc_curve.decodePoint(c1Bytes); Cipher cipher = new Cipher(); cipher.Init_dec(userD, c1); cipher.Decrypt(c2); cipher.Dofinal(c3); //返回解密结果 return c2; &#125;&#125;","tags":[{"name":"国密，SM2","slug":"国密，SM2","permalink":"https://yaoyinglong.github.io/tags/国密，SM2/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"工具","slug":"Java/工具","permalink":"https://yaoyinglong.github.io/categories/Java/工具/"}]},{"title":"国密SM4","date":"2019-10-27T16:00:00.000Z","path":"Blog/Java/工具/国密SM4/","text":"SM4 无线局域网标准的分组数据算法。对称加密，密钥长度和分组长度均为128位。 分组密码常用得五种模式，这里主要讲SM4的ECB模式： EBC-电码本模式 CBC-密码分组链接模式 CTR-计算器模式 CFB-密码反馈模式 OFB-输出反馈模式 Maven配置： 1234&lt;dependency&gt; &lt;groupId&gt;org.bouncycastle&lt;/groupId&gt; &lt;artifactId&gt;bcpkix-jdk15on&lt;/artifactId&gt;&lt;/dependency&gt; 特别关注SM4加解密最需要注意，也是最容易出错的地方是填充模式的处理。而且对数据的填充方式是高度自由的。这里介绍两种填充方式。当然也可以不填充，但一般都会要求使用填充。 进行加密得时候会进行填充，在进行解密时会去填充。若填充方式不匹配，解密得数据将会不正确。 填充方式可以为：数据得长度 + 数据 + 填充，还可以为：数据 + 填充位长度 + 填充，且填充可以在转HEX前也可以在转HEX之后，所以说填充是高度自由的。 相关代码SM4Context代码： 12345678910public class SM4Context &#123; public int mode; public long[] sk; public boolean isPadding; public SM4Context() &#123; this.mode = 1; this.isPadding = true; this.sk = new long[32]; &#125;&#125; SM4代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245public class SM4 &#123; public static final int SM4_ENCRYPT = 1; public static final int SM4_DECRYPT = 0; public static final byte[] SBOX_TABLE = &#123; (byte) 0xd6, (byte) 0x90, (byte) 0xe9, (byte) 0xfe, (byte) 0xcc, (byte) 0xe1, 0x3d, (byte) 0xb7, 0x16, (byte) 0xb6, 0x14, (byte) 0xc2, 0x28, (byte) 0xfb, 0x2c, 0x05, 0x2b, 0x67, (byte) 0x9a, 0x76, 0x2a, (byte) 0xbe, 0x04, (byte) 0xc3, (byte) 0xaa, 0x44, 0x13, 0x26, 0x49, (byte) 0x86, 0x06, (byte) 0x99, (byte) 0x9c, 0x42, 0x50, (byte) 0xf4, (byte) 0x91, (byte) 0xef, (byte) 0x98, 0x7a, 0x33, 0x54, 0x0b, 0x43, (byte) 0xed, (byte) 0xcf, (byte) 0xac, 0x62, (byte) 0xe4, (byte) 0xb3, 0x1c, (byte) 0xa9, (byte) 0xc9, 0x08, (byte) 0xe8, (byte) 0x95, (byte) 0x80, (byte) 0xdf, (byte) 0x94, (byte) 0xfa, 0x75, (byte) 0x8f, 0x3f, (byte) 0xa6, 0x47, 0x07, (byte) 0xa7, (byte) 0xfc, (byte) 0xf3, 0x73, 0x17, (byte) 0xba, (byte) 0x83, 0x59, 0x3c, 0x19, (byte) 0xe6, (byte) 0x85, 0x4f, (byte) 0xa8, 0x68, 0x6b, (byte) 0x81, (byte) 0xb2, 0x71, 0x64, (byte) 0xda, (byte) 0x8b, (byte) 0xf8, (byte) 0xeb, 0x0f, 0x4b, 0x70, 0x56, (byte) 0x9d, 0x35, 0x1e, 0x24, 0x0e, 0x5e, 0x63, 0x58, (byte) 0xd1, (byte) 0xa2, 0x25, 0x22, 0x7c, 0x3b, 0x01, 0x21, 0x78, (byte) 0x87, (byte) 0xd4, 0x00, 0x46, 0x57, (byte) 0x9f, (byte) 0xd3, 0x27, 0x52, 0x4c, 0x36, 0x02, (byte) 0xe7, (byte) 0xa0, (byte) 0xc4, (byte) 0xc8, (byte) 0x9e, (byte) 0xea, (byte) 0xbf, (byte) 0x8a, (byte) 0xd2, 0x40, (byte) 0xc7, 0x38, (byte) 0xb5, (byte) 0xa3, (byte) 0xf7, (byte) 0xf2, (byte) 0xce, (byte) 0xf9, 0x61, 0x15, (byte) 0xa1, (byte) 0xe0, (byte) 0xae, 0x5d, (byte) 0xa4, (byte) 0x9b, 0x34, 0x1a, 0x55, (byte) 0xad, (byte) 0x93, 0x32, 0x30, (byte) 0xf5, (byte) 0x8c, (byte) 0xb1, (byte) 0xe3, 0x1d, (byte) 0xf6, (byte) 0xe2, 0x2e, (byte) 0x82, 0x66, (byte) 0xca, 0x60, (byte) 0xc0, 0x29, 0x23, (byte) 0xab, 0x0d, 0x53, 0x4e, 0x6f, (byte) 0xd5, (byte) 0xdb, 0x37, 0x45, (byte) 0xde, (byte) 0xfd, (byte) 0x8e, 0x2f, 0x03, (byte) 0xff, 0x6a, 0x72, 0x6d, 0x6c, 0x5b, 0x51, (byte) 0x8d, 0x1b, (byte) 0xaf, (byte) 0x92, (byte) 0xbb, (byte) 0xdd, (byte) 0xbc, 0x7f, 0x11, (byte) 0xd9, 0x5c, 0x41, 0x1f, 0x10, 0x5a, (byte) 0xd8, 0x0a, (byte) 0xc1, 0x31, (byte) 0x88, (byte) 0xa5, (byte) 0xcd, 0x7b, (byte) 0xbd, 0x2d, 0x74, (byte) 0xd0, 0x12, (byte) 0xb8, (byte) 0xe5, (byte) 0xb4, (byte) 0xb0, (byte) 0x89, 0x69, (byte) 0x97, 0x4a, 0x0c, (byte) 0x96, 0x77, 0x7e, 0x65, (byte) 0xb9, (byte) 0xf1, 0x09, (byte) 0xc5, 0x6e, (byte) 0xc6, (byte) 0x84, 0x18, (byte) 0xf0, 0x7d, (byte) 0xec, 0x3a, (byte) 0xdc, 0x4d, 0x20, 0x79, (byte) 0xee, 0x5f, 0x3e, (byte) 0xd7, (byte) 0xcb, 0x39, 0x48 &#125;; public static final int[] FK = &#123;0xa3b1bac6, 0x56aa3350, 0x677d9197, 0xb27022dc&#125;; public static final int[] CK = &#123; 0x00070e15, 0x1c232a31, 0x383f464d, 0x545b6269, 0x70777e85, 0x8c939aa1, 0xa8afb6bd, 0xc4cbd2d9, 0xe0e7eef5, 0xfc030a11, 0x181f262d, 0x343b4249, 0x50575e65, 0x6c737a81, 0x888f969d, 0xa4abb2b9, 0xc0c7ced5, 0xdce3eaf1, 0xf8ff060d, 0x141b2229, 0x30373e45, 0x4c535a61, 0x686f767d, 0x848b9299, 0xa0a7aeb5, 0xbcc3cad1, 0xd8dfe6ed, 0xf4fb0209, 0x10171e25, 0x2c333a41, 0x484f565d, 0x646b7279 &#125;; private long GET_ULONG_BE(byte[] b, int i) &#123; long n = (long) (b[i] &amp; 0xff) &lt;&lt; 24 | (long) ((b[i + 1] &amp; 0xff) &lt;&lt; 16) | (long) ((b[i + 2] &amp; 0xff) &lt;&lt; 8) | (long) (b[i + 3] &amp; 0xff) &amp; 0xffffffffL; return n; &#125; private void PUT_ULONG_BE(long n, byte[] b, int i) &#123; b[i] = (byte) (int) (0xFF &amp; n &gt;&gt; 24); b[i + 1] = (byte) (int) (0xFF &amp; n &gt;&gt; 16); b[i + 2] = (byte) (int) (0xFF &amp; n &gt;&gt; 8); b[i + 3] = (byte) (int) (0xFF &amp; n); &#125; private long SHL(long x, int n) &#123; return (x &amp; 0xFFFFFFFF) &lt;&lt; n; &#125; private long ROTL(long x, int n) &#123; return SHL(x, n) | x &gt;&gt; 32 - n; &#125; private void SWAP(long[] sk, int i) &#123; long t = sk[i]; sk[i] = sk[31 - i]; sk[31 - i] = t; &#125; private byte sm4Sbox(byte inch) &#123; int i = inch &amp; 0xFF; byte retVal = SBOX_TABLE[i]; return retVal; &#125; private long sm4Lt(long ka) &#123; long bb = 0L; long c = 0L; byte[] a = new byte[4]; byte[] b = new byte[4]; PUT_ULONG_BE(ka, a, 0); b[0] = sm4Sbox(a[0]); b[1] = sm4Sbox(a[1]); b[2] = sm4Sbox(a[2]); b[3] = sm4Sbox(a[3]); bb = GET_ULONG_BE(b, 0); c = bb ^ ROTL(bb, 2) ^ ROTL(bb, 10) ^ ROTL(bb, 18) ^ ROTL(bb, 24); return c; &#125; private long sm4F(long x0, long x1, long x2, long x3, long rk) &#123; return x0 ^ sm4Lt(x1 ^ x2 ^ x3 ^ rk); &#125; private long sm4CalciRK(long ka) &#123; long bb = 0L; long rk = 0L; byte[] a = new byte[4]; byte[] b = new byte[4]; PUT_ULONG_BE(ka, a, 0); b[0] = sm4Sbox(a[0]); b[1] = sm4Sbox(a[1]); b[2] = sm4Sbox(a[2]); b[3] = sm4Sbox(a[3]); bb = GET_ULONG_BE(b, 0); rk = bb ^ ROTL(bb, 13) ^ ROTL(bb, 23); return rk; &#125; private void sm4_setkey(long[] SK, byte[] key) &#123; long[] MK = new long[4]; long[] k = new long[36]; int i = 0; MK[0] = GET_ULONG_BE(key, 0); MK[1] = GET_ULONG_BE(key, 4); MK[2] = GET_ULONG_BE(key, 8); MK[3] = GET_ULONG_BE(key, 12); k[0] = MK[0] ^ (long) FK[0]; k[1] = MK[1] ^ (long) FK[1]; k[2] = MK[2] ^ (long) FK[2]; k[3] = MK[3] ^ (long) FK[3]; for (; i &lt; 32; i++) &#123; k[i + 4] = k[i] ^ sm4CalciRK(k[i + 1] ^ k[i + 2] ^ k[i + 3] ^ (long) CK[i]); SK[i] = k[i + 4]; &#125; &#125; private void sm4_one_round(long[] sk, byte[] input, byte[] output) &#123; int i = 0; long[] ulbuf = new long[36]; ulbuf[0] = GET_ULONG_BE(input, 0); ulbuf[1] = GET_ULONG_BE(input, 4); ulbuf[2] = GET_ULONG_BE(input, 8); ulbuf[3] = GET_ULONG_BE(input, 12); while (i &lt; 32) &#123; ulbuf[i + 4] = sm4F(ulbuf[i], ulbuf[i + 1], ulbuf[i + 2], ulbuf[i + 3], sk[i]); i++; &#125; PUT_ULONG_BE(ulbuf[35], output, 0); PUT_ULONG_BE(ulbuf[34], output, 4); PUT_ULONG_BE(ulbuf[33], output, 8); PUT_ULONG_BE(ulbuf[32], output, 12); &#125; private byte[] padding(byte[] input, int mode) &#123; if (input == null) &#123; return null; &#125; byte[] ret; if (mode == SM4_ENCRYPT) &#123; int inputLength = input.length; String paddingPrefix = String.valueOf(inputLength); int paddingPrefixLength = 4 - paddingPrefix.length(); StringBuffer prefixBuffer = new StringBuffer(); for (int i = 0; i &lt; paddingPrefixLength; i++) &#123; prefixBuffer.append(\"0\"); &#125; paddingPrefix = ByteUtils.toHexString(prefixBuffer.append(paddingPrefix).toString().getBytes()); int paddingLength = 16 - (inputLength + 4) % 16; String inputHex = ByteUtils.toHexString(input); StringBuffer stringBuffer = new StringBuffer(paddingPrefix); stringBuffer.append(inputHex); for (int i = 0; i &lt; paddingLength; i++) &#123; stringBuffer.append(\"00\"); &#125; ret = ByteUtils.fromHexString(stringBuffer.toString()); &#125; else &#123; String inputHex = ByteUtils.toHexString(input); String paddingPrefix = inputHex.substring(0, 8); paddingPrefix = new String(ByteUtils.fromHexString(paddingPrefix)); int dataLength = Integer.valueOf(paddingPrefix); String dataHex = inputHex.substring(8, dataLength * 2 + 8); ret = ByteUtils.fromHexString(dataHex); &#125; return ret; &#125; private byte[] paddingOld(byte[] input, int mode) &#123; if (input == null) &#123; return null; &#125; byte[] ret; if (mode == SM4_ENCRYPT) &#123; String origin = new String(input); int inputLength = origin.length(); String paddingPrefix = String.valueOf(inputLength); int paddingPrefixLength = 4 - paddingPrefix.length(); StringBuffer prefixBuffer = new StringBuffer(); for (int i = 0; i &lt; paddingPrefixLength; i++) &#123; prefixBuffer.append(\"0\"); &#125; paddingPrefix = prefixBuffer.append(paddingPrefix).toString(); int paddingLength = 16 - (inputLength + 4) % 16; StringBuffer stringBuffer = new StringBuffer(paddingPrefix); stringBuffer.append(origin); for (int i = 0; i &lt; paddingLength; i++) &#123; stringBuffer.append(\"0\"); &#125; ret = stringBuffer.toString().getBytes(); &#125; else &#123; String origin = new String(input); String paddingPrefix = origin.substring(0, 4); int dataLength = Integer.valueOf(paddingPrefix); String data = origin.substring(4, dataLength + 4); ret = data.getBytes(); &#125; return ret; &#125; public void sm4_setkey_enc(SM4Context ctx, byte[] key) throws Exception &#123; if (ctx == null) &#123; throw new Exception(\"SM4 sm4_setkey_enc SM4Context is null!\"); &#125; if (key == null || key.length != 16) &#123; throw new Exception(\"SM4 sm4_setkey_enc key byte array error!\"); &#125; ctx.mode = SM4_ENCRYPT; sm4_setkey(ctx.sk, key); &#125; public void sm4_setkey_dec(SM4Context ctx, byte[] key) throws Exception &#123; if (ctx == null) &#123; throw new Exception(\"SM4 sm4_setkey_dec SM4Context is null!\"); &#125; if (key == null || key.length != 16) &#123; throw new Exception(\"SM4 sm4_setkey_dec key byte array error!\"); &#125; int i = 0; ctx.mode = SM4_DECRYPT; sm4_setkey(ctx.sk, key); for (i = 0; i &lt; 16; i++) &#123; SWAP(ctx.sk, i); &#125; &#125; public byte[] sm4_crypt_ecb(SM4Context ctx, byte[] input) throws Exception &#123; if (input == null) &#123; throw new Exception(\"SM4 sm4_crypt_ecb input byte array is null!\"); &#125; if (ctx.isPadding &amp;&amp; ctx.mode == SM4_ENCRYPT) &#123; input = padding(input, SM4_ENCRYPT); &#125; int length = input.length; ByteArrayInputStream bins = new ByteArrayInputStream(input); ByteArrayOutputStream bous = new ByteArrayOutputStream(); for (; length &gt; 0; length -= 16) &#123; byte[] in = new byte[16]; byte[] out = new byte[16]; bins.read(in); sm4_one_round(ctx.sk, in, out); bous.write(out); &#125; byte[] output = bous.toByteArray(); if (ctx.isPadding &amp;&amp; ctx.mode == SM4_DECRYPT) &#123; output = padding(output, SM4_DECRYPT); &#125; bins.close(); bous.close(); return output; &#125;&#125; SM4Utils代码： 123456789101112131415161718192021222324252627282930313233343536public class SM4Utils &#123; public static String encryptDataEcb(String plainText, String sm4Key) throws Exception &#123; SM4Context ctx = new SM4Context(); ctx.isPadding = true; ctx.mode = SM4.SM4_ENCRYPT; SM4 sm4 = new SM4(); byte[] keyBytes = ByteUtils.fromHexString(sm4Key); sm4.sm4_setkey_enc(ctx, keyBytes); byte[] encrypted = sm4.sm4_crypt_ecb(ctx, ByteUtils.fromHexString(plainText)); return ByteUtils.toHexString(encrypted); &#125; public static String decryptDataEcb(String cipherText, String sm4Key) throws Exception &#123; SM4Context ctx = new SM4Context(); ctx.isPadding = true; ctx.mode = SM4.SM4_DECRYPT; byte[] keyBytes = ByteUtils.fromHexString(sm4Key); SM4 sm4 = new SM4(); sm4.sm4_setkey_dec(ctx, keyBytes); byte[] decrypted = sm4.sm4_crypt_ecb(ctx, Base64.decodeBase64(cipherTextTransform(cipherText))); return ByteUtils.toHexString(decrypted); &#125; private static String cipherTextTransform(String cipherText) throws Exception &#123; byte[] encrypted = ByteUtils.fromHexString(cipherText); cipherText = Base64.encodeBase64String(encrypted); if (StringUtils.isNotBlank(cipherText)) &#123; Pattern p = Pattern.compile(\"\\\\s*|\\t|\\r|\\n\"); Matcher m = p.matcher(cipherText); cipherText = m.replaceAll(\"\"); &#125; return cipherText; &#125;&#125;","tags":[{"name":"国密","slug":"国密","permalink":"https://yaoyinglong.github.io/tags/国密/"},{"name":"SM4","slug":"SM4","permalink":"https://yaoyinglong.github.io/tags/SM4/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"工具","slug":"Java/工具","permalink":"https://yaoyinglong.github.io/categories/Java/工具/"}]},{"title":"Maven Assembly标签全解","date":"2019-10-27T16:00:00.000Z","path":"Blog/Maven/Maven Assembly标签全解/","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727728729730731732733734735736737738739740741742743744745746747748749750751752753754755756757758759760761762763764765766767768769770771772773774775776777778779780781782783784785786787788789790791792793794795796&lt;assembly xmlns=\"http://maven.apache.org/ASSEMBLY/2.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/ASSEMBLY/2.0.0 http://maven.apache.org/xsd/assembly-2.0.0.xsd\"&gt; &lt;!-- 设置此程序集的标识。这是来自此项目的特定文件组合的符号名称。此外，除了用于通过将生成的归档的值附加到组合包以明确命名组合包之外，该ID在部署时用作工件的分类器。 --&gt; &lt;!--string--&gt; &lt;id/&gt; &lt;!-- (许多） 指定程序集的格式。通过目标参数而不是在这里指定格式通常会更好。例如，允许不同的配置文件生成不同类型的档案。 可以提供多种格式，装配体插件将生成每种所需格式的档案。部署项目时，所有指定的文件格式也将被部署。 通过在&lt;format&gt;子元素中提供以下值之一来指定格式： “zip” - 创建一个ZIP文件格式 “tar” - 创建一个TAR格式 “tar.gz”或“tgz” - 创建一个gzip'd TAR格式 “tar.bz2”或“tbz2” - 创建一个bzip'd TAR格式 “tar.snappy” - 创建一个灵活的TAR格式 “tar.xz”或“txz” - 创建一个xz'd TAR格式 “jar” - 创建一个JAR格式 “dir” - 创建分解的目录格式 “战争” - 创建一个WAR格式 --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;formats/&gt; &lt;!-- 在最终归档中包含一个基本目录。例如，如果您正在创建一个名为“your-app”的程序集，则将includeBaseDirectory设置为true将创建一个包含此基本目录的归档文件。 如果此选项设置为false，则创建的存档将其内容解压缩到当前目录。 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;includeBaseDirectory/&gt; &lt;!-- 设置生成的程序集归档的基本目录。如果没有设置，并且includeBaseDirectory == true，则将使用$ &#123;project.build.finalName&#125;。（从2.2-beta-1开始） --&gt; &lt;!--string--&gt; &lt;baseDirectory/&gt; &lt;!-- 在最终档案中包含一个网站目录。项目的站点目录位置由Assembly Plugin的siteDirectory参数确定。 默认值是：false。 --&gt; &lt;!--boolean--&gt; &lt;includeSiteDirectory/&gt; &lt;!-- （许多） 从常规归档流中过滤各种容器描述符的组件集合，因此可以将它们聚合然后添加。 --&gt; &lt;!--List&lt;ContainerDescriptorHandlerConfig&gt;--&gt; &lt;containerDescriptorHandlers&gt; &lt;!-- 配置文件头部的过滤器，以启用各种类型的描述符片段（如components.xml，web.xml等）的聚合。 --&gt; &lt;containerDescriptorHandler&gt; &lt;!-- 处理程序的plexus角色提示，用于从容器中查找。 --&gt; &lt;!--string--&gt; &lt;handlerName/&gt; &lt;!-- 处理程序的配置选项。 --&gt; &lt;!--DOM--&gt; &lt;configuration/&gt; &lt;/containerDescriptorHandler&gt; &lt;/containerDescriptorHandlers&gt; &lt;!-- （许多） 指定在程序集中包含哪些模块文件。moduleSet是通过提供一个或多个&lt;moduleSet&gt;子元素来指定的。 --&gt; &lt;!--List&lt;ModuleSet&gt;--&gt; &lt;moduleSets&gt; &lt;!-- moduleSet表示一个或多个在项目的pom.xml中存在的&lt;module&gt;项目。这使您可以包含属于项目&lt;modules&gt;的源代码或二进制文件。 注意：从命令行使用&lt;moduleSets&gt;时，需要先通过“mvn package assembly：assembly”来传递包阶段。这个bug计划由Maven 2.1解决。 --&gt; &lt;moduleSet&gt; &lt;!-- 如果设置为true，则该插件将包含当前反应堆中的所有项目，以便在此ModuleSet中进行处理。这些将被 纳入/排除(includes/excludes) 规则。（从2.2开始） 默认值是：false。 --&gt; &lt;!--boolean--&gt; &lt;useAllReactorProjects/&gt; &lt;!-- 如果设置为false，则该插件将从该ModuleSet中排除子模块的处理。否则，它将处理所有子模块，每个子模块都要遵守包含/排除规则。（从2.2-beta-1开始） 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;includeSubModules/&gt; &lt;!-- （许多） 当存在&lt;include&gt;子元素时，它们定义一组包含的项目坐标。如果不存在，则&lt;includes&gt;表示所有有效值。 工件坐标可以以简单的groupId：artifactId形式给出，或者可以以groupId：artifactId：type [：classifier]：version的形式完全限定。 另外，可以使用通配符，如*：maven- * --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;includes/&gt; &lt;!-- （许多） 当存在&lt;exclude&gt;子元素时，它们定义一组要排除的项目工件坐标。如果不存在，则&lt;excludes&gt;不表示排除。 工件坐标可以以简单的groupId：artifactId形式给出，或者可以以groupId：artifactId：type [：classifier]：version的形式完全限定。 另外，可以使用通配符，如*：maven- * --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;excludes/&gt; &lt;!-- 当存在这个时，插件将在生成的程序集中包含这个集合中包含的模块的源文件。 包含用于在程序集中包含项目模块的源文件的配置选项。 --&gt; &lt;!--ModuleSources--&gt; &lt;sources&gt; &lt;!-- 在计算受该集合影响的文件时，是否应该使用标准排除模式，例如那些匹配CVS和Subversion元数据文件的排除模式。为了向后兼容，默认值是true。（从2.2-beta-1开始） 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;useDefaultExcludes/&gt; &lt;!-- 设置输出目录相对于程序集根目录的根目录。例如，“日志”将把指定的文件放在日志目录中。 --&gt; &lt;!--string--&gt; &lt;outputDirectory/&gt; &lt;!-- （许多） 当&lt;include&gt;子元素存在时，它们定义一组要包含的文件和目录。如果不存在，则&lt;includes&gt;表示所有有效值。 --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;includes/&gt; &lt;!-- （许多） 当存在&lt;exclude&gt;子元素时，它们定义一组要排除的文件和目录。如果不存在，则&lt;excludes&gt;不表示排除。 --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;excludes/&gt; &lt;!-- 与UNIX权限类似，设置所包含文件的文件模式。这是一个 OCTAL VALUE。格式：（用户）（组）（其他）其中每个组件是Read = 4，Write = 2和Execute = 1的总和。 例如，值0644转换为用户读写，组和其他只读。默认值是0644 --&gt; &lt;!--string--&gt; &lt;fileMode/&gt; &lt;!-- 与UNIX权限类似，设置包含的目录的目录模式。这是一个 OCTAL VALUE。格式：（用户）（组）（其他）[Format: (User)(Group)(Other) ] 其中每个组件是Read = 4，Write = 2和Execute = 1的总和。 例如，值0755转换为用户读写，Group和其他只读。默认值是0755. --&gt; &lt;!--string--&gt; &lt;directoryMode/&gt; &lt;!-- （许多） 指定包含在程序集中的每个包含模块的哪些文件组。fileSet通过提供一个或多个&lt;fileSet&gt;子元素来指定。（从2.2-beta-1开始） --&gt; &lt;!--List&lt;FileSet&gt;--&gt; &lt;fileSets&gt; &lt;!-- fileSet允许将文件组包含到程序集中。 --&gt; &lt;fileSet&gt; &lt;!-- 在计算受该集合影响的文件时，是否应该使用标准排除模式，例如那些匹配CVS和Subversion元数据文件的排除模式。为了向后兼容，默认值是true。（从2.2-beta-1开始） 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;useDefaultExcludes/&gt; &lt;!-- 设置输出目录相对于程序集根目录的根目录。例如，“日志”将把指定的文件放在日志目录中。 --&gt; &lt;!--string--&gt; &lt;outputDirectory/&gt; &lt;!-- （许多） 当&lt;include&gt;子元素存在时，它们定义一组要包含的文件和目录。如果不存在，则&lt;includes&gt;表示所有有效值。 --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;includes/&gt; &lt;!-- （许多） 当存在&lt;exclude&gt;子元素时，它们定义一组要排除的文件和目录。如果不存在，则&lt;excludes&gt;不表示排除。 --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;excludes/&gt; &lt;!-- 与UNIX权限类似，设置所包含文件的文件模式。这是一个 OCTAL VALUE。格式：（用户）（组）（其他）其中每个组件是Read = 4，Write = 2和Execute = 1的总和。 例如，值0644转换为用户读写，组和其他只读。默认值是0644. --&gt; &lt;!--string--&gt; &lt;fileMode/&gt; &lt;!-- 与UNIX权限类似，设置包含的目录的目录模式。这是一个 OCTAL VALUE。格式：（用户）（组）（其他）其中每个组件是Read = 4，Write = 2和Execute = 1的总和。 例如，值0755转换为用户读写，Group和其他只读。默认值是0755. --&gt; &lt;!--string--&gt; &lt;directoryMode/&gt; &lt;!-- 设置模块目录的绝对或相对位置。例如，“src / main / bin”会选择定义这个依赖关系的项目的这个子目录。 --&gt; &lt;!--string--&gt; &lt;directory/&gt; &lt;!-- 设置此文件集中文件的行结束符。有效值： “keep” - 保留所有的行结束 “unix” - 使用Unix风格的行尾（即“\\ n”） “lf” - 使用一个换行符结束符（即“\\ n”） “dos” - 使用DOS / Windows风格的行尾（即“\\ r \\ n”） “windows” - 使用DOS / Windows风格的行尾（即“\\ r \\ n”） “crlf” - 使用回车，换行符结尾（即“\\ r \\ n”） --&gt; &lt;!--string--&gt; &lt;lineEnding/&gt; &lt;!-- 是否在复制文件时过滤符号，使用构建配置中的属性。（从2.2-beta-1开始） 默认值是：false。 --&gt; &lt;!--boolean--&gt; &lt;filtered/&gt; &lt;/fileSet&gt; &lt;/fileSets&gt; &lt;!-- 指定模块的finalName是否应该添加到应用于它的任何fileSets的outputDirectory值。（从2.2-beta-1开始） 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;includeModuleDirectory/&gt; &lt;!-- 指定是否应从应用于该模块的文件集中排除当前模块下方的子模块目录。如果仅仅意味着复制与此ModuleSet匹配的确切模块列表的源，忽略（或单独处理）当前目录下目录中存在的模块，这可能会很有用。（从2.2-beta-1开始） 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;excludeSubModuleDirectories/&gt; &lt;!-- 设置此程序集中包含的所有模块基本目录的映射模式。注意：只有在includeModuleDirectory == true的情况下才会使用此字段。 缺省值是在 2.2-beta-1中是$ &#123;artifactId&#125;，以及后续版本中是$ &#123;module.artifactId&#125;。（从2.2-beta-1开始） 默认值是：$ &#123;module.artifactId&#125;。 --&gt; &lt;!--string--&gt; &lt;outputDirectoryMapping/&gt; &lt;/sources&gt; &lt;!-- 如果存在，插件将在生成的程序集中包含来自该组的所包含模块的二进制文件。 包含用于将项目模块的二进制文件包含在程序集中的配置选项。 --&gt; &lt;!--ModuleBinaries--&gt; &lt;binaries&gt; &lt;!-- 设置输出目录相对于程序集根目录的根目录。例如，“log”会将指定的文件放在归档根目录下的日志目录中。 --&gt; &lt;!--string--&gt; &lt;outputDirectory/&gt; &lt;!-- （许多） 当存在&lt;include&gt;子元素时，它们定义一组要包含的工件坐标。如果不存在，则&lt;includes&gt;表示所有有效值。 工件坐标可以以简单的groupId：artifactId形式给出，或者可以以groupId：artifactId：type [：classifier]：version的形式完全限定。 另外，可以使用通配符，如*：maven- * --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;includes/&gt; &lt;!-- （许多） 当存在&lt;exclude&gt;子元素时，它们定义一组依赖项工件坐标以排除。如果不存在，则&lt;excludes&gt;不表示排除。 工件坐标可以以简单的groupId：artifactId形式给出，或者可以以groupId：artifactId：type [：classifier]：version的形式完全限定。 另外，可以使用通配符，如*：maven- * --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;excludes/&gt; &lt;!-- 与UNIX权限类似，设置所包含文件的文件模式。这是一个 OCTAL VALUE。格式：（用户）（组）（其他）其中每个组件是Read = 4，Write = 2和Execute = 1的总和。 例如，值0644转换为用户读写，组和其他只读。默认值是0644 --&gt; &lt;!--string--&gt; &lt;fileMode/&gt; &lt;!-- 与UNIX权限类似，设置包含的目录的目录模式。这是一个 OCTAL VALUE。格式：（用户）（组）（其他）[Format: (User)(Group)(Other) ] 其中每个组件是Read = 4，Write = 2和Execute = 1的总和。 例如，值0755转换为用户读写，Group和其他只读。默认值是0755. --&gt; &lt;!--string--&gt; &lt;directoryMode/&gt; &lt;!-- 指定时，attachmentClassifier将使汇编器查看附加到模块的工件，而不是主工程工件。如果能够找到与指定分类符匹配的附件，则会使用它; 否则，会抛出异常。（从2.2-beta-1开始） --&gt; &lt;!--string--&gt; &lt;attachmentClassifier/&gt; &lt;!-- 如果设置为true，插件将包含这里包含的项目模块的直接和传递依赖关系。否则，它将只包含模块包。 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;includeDependencies/&gt; &lt;!--List&lt;DependencySet&gt;--&gt; &lt;dependencySets&gt; &lt;!-- 依赖关系集允许在程序集中包含和排除项目依赖关系。 --&gt; &lt;dependencySet&gt; &lt;!-- 设置输出目录相对于程序集根目录的根目录。例如，“log”会将指定的文件放在归档根目录下的日志目录中。 --&gt; &lt;!--string--&gt; &lt;outputDirectory/&gt; &lt;!-- （许多） 当存在&lt;include&gt;子元素时，它们定义一组要包含的工件坐标。如果不存在，则&lt;includes&gt;表示所有有效值。 工件坐标可以以简单的groupId：artifactId形式给出，或者可以以groupId：artifactId：type [：classifier]：version的形式完全限定。 另外，可以使用通配符，如*：maven- * --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;includes/&gt; &lt;!-- （许多） 当存在&lt;exclude&gt;子元素时，它们定义一组依赖项工件坐标以排除。如果不存在，则&lt;excludes&gt;不表示排除。 工件坐标可以以简单的groupId：artifactId形式给出，或者可以以groupId：artifactId：type [：classifier]：version的形式完全限定。 另外，可以使用通配符，如*：maven- * --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;excludes/&gt; &lt;!-- 与UNIX权限类似，设置所包含文件的文件模式。这是一个 OCTAL VALUE。格式：（用户）（组）（其他）其中每个组件是Read = 4，Write = 2和Execute = 1的总和。 例如，值0644转换为用户读写，组和其他只读。默认值是0644 --&gt; &lt;!--string--&gt; &lt;fileMode/&gt; &lt;!-- 与UNIX权限类似，设置包含的目录的目录模式。这是一个 OCTAL VALUE。格式：（用户）（组）（其他）[Format: (User)(Group)(Other) ] 其中每个组件是Read = 4，Write = 2和Execute = 1的总和。 例如，值0755转换为用户读写，Group和其他只读。默认值是0755. --&gt; &lt;!--string--&gt; &lt;directoryMode/&gt; &lt;!-- 如果指定为true，那么在程序集创建过程中任何用于过滤实际构件的包含/排除模式都将导致构建失败，并显示错误。这是为了强调过时的包含或排除，或者表示程序集描述符配置不正确。（从2.2开始） 默认值是：false。 --&gt; &lt;!--boolean--&gt; &lt;useStrictFiltering/&gt; &lt;!-- 为此程序集中包含的所有依赖项设置映射模式。（从2.2-beta-2开始； 2.2-beta-1使用$ &#123;artifactId&#125; - $ &#123;version&#125; $ &#123;dashClassifier？&#125;。$ &#123;extension&#125;作为默认值）。 默认值是：$ &#123;artifact.artifactId&#125; - $ &#123;artifact.version&#125; $ &#123;dashClassifier？&#125;。$ &#123;artifact.extension&#125;。 --&gt; &lt;!--string--&gt; &lt;outputFileNameMapping/&gt; &lt;!-- 如果设置为true，则此属性将所有依赖项解包到指定的输出目录中。设置为false时，依赖关系将被包含为档案（jar）。只能解压jar，zip，tar.gz和tar.bz压缩文件。 默认值是：false。 --&gt; &lt;!--boolean--&gt; &lt;unpack/&gt; &lt;!-- 允许指定包含和排除以及过滤选项，以指定从相关性工件解压缩的项目。（从2.2-beta-1开始） --&gt; &lt;unpackOptions&gt; &lt;!-- （许多） 文件和/或目录模式的集合，用于匹配将在解压缩时从归档文件中包含的项目。每个项目被指定为&lt;include&gt; some / path &lt;/ include&gt;（从2.2-beta-1开始） --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;includes/&gt; &lt;!-- （许多） 用于匹配项目的文件和/或目录模式的集合，在解压缩时将其从归档文件中排除。每个项目被指定为&lt;exclude&gt; some / path &lt;/ exclude&gt;（从2.2-beta-1开始） --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;excludes/&gt; &lt;!-- 是否使用构建配置中的属性过滤从档案中解压缩的文件中的符号。（从2.2-beta-1开始） 默认值是：false。 --&gt; &lt;!--boolean--&gt; &lt;filtered/&gt; &lt;!-- 设置文件的行尾。（从2.2开始）有效值： “keep” - 保留所有的行结束 “unix” - 使用Unix风格的行结尾 “lf” - 使用单个换行符结束符 “dos” - 使用DOS风格的行尾 “ crlf ” - 使用Carraige返回，换行符结束 --&gt; &lt;!--string--&gt; &lt;lineEnding/&gt; &lt;!-- 在计算受该集合影响的文件时，是否应该使用标准排除模式，例如那些匹配CVS和Subversion元数据文件的排除模式。为了向后兼容，默认值是true。（从2.2开始） 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;useDefaultExcludes/&gt; &lt;!-- 允许指定解压档案时使用的编码，支持指定编码的unarchiver。如果未指定，将使用归档程序默认值。Archiver默认值通常代表理智（modern）的values。 --&gt; &lt;!--string--&gt; &lt;encoding/&gt; &lt;/unpackOptions&gt; &lt;!-- 为此dependencySet设置依赖项范围。 默认值是：runtime。 --&gt; &lt;!--string--&gt; &lt;scope/&gt; &lt;!-- 确定当前项目构建过程中产生的工件是否应该包含在这个依赖集中。（从2.2-beta-1开始） 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;useProjectArtifact/&gt; &lt;!-- 确定当前项目构建过程中产生的附件是否应该包含在这个依赖集中。（从2.2-beta-1开始） 默认值是：false。 --&gt; &lt;!--boolean--&gt; &lt;useProjectAttachments/&gt; &lt;!-- 确定是否将传递依赖项包含在当前依赖项集的处理中。如果为true，那么include / excludes / useTransitiveFiltering将应用于传递依赖项构件以及主项目依赖项构件。 如果为false，则useTransitiveFiltering无意义，并且包含/排除仅影响项目的直接依赖关系。 默认情况下，这个值是真的。（从2.2-beta-1开始） 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;useTransitiveDependencies/&gt; &lt;!-- 确定此依赖项集中的包含/排除模式是否将应用于给定工件的传递路径。 如果为真，并且当前工件是由包含或排除模式匹配的另一个工件引入的传递依赖性，则当前工件具有与其相同的包含/排除逻辑。 默认情况下，此值为false，以保持与2.1版的向后兼容性。这意味着包含/排除仅仅直接应用于当前的工件，而不应用于传入的工件。（从2.2-beta-1） 默认值为：false。 --&gt; &lt;!--boolean--&gt; &lt;useTransitiveFiltering/&gt; &lt;/dependencySet&gt; &lt;/dependencySets&gt; &lt;!-- 如果设置为true，则此属性将所有模块包解包到指定的输出目录中。当设置为false时，模块包将作为归档（jar）包含在内。 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;unpack/&gt; &lt;!-- 允许指定包含和排除以及过滤选项，以指定从相关性工件解压缩的项目。（从2.2-beta-1开始） --&gt; &lt;unpackOptions&gt; &lt;!-- （许多） 文件和/或目录模式的集合，用于匹配将在解压缩时从归档文件中包含的项目。每个项目被指定为&lt;include&gt; some / path &lt;/ include&gt;（从2.2-beta-1开始） --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;includes/&gt; &lt;!-- （许多） 用于匹配项目的文件和/或目录模式的集合，在解压缩时将其从归档文件中排除。每个项目被指定为&lt;exclude&gt; some / path &lt;/ exclude&gt;（从2.2-beta-1开始） --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;excludes/&gt; &lt;!-- 是否使用构建配置中的属性过滤从档案中解压缩的文件中的符号。（从2.2-beta-1开始） 默认值是：false。 --&gt; &lt;!--boolean--&gt; &lt;filtered/&gt; &lt;!-- 设置文件的行尾。（从2.2开始）有效值： “keep” - 保留所有的行结束 “unix” - 使用Unix风格的行结尾 “lf” - 使用单个换行符结束符 “dos” - 使用DOS风格的行尾 “ crlf ” - 使用Carraige返回，换行符结束 --&gt; &lt;!--string--&gt; &lt;lineEnding/&gt; &lt;!-- 在计算受该集合影响的文件时，是否应该使用标准排除模式，例如那些匹配CVS和Subversion元数据文件的排除模式。为了向后兼容，默认值是true。（从2.2开始） 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;useDefaultExcludes/&gt; &lt;!-- 允许指定解压档案时使用的编码，支持指定编码的unarchiver。如果未指定，将使用归档程序默认值。Archiver默认值通常代表理智（modern）的values。 --&gt; &lt;!--string--&gt; &lt;encoding/&gt; &lt;/unpackOptions&gt; &lt;!-- 设置此程序集中包含的所有非UNPACKED依赖关系的映射模式。（由于2.2-beta-2; 2.2-beta-1使用$ &#123;artifactId&#125; - $ &#123;version&#125; $ &#123;dashClassifier？&#125;。$ &#123;extension&#125;作为默认值）注意：如果dependencySet指定unpack == true，则outputFileNameMapping将不要使用; 在这些情况下，使用outputDirectory。有关可用于outputFileNameMapping参数的条目的更多详细信息，请参阅插件FAQ。 默认值是：$ &#123;module.artifactId&#125; - $ &#123;module.version&#125; $ &#123;dashClassifier？&#125;。$ &#123;module.extension&#125;。 --&gt; &lt;!--string--&gt; &lt;outputFileNameMapping/&gt; &lt;/binaries&gt; &lt;/moduleSet&gt; &lt;/moduleSets&gt; &lt;!-- （许多） 指定在程序集中包含哪些文件组。fileSet通过提供一个或多个&lt;fileSet&gt;子元素来指定。 --&gt; &lt;!--List&lt;FileSet&gt;--&gt; &lt;fileSets&gt; &lt;!-- fileSet允许将文件组包含到程序集中。 --&gt; &lt;fileSet&gt; &lt;!-- 在计算受该集合影响的文件时，是否应该使用标准排除模式，例如那些匹配CVS和Subversion元数据文件的排除模式。为了向后兼容，默认值是true。（从2.2-beta-1开始） 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;useDefaultExcludes/&gt; &lt;!-- 设置输出目录相对于程序集根目录的根目录。例如，“日志”将把指定的文件放在日志目录中。 --&gt; &lt;!--string--&gt; &lt;outputDirectory/&gt; &lt;!-- （许多） 当&lt;include&gt;子元素存在时，它们定义一组要包含的文件和目录。如果不存在，则&lt;includes&gt;表示所有有效值。 --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;includes/&gt; &lt;!-- （许多） 当存在&lt;exclude&gt;子元素时，它们定义一组要排除的文件和目录。如果不存在，则&lt;excludes&gt;不表示排除。 --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;excludes/&gt; &lt;!-- 与UNIX权限类似，设置所包含文件的文件模式。这是一个 OCTAL VALUE。格式：（用户）（组）（其他）其中每个组件是Read = 4，Write = 2和Execute = 1的总和。 例如，值0644转换为用户读写，组和其他只读。默认值是0644. --&gt; &lt;!--string--&gt; &lt;fileMode/&gt; &lt;!-- 与UNIX权限类似，设置包含的目录的目录模式。这是一个 OCTAL VALUE。格式：（用户）（组）（其他）其中每个组件是Read = 4，Write = 2和Execute = 1的总和。 例如，值0755转换为用户读写，Group和其他只读。默认值是0755. --&gt; &lt;!--string--&gt; &lt;directoryMode/&gt; &lt;!-- 设置模块目录的绝对或相对位置。例如，“src / main / bin”会选择定义这个依赖关系的项目的这个子目录。 --&gt; &lt;!--string--&gt; &lt;directory/&gt; &lt;!-- 设置此文件集中文件的行结束符。有效值： “keep” - 保留所有的行结束 “unix” - 使用Unix风格的行尾（即“\\ n”） “lf” - 使用一个换行符结束符（即“\\ n”） “dos” - 使用DOS / Windows风格的行尾（即“\\ r \\ n”） “windows” - 使用DOS / Windows风格的行尾（即“\\ r \\ n”） “crlf” - 使用回车，换行符结尾（即“\\ r \\ n”） --&gt; &lt;!--string--&gt; &lt;lineEnding/&gt; &lt;!-- 是否在复制文件时过滤符号，使用构建配置中的属性。（从2.2-beta-1开始） 默认值是：false。 --&gt; &lt;!--boolean--&gt; &lt;filtered/&gt; &lt;/fileSet&gt; &lt;/fileSets&gt; &lt;!-- （许多） 指定在程序集中包含哪些单个文件。通过提供一个或多个&lt;file&gt;子元素来指定文件。 --&gt; &lt;!--List&lt;FileItem&gt;--&gt; &lt;files&gt; &lt;!-- 一个文件允许单个文件包含选项来更改不受fileSets支持的目标文件名。 --&gt; &lt;file&gt; &lt;!-- 设置要包含在程序集中的文件的模块目录的绝对路径或相对路径。 --&gt; &lt;!--string--&gt; &lt;source/&gt; &lt;!-- 设置输出目录相对于程序集根目录的根目录。例如，“日志”将把指定的文件放在日志目录中。 --&gt; &lt;!--string--&gt; &lt;outputDirectory/&gt; &lt;!-- 在outputDirectory中设置目标文件名。默认是与源文件相同的名称。 --&gt; &lt;!--string--&gt; &lt;destName/&gt; &lt;!-- 与UNIX权限类似，设置所包含文件的文件模式。这是一个八卦价值。格式：（用户）（组）（其他）其中每个组件是Read = 4，Write = 2和Execute = 1的总和。 例如，值0644转换为用户读写，组和其他只读。默认值是0644 --&gt; &lt;!--string--&gt; &lt;fileMode/&gt; &lt;!-- 设置此文件中文件的行结束符。有效值是： “keep” - 保留所有的行结束 “unix” - 使用Unix风格的行尾（即“\\ n”） “lf” - 使用一个换行符结束符（即“\\ n”） “dos” - 使用DOS / Windows风格的行尾（即“\\ r \\ n”） “windows” - 使用DOS / Windows风格的行尾（即“\\ r \\ n”） “crlf” - 使用回车，换行符结尾（即“\\ r \\ n”） --&gt; &lt;!--string--&gt; &lt;lineEnding/&gt; &lt;!-- 设置是否确定文件是否被过滤。 默认值是：false。 --&gt; &lt;!--boolean--&gt; &lt;filtered/&gt; &lt;/file&gt; &lt;/files&gt; &lt;!--List&lt;DependencySet&gt;--&gt; &lt;dependencySets&gt; &lt;!-- 依赖关系集允许在程序集中包含和排除项目依赖关系。 --&gt; &lt;dependencySet&gt; &lt;!-- 设置输出目录相对于程序集根目录的根目录。例如，“log”会将指定的文件放在归档根目录下的日志目录中。 --&gt; &lt;!--string--&gt; &lt;outputDirectory/&gt; &lt;!-- （许多） 当存在&lt;include&gt;子元素时，它们定义一组要包含的工件坐标。如果不存在，则&lt;includes&gt;表示所有有效值。 工件坐标可以以简单的groupId：artifactId形式给出，或者可以以groupId：artifactId：type [：classifier]：version的形式完全限定。 另外，可以使用通配符，如*：maven- * --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;includes/&gt; &lt;!-- （许多） 当存在&lt;exclude&gt;子元素时，它们定义一组依赖项工件坐标以排除。如果不存在，则&lt;excludes&gt;不表示排除。 工件坐标可以以简单的groupId：artifactId形式给出，或者可以以groupId：artifactId：type [：classifier]：version的形式完全限定。 另外，可以使用通配符，如*：maven- * --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;excludes/&gt; &lt;!-- 与UNIX权限类似，设置所包含文件的文件模式。这是一个 OCTAL VALUE。格式：（用户）（组）（其他）其中每个组件是Read = 4，Write = 2和Execute = 1的总和。 例如，值0644转换为用户读写，组和其他只读。默认值是0644 --&gt; &lt;!--string--&gt; &lt;fileMode/&gt; &lt;!-- 与UNIX权限类似，设置包含的目录的目录模式。这是一个 OCTAL VALUE。格式：（用户）（组）（其他）[Format: (User)(Group)(Other) ] 其中每个组件是Read = 4，Write = 2和Execute = 1的总和。 例如，值0755转换为用户读写，Group和其他只读。默认值是0755. --&gt; &lt;!--string--&gt; &lt;directoryMode/&gt; &lt;!-- 如果指定为true，那么在程序集创建过程中任何用于过滤实际构件的包含/排除模式都将导致构建失败，并显示错误。这是为了强调过时的包含或排除，或者表示程序集描述符配置不正确。（从2.2开始） 默认值是：false。 --&gt; &lt;!--boolean--&gt; &lt;useStrictFiltering/&gt; &lt;!-- 为此程序集中包含的所有依赖项设置映射模式。（从2.2-beta-2开始； 2.2-beta-1使用$ &#123;artifactId&#125; - $ &#123;version&#125; $ &#123;dashClassifier？&#125;。$ &#123;extension&#125;作为默认值）。 默认值是：$ &#123;artifact.artifactId&#125; - $ &#123;artifact.version&#125; $ &#123;dashClassifier？&#125;。$ &#123;artifact.extension&#125;。 --&gt; &lt;!--string--&gt; &lt;outputFileNameMapping/&gt; &lt;!-- 如果设置为true，则此属性将所有依赖项解包到指定的输出目录中。设置为false时，依赖关系将被包含为档案（jar）。只能解压jar，zip，tar.gz和tar.bz压缩文件。 默认值是：false。 --&gt; &lt;!--boolean--&gt; &lt;unpack/&gt; &lt;!-- 允许指定包含和排除以及过滤选项，以指定从相关性工件解压缩的项目。（从2.2-beta-1开始） --&gt; &lt;unpackOptions&gt; &lt;!-- （许多） 文件和/或目录模式的集合，用于匹配将在解压缩时从归档文件中包含的项目。每个项目被指定为&lt;include&gt; some / path &lt;/ include&gt;（从2.2-beta-1开始） --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;includes/&gt; &lt;!-- （许多） 用于匹配项目的文件和/或目录模式的集合，在解压缩时将其从归档文件中排除。每个项目被指定为&lt;exclude&gt; some / path &lt;/ exclude&gt;（从2.2-beta-1开始） --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;excludes/&gt; &lt;!-- 是否使用构建配置中的属性过滤从档案中解压缩的文件中的符号。（从2.2-beta-1开始） 默认值是：false。 --&gt; &lt;!--boolean--&gt; &lt;filtered/&gt; &lt;!-- 设置文件的行尾。（从2.2开始）有效值： “keep” - 保留所有的行结束 “unix” - 使用Unix风格的行结尾 “lf” - 使用单个换行符结束符 “dos” - 使用DOS风格的行尾 “crlf ” - 使用Carraige返回，换行符结束 --&gt; &lt;!--string--&gt; &lt;lineEnding/&gt; &lt;!-- 在计算受该集合影响的文件时，是否应该使用标准排除模式，例如那些匹配CVS和Subversion元数据文件的排除模式。为了向后兼容，默认值是true。（从2.2开始） 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;useDefaultExcludes/&gt; &lt;!-- 允许指定解压档案时使用的编码，支持指定编码的unarchiver。如果未指定，将使用归档程序默认值。Archiver默认值通常代表理智（modern）的values。 --&gt; &lt;!--string--&gt; &lt;encoding/&gt; &lt;/unpackOptions&gt; &lt;!-- 为此dependencySet设置依赖项范围。 默认值是：runtime。 --&gt; &lt;!--string--&gt; &lt;scope/&gt; &lt;!-- 确定当前项目构建过程中产生的工件是否应该包含在这个依赖集中。（从2.2-beta-1开始） 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;useProjectArtifact/&gt; &lt;!-- 确定当前项目构建过程中产生的附件是否应该包含在这个依赖集中。（从2.2-beta-1开始） 默认值是：false。 --&gt; &lt;!--boolean--&gt; &lt;useProjectAttachments/&gt; &lt;!-- 确定是否将传递依赖项包含在当前依赖项集的处理中。如果为true，那么include / excludes / useTransitiveFiltering将应用于传递依赖项构件以及主项目依赖项构件。 如果为false，则useTransitiveFiltering无意义，并且包含/排除仅影响项目的直接依赖关系。 默认情况下，这个值是真的。（从2.2-beta-1开始） 默认值是：true。 --&gt; &lt;!--boolean--&gt; &lt;useTransitiveDependencies/&gt; &lt;!-- 确定此依赖项集中的包含/排除模式是否将应用于给定工件的传递路径。 如果为真，并且当前工件是由包含或排除模式匹配的另一个工件引入的传递依赖性，则当前工件具有与其相同的包含/排除逻辑。 默认情况下，此值为false，以保持与2.1版的向后兼容性。这意味着包含/排除仅仅直接应用于当前的工件，而不应用于传入的工件。（从2.2-beta-1） 默认值为：false。 --&gt; &lt;!--boolean--&gt; &lt;useTransitiveFiltering/&gt; &lt;/dependencySet&gt; &lt;/dependencySets&gt; &lt;!-- 定义要包含在程序集中的Maven仓库。可用于存储库中的工件是项目的依赖工件。创建的存储库包含所需的元数据条目，并且还包含sha1和md5校验和。这对创建将被部署到内部存储库的档案很有用。 注意：目前，只有来自中央存储库的工件才被允许。 --&gt; &lt;!--List&lt;Repository&gt;--&gt; &lt;repositories&gt; &lt;repository&gt; &lt;!-- 设置输出目录相对于程序集根目录的根目录。例如，“log”会将指定的文件放在归档根目录下的日志目录中。 --&gt; &lt;!--string--&gt; &lt;outputDirectory/&gt; &lt;!-- （许多） 当存在&lt;include&gt;子元素时，它们定义一组包含的项目坐标。如果不存在，则&lt;includes&gt;表示所有有效值。 工件坐标可以以简单的groupId：artifactId形式给出，或者可以以groupId：artifactId：type [：classifier]：version的形式完全限定。 另外，可以使用通配符，如*：maven- * --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;includes/&gt; &lt;!-- （许多） 当存在&lt;exclude&gt;子元素时，它们定义一组要排除的项目工件坐标。如果不存在，则&lt;excludes&gt;不表示排除。 工件坐标可以以简单的groupId：artifactId形式给出，或者可以以groupId：artifactId：type [：classifier]：version的形式完全限定。 另外，可以使用通配符，如*：maven- * --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;excludes/&gt; &lt;!-- 与UNIX权限类似，设置所包含文件的文件模式。这是一个 OCTAL VALUE。格式：（用户）（组）（其他）其中每个组件是Read = 4，Write = 2和Execute = 1的总和。 例如，值0644转换为用户读写，组和其他只读。默认值是0644 --&gt; &lt;!--string--&gt; &lt;fileMode/&gt; &lt;!-- 与UNIX权限类似，设置包含的目录的目录模式。这是一个 OCTAL VALUE。格式：（用户）（组）（其他）[Format: (User)(Group)(Other) ] 其中每个组件是Read = 4，Write = 2和Execute = 1的总和。 例如，值0755转换为用户读写，Group和其他只读。默认值是0755. --&gt; &lt;!--string--&gt; &lt;directoryMode/&gt; &lt;!-- 如果设置为true，则此属性将触发创建存储库元数据，这将允许存储库用作功能性远程存储库。 默认值是：false。 --&gt; &lt;!--boolean--&gt; &lt;includeMetadata/&gt; &lt;!-- （许多） 指定要将一组工件与指定的版本对齐。groupVersionAlignment通过提供一个或多个&lt;groupVersionAlignment&gt;子元素来指定。 允许一组工件与指定的版本对齐。 --&gt; &lt;!--List&lt;GroupVersionAlignment&gt;--&gt; &lt;groupVersionAlignments&gt; &lt;groupVersionAlignment&gt; &lt;!-- 要为其对齐版本的工件的groupId。 --&gt; &lt;!--string--&gt; &lt;id/&gt; &lt;!-- 您想要将该组对齐的版本。 --&gt; &lt;!--string--&gt; &lt;version/&gt; &lt;!-- （许多） 当存在&lt;exclude&gt;子元素时，它们定义要排除的构件的artifactIds。如果不存在，则&lt;excludes&gt;不表示排除。排除是通过提供一个或多个&lt;exclude&gt;子元素来指定的。 --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;excludes/&gt; &lt;/groupVersionAlignment&gt; &lt;/groupVersionAlignments&gt; &lt;!-- 指定此存储库中包含的工件的范围。（从2.2-beta-1开始） 默认值是：runtime。 --&gt; &lt;!--string--&gt; &lt;scope/&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;!-- （许多） 指定要包含在程序集中的共享组件xml文件位置。指定的位置必须相对于描述符的基本位置。 如果描述符是通过类路径中的&lt;descriptorRef /&gt;元素找到的，那么它指定的任何组件也将在类路径中找到。 如果通过路径名通过&lt;descriptor /&gt;元素找到，则此处的值将被解释为相对于项目basedir的路径。 当找到多个componentDescriptors时，它们的内容被合并。检查 描述符组件 了解更多信息。 componentDescriptor通过提供一个或多个&lt;componentDescriptor&gt;子元素来指定。 --&gt; &lt;!--List&lt;String&gt;--&gt; &lt;componentDescriptors/&gt;&lt;/assembly&gt;","tags":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/tags/Maven/"},{"name":"Assembly","slug":"Assembly","permalink":"https://yaoyinglong.github.io/tags/Assembly/"}],"categories":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/categories/Maven/"}]},{"title":"Spring线程池跨线程数据共享","date":"2019-10-23T16:00:00.000Z","path":"Blog/框架/Spring/Spring线程池跨线程数据共享/","text":"在Spring Cloud中可能会用到sleuth做链路追踪，以及内部链路中需要用到Header中得一些数据，在单线程是没有问题得，但是在某些场景下就会有问题，比如上层业务系统得一个请求需要同时并发去调用基础服务得多个产品，这样请求到其他服务得链路追踪信息就不一样了等。 为了实现多线程并发情况下主线程和线程池的线程共享ThreadLocal变量，如MDC、RequestAttributes中的数据，需要自定义线程池及线程实现。 自定义线程池继承ThreadPoolTaskExecutor类重写execute和submit方法即可，Spring的ExecutorMethodInterceptor会拦截使用LazyTraceThreadPoolTaskExecutor装饰实际执行的task然后调用当前executor执行。代码如下： 1234567891011121314151617public class CusThreadPoolExecutor extends ThreadPoolTaskExecutor &#123; @Override public void execute(Runnable task) &#123; ServletRequestAttributes servletRequestAttributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes(); Map&lt;String, String&gt; contextOfMDC = MDC.getCopyOfContextMap(); Runnable cusTask = new CusInheritThreadVarRunnable(servletRequestAttributes, contextOfMDC, task); super.execute(cusTask); &#125; @Override public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; ServletRequestAttributes servletRequestAttributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes(); Map&lt;String, String&gt; contextOfMDC = MDC.getCopyOfContextMap(); Callable&lt;T&gt; cusTask = new CusInheritThreadVarCallable&lt;T&gt;(servletRequestAttributes, contextOfMDC, task); return super.submit(cusTask); &#125;&#125; 该线程池的使用和普通的线程池使用是一样。 只是在在提交到真正的线程池之前，会获取主线程中需要共享的ThreadLocal相关变量。然后将任务包装成一个新的Runnable或Callable，在子线程中执行任务之前，将ThreadLocal相关变量设置到子线程的ThreadLocalMap中，执行结束之前清空设置的ThreadLocal相关变量，防止不同线程中串数据。 Callable实现： 12345678910111213141516171819202122232425262728public class CusInheritThreadVarCallable&lt;V&gt; implements Callable&lt;V&gt; &#123; private Callable&lt;V&gt; delegate; private Map&lt;String, String&gt; contextOfMDC; private ServletRequestAttributes servletRequestAttributes; public CusInheritThreadVarCallable(ServletRequestAttributes servletRequestAttributes, Map&lt;String, String&gt; contextOfMDC, Callable&lt;V&gt; delegate) &#123; this.contextOfMDC = contextOfMDC; this.servletRequestAttributes = servletRequestAttributes; this.delegate = delegate; &#125; @Override public V call() throws Exception &#123; RestStrategyContext.clearCurrentContext(); //设置当前线程servletRequestAttributes RequestContextHolder.setRequestAttributes(servletRequestAttributes); //设置当前线程MDC MDC.setContextMap(contextOfMDC); V result; try &#123; result = delegate.call(); &#125; finally &#123; MDC.clear(); RequestContextHolder.resetRequestAttributes(); &#125; return result; &#125;&#125; Runnable实现： 12345678910111213141516171819202122232425262728public class CusInheritThreadVarRunnable implements Runnable &#123; private Runnable delegate; private Map&lt;String, String&gt; contextOfMDC; private ServletRequestAttributes servletRequestAttributes; public CusInheritThreadVarRunnable(ServletRequestAttributes servletRequestAttributes, Map&lt;String, String&gt; contextOfMDC, Runnable delegate) &#123; this.contextOfMDC = contextOfMDC; this.servletRequestAttributes = servletRequestAttributes; this.delegate = delegate; &#125; @Override public void run() &#123; RestStrategyContext.clearCurrentContext(); //设置当前线程servletRequestAttributes RequestContextHolder.setRequestAttributes(servletRequestAttributes); //设置当前线程MDC MDC.setContextMap(contextOfMDC); try &#123; // 执行 delegate.run(); &#125; finally &#123; // 清空 MDC.clear(); RequestContextHolder.resetRequestAttributes(); &#125; &#125;&#125; 线程池的配置如下： 1234567891011121314@Bean(name = \"processorExecutor\")public ThreadPoolTaskExecutor taskProcessorExecutor() &#123; CusThreadPoolExecutor executor = new CusThreadPoolExecutor(); executor.setCorePoolSize(taskPoolConfig.getCorePoolSize()); executor.setMaxPoolSize(taskPoolConfig.getMaxPoolSize()); executor.setQueueCapacity(taskPoolConfig.getQueueCapacity()); executor.setKeepAliveSeconds(taskPoolConfig.getKeepAliveSeconds()); executor.setThreadNamePrefix(\"CusTask-\"); executor.setRejectedExecutionHandler(cusCallerRunsPolicy); executor.setWaitForTasksToCompleteOnShutdown(true); executor.setAwaitTerminationSeconds(taskPoolConfig.getAwaitTerminationSeconds()); executor.initialize(); return executor;&#125; 对于线程池的配置需要注意的是，拒绝策略不要使用CallerRunsPolicy拒绝策略，该拒绝策略会在任务添加到线程池被拒绝时使用主线程执行该任务。在并发较高的情况下，拒绝策略生效，导致很多任务由主线程执行了，从而导致主线程中的MDC数据被清空了，从而导致一些trace信息丢失。可以自定义拒绝策略将任务丢回队列： 123456789101112public class CusCallerRunsPolicy implements RejectedExecutionHandler &#123; @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123; if (!executor.isShutdown()) &#123; try &#123; executor.getQueue().put(r); &#125; catch (InterruptedException e) &#123; log.error(\"Reject policy interrupted exception \", e); &#125; &#125; &#125;&#125;","tags":[{"name":"Spring，线程池","slug":"Spring，线程池","permalink":"https://yaoyinglong.github.io/tags/Spring，线程池/"}],"categories":[{"name":"框架","slug":"框架","permalink":"https://yaoyinglong.github.io/categories/框架/"},{"name":"Spring","slug":"框架/Spring","permalink":"https://yaoyinglong.github.io/categories/框架/Spring/"}]},{"title":"动态代理","date":"2019-09-09T16:00:00.000Z","path":"Blog/Java/基础/动态代理/","text":"代理的基础类 12345678910public interface Subject &#123; void doSomething(String param);&#125;public class RealSubject implements Subject &#123; @Override public void doSomething(String param) &#123; System.out.println(\"RealSubject do something \" + param); &#125;&#125; 静态代理1234567891011121314public class SubjectProxy implements Subject &#123; private Subject subject; public SubjectProxy(Subject subject) &#123; this.subject = subject; &#125; @Override public void doSomething(String param) &#123; System.out.println(\"Do something before\"); subject.doSomething(param); System.out.println(\"Do something after\"); &#125;&#125; JDK动态代理JDK动态代理是jre提供的类库，可直接使用不依赖第三方，但JDK的动态代理只能代理接口。首先创建一个代理类EnhaceInvocationHandler实现java.lang.reflect.InvocationHandler接口，重写invoke方法。在method.invoke方法调用前后添加我们需要增强的代码逻辑。 123456789101112131415161718192021222324252627282930313233public class EnhaceInvocationHandler implements InvocationHandler &#123; private Object target; public EnhaceInvocationHandler(Object target) &#123; this.target = target; &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; if (args != null) &#123; for (Object obj : args) &#123; System.out.println(\"args==\" + obj.toString()); &#125; &#125; else &#123; System.out.println(\"args==null\"); &#125; try &#123; System.out.println(\"Do something before\"); Object result = method.invoke(target, args); System.out.println(\"Do something after\"); return result; &#125; catch (Exception e) &#123; e.getCause().printStackTrace(); throw e; &#125; &#125; public Object creatProxyObj() &#123; return Proxy.newProxyInstance(target.getClass().getClassLoader(), target.getClass().getInterfaces(), this); &#125;&#125; 代理配置 123456789Subject realSubject = new RealSubject();Subject subject = (Subject) Proxy.newProxyInstance(Subject.class.getClassLoader(), new Class[]&#123;Subject.class&#125;, new EnhaceInvocationHandler(realSubject));subject.doSomething(\"AAAA\");EnhaceInvocationHandler handler = new EnhaceInvocationHandler(realSubject);Subject subject = (Subject) handler.creatProxyObj();subject.doSomething(\"AAAA\"); CGLib代理代理的目的是构造一个和被代理的对象同样行为的对象，一个对象的行为是在类中定义的，对象只是类的实例，故构造代理不一定非得通过持有、包装对象这一种方式。CGLib是通过继承父类所有的公有方法，然后重写这些方法，在重写时对这些方法增强。首先也是创建一个代理类CGLibProxy实现net.sf.cglib.proxy.MethodInterceptor接口重写intercept方法。 1234567891011121314151617public class CGLibProxy implements MethodInterceptor &#123; @Override public Object intercept(Object obj, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; System.out.println(\"Do something before\"); Object object = methodProxy.invokeSuper(obj, objects); System.out.println(\"Do something after\"); return object; &#125; public Object creatProxyObj(Class&lt;?&gt; clazz) &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(clazz); enhancer.setCallback(this); return enhancer.create(); &#125;&#125; 在配置代理的地方与JDK动态代理略有区别。并不要求委托类必须实现接口，底层采用asm字节码生成框架生成代理类的字节码，Enhancer是CGLib的字节码增强器，可以方便的对类进行扩展，内部调用GeneratorStrategy.generate方法生成代理类的字节码，CGLib动态代理不仅仅可以代理接口，还可以代理非接口类。 12345678910Subject realSubject = new RealSubject();Enhancer enhancer = new Enhancer();enhancer.setSuperclass(realSubject.getClass());enhancer.setCallback(new CGLibProxy());Subject subject = (Subject) enhancer.create();subject.doSomething(\"AAAA\");CGLibProxy proxy = new CGLibProxy();Subject subject = (Subject) proxy.creatProxyObj(realSubject.getClass());subject.doSomething(\"AAAA\"); CGLib动态代理中生成的字节码更加复杂，生成的代理类是委托类的子类，且不能处理被final关键字修饰的方法；JDK采用反射机制调用委托类的方法，CGLib采用类似索引的方式直接调用委托类方法；","tags":[{"name":"动态代理","slug":"动态代理","permalink":"https://yaoyinglong.github.io/tags/动态代理/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"基础","slug":"Java/基础","permalink":"https://yaoyinglong.github.io/categories/Java/基础/"}]},{"title":"反射基础","date":"2019-09-07T16:00:00.000Z","path":"Blog/Java/基础/反射基础/","text":"反射主要指程序可以访问、检测和修改他本身状态和行为的一种能力，程序在运行时能获取自身的信息；对于任意一个类，都能够获取到这个类的所有属性和方法，对于任意一个对象，都能够调用它的任意一个方法和属性，包括私有的方法和属性，这种动态获取的信息以及动态调用对象的方法的功能就称为Java语言的反射机制。 反射的优点：能使代码更灵活，更加容易实现面向对象，能够使我们很方便的创建灵活的代码，这些代码可以在运行时再装配，无需组件之间进行源代码的链接，体现了多态的应用，降低类之间的耦合性，可以动态的创建对象和编译； 反射的缺点：打破了Java的封装性，导致了Java对像的不安全，使软件的性能降低，复杂度增加，维护成本变高。 反射相关的主要API: java.lang.Class：代表一个类 java.lang.reflect.Method：代表类的方法 java.lang.reflect.Field：代表类的成员变量 java.lang.reflect.Constructor：代表类的构造方法 用于测试的基础类 123456789101112131415161718192021222324public class ReflectIssue &#123; public String publicParam = \"this is a reflect public parameter\"; private String privateParam = \"this is a reflect private parameter\"; public ReflectIssue() &#123; &#125; public ReflectIssue(String publicParam, String privateParam) &#123; this.publicParam = publicParam; this.privateParam = privateParam; &#125; private void reflectPrivate(String str) &#123; System.out.println(\"private : \" + str); &#125; public void reflectPublic(String str) &#123; System.out.println(\"public : \" + str); &#125; public void moreParam(String paramA, String paramB) &#123; System.out.println(\"paramA : \" + paramA + \", paramB：\" + paramB); &#125;&#125; Reflection方式获取类的Class对象有以下四种方式，实际应用中最常用的是通过Class.forName和classLoader的方式来获取Class对象。 123456789ReflectIssue reflectIssue = new ReflectIssue();Class clazz = reflectIssue.getClass();Class clazz = ReflectIssue.class;Class clazz = Class.forName(\"com.example.ReflectIssue\");ClassLoader classLoader = this.getClass().getClassLoader();Class clazz = classLoader.loadClass(\"com.example.ReflectIssue\"); getField不能获取私有属性，要获取私有属性使用getDeclaredField方法，该方法也可以用于获取public属性。如果要访问私有属性必须通过setAccessible将访问权限打开。如果在当前类中进行反射调用自己可以不用通过setAccessible打开权限。 1234567891011Class clazz = Class.forName(\"com.example.ReflectIssue\");ReflectIssue reflectIssue = (ReflectIssue) clazz.newInstance();Field publicParam = clazz.getField(\"publicParam\");System.out.println(publicParam.getName());System.out.println(publicParam.get(reflectIssue));Field privateParam = clazz.getDeclaredField(\"privateParam\");privateParam.setAccessible(true);System.out.println(privateParam.getName());System.out.println(privateParam.get(reflectIssue));privateParam.set(reflectIssue, \"new private param value\"); 同样针对于方法的获取，私有方法获取必须使用getDeclaredMethod方法，该方法也可以用于获取public方法，关于参数的列表可以直接传入一个数组，也可以按照顺序传入多个参数。私有方法的调用需要通过setAccessible方法打开权限。 1234567891011Method method = clazz.getMethod(\"reflectPublic\", String.class);method.invoke(clazz.newInstance(), \"this is a public function\");Method method = clazz.getMethod(\"reflectPublic\", new Class[]&#123;String.class&#125;);method.invoke(clazz.newInstance(), new Object[]&#123;\"this is a public function\"&#125;);Method reflectPrivate = clazz.getDeclaredMethod(\"reflectPrivate\", String.class);reflectPrivate.setAccessible(true);reflectPrivate.invoke(clazz.newInstance(), \"this is a private function\");((ReflectIssue) clazz.newInstance()).reflectPrivate(\"this is a private function\"); 在实际使用中可能需要用到多参数构造方法进行对象的实例化，多参数构造方法实例化类，使用getConstructor和getDeclaredConstructor都可以。getDeclaredConstructor可以获取私有构造方法。和私有属性私有方法访问一样私有构造方法访问需要通过Constructor的setAccessible打开访问权限。 1234567Class clazz = Class.forName(\"com.example.ReflectIssue\");Constructor constructor = clazz.getDeclaredConstructor(String.class, String.class);ReflectIssue reflectIssue2 = (ReflectIssue) constructor.newInstance(\"paramA\", \"paramB\");Constructor constructor = clazz.getDeclaredConstructor(String.class);constructor.setAccessible(true);ReflectIssue reflectIssue2 = (ReflectIssue) constructor.newInstance(\"paramA\"); MethodHandle方式也可以使用虚拟机提供的MethodHandle通过模拟字节码层次的调用来实现反射，需要主意得是，默认所有得方法得第一个参数一定是一个void参数。 1234567891011121314151617Class clazz = Class.forName(\"com.example.ReflectIssue\");MethodType methodType = MethodType.methodType(void.class, String.class);MethodHandle methodHandle = MethodHandles.lookup().findVirtual(clazz, \"reflectPublic\", methodType).bindTo(clazz.newInstance());methodHandle.invokeExact(\"a\");MethodType methodType = MethodType.methodType(void.class, String.class, String.class);MethodHandle methodHandle = MethodHandles.lookup().findVirtual(clazz, \"moreParam\", methodType).bindTo(clazz.newInstance());methodHandle.invokeExact(\"a\", \"b\");MethodHandles.Lookup lookup = MethodHandles.lookup();Method pm = clazz.getDeclaredMethod(\"reflectPrivate\", String.class);pm.setAccessible(true);MethodHandle methodHandle = lookup.unreflect(pm);methodHandle.invoke(clazz.newInstance(), \"a\");methodHandle.invokeExact((ReflectIssue) clazz.newInstance(), \"a\"); MethodHandle服务于所有java虚拟机上的语言，Reflection仅仅服务于java语言，Reflection在模拟Java代码层次的调用，而MethodHandle在模拟字节码层次的方法调用。Reflection是重量级，而MethodHandle是轻量级。MethodHandle可以进行内联优化，Reflection完全没有。但JDK8环境下MethodHandles.lookup方法是调用者敏感的。不同调用者访问权限不同，其结果也不同。","tags":[{"name":"反射","slug":"反射","permalink":"https://yaoyinglong.github.io/tags/反射/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"基础","slug":"Java/基础","permalink":"https://yaoyinglong.github.io/categories/Java/基础/"}]},{"title":"HashMap源码分析JDK8","date":"2019-09-06T16:00:00.000Z","path":"Blog/Java/基础/HashMap源码分析JDK8/","text":"数据存储结构JDK7中数据结构的存储由数组+链表的方式，因为数组是一组连续的内存空间，易查询，不易增删，而链表是不连续的内存空间，通过节点相互连接，易删除，不易查询。 JDK8中为了解决hash碰撞过于频繁和链表过长查询效率过低，采用数组+链表+红黑树的存储方式，当链表长度超过阈值8时，将链表转换为红黑树。极大的提高了查询效率。 在JDK8中默认容量，最大容量以及装载因子等默认值未发生变化。但是多了一些树相关的属性。 12345678910111213static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4;static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;static final float DEFAULT_LOAD_FACTOR = 0.75f;static final int TREEIFY_THRESHOLD = 8;static final int UNTREEIFY_THRESHOLD = 6;static final int MIN_TREEIFY_CAPACITY = 64;transient Node&lt;K,V&gt;[] table;transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet;transient int size;transient int modCount;int threshold;final float loadFactor; JDK8中hash方法有略微的简化了，可能是因为引用了红黑树，没有必要再对hashCode过于离散化。 1234static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 构造方法略微变化，最大的变化是将获取table的容量的方法tableSizeFor进行了优化，且移位方式由带符号右移变成了无符号又移，在构造方法中就计算好threshold。 123456789101112131415161718192021222324252627public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125;public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false);&#125;static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 添加方法在JDK8中table的扩容是在添加元素后再进行的。当table为空时通过resize()方法对table进行初始化，以及++size &gt; threshold时通过resize()方法对table的扩容。 如果新插入的元素的key不存在与链表中，则将新元素插入到对应链表的尾部，相对于JDK7的头插法，解决了并发情况下的死循环问题。当插入新元素后链表的长度大于等于8时，会通过treeifyBin方法将链表转换成红黑树。 如果新插入的元素的key存在于链表中，退出for (int binCount = 0; ; ++binCount)循环，将旧值替换为新的值。其中13、14行干的是同样的事。 如果table中存的已经是红黑树了，就直接进行红黑树的插入操作。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; for (int binCount = 0; ; ++binCount) &#123; if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; threshold的值在构造方法中被赋值为table的capacity，但是在resize()方法中被重新设置为capacity * loadFactor。这里对table的扩容以及threshold调整都是通过向左移位来完成的。 43行的if判断，主要是为了将老的table中的一个链表按照高位和低位拆分成两个链表。这个跟JDK是类是的，只不过JDK7是使用的头插法，这里是使用的尾插法，实现方式不一样。高位链表的数据下标按照JDK7的实现方式就为hiHead.hash &amp; (newCap - 1)其实就等于这里的j + oldCap。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; resize()方法中当table存储的元素是红黑树时，将通过split方法按照hash值得高低位将一颗树拆分成两棵树。如果拆分后树得节点个数小于等于UNTREEIFY_THRESHOLD = 6时，将树转换回链表。否正将loHead和hiHead转换成红黑树。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859final void split(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int index, int bit) &#123; TreeNode&lt;K,V&gt; b = this; // Relink into lo and hi lists, preserving order TreeNode&lt;K,V&gt; loHead = null, loTail = null; TreeNode&lt;K,V&gt; hiHead = null, hiTail = null; int lc = 0, hc = 0; for (TreeNode&lt;K,V&gt; e = b, next; e != null; e = next) &#123; next = (TreeNode&lt;K,V&gt;)e.next; e.next = null; if ((e.hash &amp; bit) == 0) &#123; if ((e.prev = loTail) == null) loHead = e; else loTail.next = e; loTail = e; ++lc; &#125; else &#123; if ((e.prev = hiTail) == null) hiHead = e; else hiTail.next = e; hiTail = e; ++hc; &#125; &#125; if (loHead != null) &#123; if (lc &lt;= UNTREEIFY_THRESHOLD) tab[index] = loHead.untreeify(map); else &#123; tab[index] = loHead; if (hiHead != null) // (else is already treeified) loHead.treeify(tab); &#125; &#125; if (hiHead != null) &#123; if (hc &lt;= UNTREEIFY_THRESHOLD) tab[index + bit] = hiHead.untreeify(map); else &#123; tab[index + bit] = hiHead; if (loHead != null) hiHead.treeify(tab); &#125; &#125;&#125;final Node&lt;K,V&gt; untreeify(HashMap&lt;K,V&gt; map) &#123; Node&lt;K,V&gt; hd = null, tl = null; for (Node&lt;K,V&gt; q = this; q != null; q = q.next) &#123; Node&lt;K,V&gt; p = map.replacementNode(q, null); if (tl == null) hd = p; else tl.next = p; tl = p; &#125; return hd;&#125;","tags":[{"name":"HashMap","slug":"HashMap","permalink":"https://yaoyinglong.github.io/tags/HashMap/"},{"name":"JDK8","slug":"JDK8","permalink":"https://yaoyinglong.github.io/tags/JDK8/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"基础","slug":"Java/基础","permalink":"https://yaoyinglong.github.io/categories/Java/基础/"}]},{"title":"HashMap源码分析JDK7","date":"2019-09-06T16:00:00.000Z","path":"Blog/Java/基础/HashMap源码分析JDK7/","text":"哈希算法 直接定址法：直接以关键字k或者k加上某个常数（k+c）作为哈希地址。 数字分析法：提取关键字中取值比较均匀的数字作为哈希地址。 除留余数法：用关键字k除以某个不大于哈希表长度m的数p，将所得余数作为哈希表地址。 分段叠加法：按照哈希表地址位数将关键字分成位数相等的几部分，其中最后一部分可以比较短。然后将这几部分相加，舍弃最高进位后的结果就是该关键字的哈希地址。 平方取中法：如果关键字各个部分分布都不均匀的话，可以先求出它的平方值，然后按照需求取中间的几位作为哈希地址。 伪随机数法：采用一个伪随机数当作哈希函数 解决碰撞算法衡量一个哈希函数的好坏的重要指标就是发生碰撞的概率以及发生碰撞的解决方案。任何哈希函数基本都无法彻底避免碰撞，常见的解决碰撞的方法有以下几种： 开放定址法：开放定址法就是一旦发生了冲突，就去寻找下一个空的散列地址，只要散列表足够大，空的散列地址总能找到，并将记录存入。 链地址法：将哈希表的每个单元作为链表的头结点，所有哈希地址为i的元素构成一个同义词链表。即发生冲突时就把该关键字链在以该单元为头结点的链表的尾部。 再哈希法：当哈希地址发生冲突用其他的函数计算另一个哈希函数地址，直到冲突不再产生为止。 建立公共溢出区：将哈希表分为基本表和溢出表两部分，发生冲突的元素都放入溢出表中。 数据存储结构HashMap是由数组和链表来实现的对数据的存储，采用Entry数组来存储key-value对，每一个键值对组成了一个Entry实体，Entry类实际上是一个单向的链表结构，它具有Next指针，可以连接下一个Entry实体，以此来解决Hash冲突的问题。 123456static class Entry&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final K key; V value; Entry&lt;K,V&gt; next; int hash;&#125; hashSeed问题对key的hashCode进行了二次hash，即hash扰动，以获得更好的散列值。这里做二次hash的目的是避免，自定义对象的hashCode方法，算出来的hashCode离散性比较差，从而导致某些链表特别长，而有些特别短，从而导致性能差。 1234567891011final int hash(Object k) &#123; int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; h ^= k.hashCode(); h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);&#125; 上面用到的hashSeed值在HashMap初始化时默认为0，根据源码来看hashSeed可能会在初始化table时通过inflateTable中调用的initHashSeedAsNeeded方法被重新设置。currentAltHashing显然为false，useAltHashing通过下面分析可知其值为也为false，故initHashSeedAsNeeded始终返回false，而hashSeed值始终得不到重新设置，所以其始终为0。 123456789final boolean initHashSeedAsNeeded(int capacity) &#123; boolean currentAltHashing = hashSeed != 0; boolean useAltHashing = sun.misc.VM.isBooted() &amp;&amp; (capacity &gt;= Holder.ALTERNATIVE_HASHING_THRESHOLD); boolean switching = currentAltHashing ^ useAltHashing; if (switching) &#123; hashSeed = useAltHashing ? sun.misc.Hashing.randomHashSeed(this) : 0; &#125; return switching;&#125; sun.misc.VM.isBooted()的源码如下，但是实际通过调用发现其返回值为true。 1234private static volatile boolean booted = false;public static boolean isBooted() &#123; return booted;&#125; 而关于Holder.ALTERNATIVE_HASHING_THRESHOLD，如下所示该值取决于altThreshold的值，实际条用发现该值其实为null，故Holder.ALTERNATIVE_HASHING_THRESHOLD为Integer.MAX_VALUE。 123456789101112131415161718192021private static class Holder &#123; static final int ALTERNATIVE_HASHING_THRESHOLD; static &#123; String altThreshold = java.security.AccessController.doPrivileged( new sun.security.action.GetPropertyAction(\"jdk.map.althashing.threshold\")); int threshold; try &#123; threshold = (null != altThreshold) ? Integer.parseInt(altThreshold) : ALTERNATIVE_HASHING_THRESHOLD_DEFAULT; if (threshold == -1) &#123; threshold = Integer.MAX_VALUE; &#125; if (threshold &lt; 0) &#123; throw new IllegalArgumentException(\"value must be positive integer.\"); &#125; &#125; catch(IllegalArgumentException failed) &#123; throw new Error(\"Illegal value for 'jdk.map.althashing.threshold'\", failed); &#125; ALTERNATIVE_HASHING_THRESHOLD = threshold; &#125;&#125; 构造方法HashMap的前三个构造方法仅仅是给负载系数loadFactor和数组容量阈值threshold赋值，并不会对数组table进行填充初始化等。HashMap的填充是在真正使用时才会通过inflateTable方法进行填充。如HashMap(Map&lt;? extends K, ? extends V&gt; m)、put(K key, V value)、putAll(Map&lt;? extends K, ? extends V&gt; m)等方法。 1234567891011121314151617181920212223242526272829303132333435363738394041static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4;static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;static final float DEFAULT_LOAD_FACTOR = 0.75f;static final Entry&lt;?,?&gt;[] EMPTY_TABLE = &#123;&#125;;// 用于存储链表数据transient Entry&lt;K,V&gt;[] table = (Entry&lt;K,V&gt;[]) EMPTY_TABLE;// 存储KV的数量, 所有链表元素总和transient int size;// threshold=capacity*loadFactor，size大于threshold时会执行resize操作int threshold;// 装载因子，用来衡量HashMap满的程度final float loadFactor;// 记录当前集合被修改的次数: 添加，删除，为了实现快速失败的机制transient int modCount;public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); this.loadFactor = loadFactor; threshold = initialCapacity; init();&#125;public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125;public HashMap() &#123; this(DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR);&#125;public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this(Math.max((int) (m.size() / DEFAULT_LOAD_FACTOR) + 1, DEFAULT_INITIAL_CAPACITY), DEFAULT_LOAD_FACTOR); inflateTable(threshold); putAllForCreate(m);&#125; 表的初始化inflateTable方法是为了初始化数组table，当通过构造方法创建HashMap时设置了initialCapacity，但是实际上创建数组时，使用的并不是我们设置initialCapacity来创建的数组的长度，而是通过roundUpToPowerOf2方法对数组容量进行了优化，不管怎么设置initialCapacity大小，数组容量始终是2的幂，且是大于等于threshold的最近的2的幂。也为后续通过indexFor方法为hash值取模起到帮助。 highestOneBit方法是为了获取二进制数据的最高位，低位全部置0，在调用highestOneBit方法之所以传入的是(number - 1) &lt;&lt; 1而不是直接传入number &lt;&lt; 1，因为若number本身就是2的幂，就会造成将数组容量扩大一倍，若number = 16期望返回的是16，若传入number &lt;&lt; 1将放回32. 12345678910111213141516171819202122private void inflateTable(int toSize) &#123; int capacity = roundUpToPowerOf2(toSize); threshold = (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1); table = new Entry[capacity]; initHashSeedAsNeeded(capacity);&#125;// 获取大于等于number的最接近的2的幂的数作为数组的容量private static int roundUpToPowerOf2(int number) &#123; return number &gt;= MAXIMUM_CAPACITY ? MAXIMUM_CAPACITY : (number &gt; 1) ? Integer.highestOneBit((number - 1) &lt;&lt; 1) : 1;&#125;// 获取数据二进制的最高位，低位全部置0public static int highestOneBit(int i) &#123; i |= (i &gt;&gt; 1); i |= (i &gt;&gt; 2); i |= (i &gt;&gt; 4); i |= (i &gt;&gt; 8); i |= (i &gt;&gt; 16); return i - (i &gt;&gt;&gt; 1);&#125; 添加方法当存在相同的key且hash相同时，是替换已有的值，并将旧值返回，而不知直接插入到链表中。之所以即要判断散列值也要判断key，是因为不同的输入可能会散列成相同的输出。根据同一散列函数计算出的散列值如果不同，那么输入值肯定也不同。但是，根据同一散列函数计算出的散列值如果相同，输入值不一定相同。同一散列函数计算出的散列值相同的现象叫做碰撞。 12345678910111213141516171819202122public V put(K key, V value) &#123; if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; if (key == null) return putForNullKey(value); int hash = hash(key); int i = indexFor(hash, table.length); for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; addEntry(hash, key, value, i); return null;&#125; 仅当 b = 2^n 时位运算才可以转换成取模运算，a % b = a &amp; (b - 1) 。故HashMap才将初始长度设置为 16，且扩容只能是以 2 的倍数扩容。由上面可知数组容量始终是2的幂，故可通过h &amp; (length-1)对hash值取余，从而获取对应的table数组的下标。使用位运算代替取模运算，除了性能之外，还有一个好处就是可以很好的解决负数的问题。 123static int indexFor(int h, int length) &#123; return h &amp; (length-1);&#125; 通过put方法中key为空的情况调用的putForNullKey()方法可知，HashMap中key为空的数据始终是存储到数组table下标为0的链表中。 12345678910111213private V putForNullKey(V value) &#123; for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) &#123; if (e.key == null) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; addEntry(0, null, value, 0); return null;&#125; table数组的长度并不是初始化后就固定不变了，将链表变得非常长后效率将变得低下，故当元素个数大于等于threshold = capacity * loadFactor时且该数组下标对应的链表不为空，就对数组进行扩容。且是按两倍进行扩容。并将数据从旧的table中拷贝到新的table中。在createEntry仅仅只有两行代码，实现了数据在链表中的头插法插入。 1234567891011121314151617181920212223242526272829void addEntry(int hash, K key, V value, int bucketIndex) &#123; if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; resize(2 * table.length); hash = (null != key) ? hash(key) : 0; bucketIndex = indexFor(hash, table.length); &#125; createEntry(hash, key, value, bucketIndex);&#125;void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; Entry[] newTable = new Entry[newCapacity]; transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);&#125;void createEntry(int hash, K key, V value, int bucketIndex) &#123; Entry&lt;K,V&gt; e = table[bucketIndex]; table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++;&#125; 由于newCapacity容量变化了，故indexFor返回的数据下标将可能变化或变成另一个固定的值，故旧的table中同一个链表的数据拷贝到新的table中可能会拆分成两个链表，且将旧表中的数据使用的头插法进行拷贝到新的table中的链表中，链表中的数据将被反序。而不是直接将数组的前N个元素对拷贝到新的数组中。 123456789101112131415void transfer(Entry[] newTable, boolean rehash) &#123; int newCapacity = newTable.length; for (Entry&lt;K,V&gt; e : table) &#123; while(null != e) &#123; Entry&lt;K,V&gt; next = e.next; if (rehash) &#123; e.hash = null == e.key ? 0 : hash(e.key); &#125; int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; newTable[i] = e; e = next; &#125; &#125;&#125; 在1.8之前，新插入的元素都是放在了链表的头部位置，但是这种操作在高并发的环境下容易导致死锁，所以1.8之后，新插入的元素都放在了链表的尾部。 获取方法首先计算hash值通过indexFor()方法得到该key在table中的存储位置，遍历链表，在获取数据时不仅判断了hash值是否相等，还判断了key是否相等，故有时候重写hashCode和equals方法尤为重要。 123456789101112131415161718192021public V get(Object key) &#123; if (key == null) return getForNullKey(); Entry&lt;K,V&gt; entry = getEntry(key); return null == entry ? null : entry.getValue();&#125;final Entry&lt;K,V&gt; getEntry(Object key) &#123; if (size == 0) &#123; return null; &#125; int hash = (key == null) ? 0 : hash(key); for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; return null;&#125;","tags":[{"name":"HashMap","slug":"HashMap","permalink":"https://yaoyinglong.github.io/tags/HashMap/"},{"name":"JDK7","slug":"JDK7","permalink":"https://yaoyinglong.github.io/tags/JDK7/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"基础","slug":"Java/基础","permalink":"https://yaoyinglong.github.io/categories/Java/基础/"}]},{"title":"MySQL事务","date":"2019-09-04T16:00:00.000Z","path":"Blog/DB/MySQL事务/","text":"","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yaoyinglong.github.io/tags/MySQL/"},{"name":"事务","slug":"事务","permalink":"https://yaoyinglong.github.io/tags/事务/"}],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"MySQL锁机制","date":"2019-09-04T16:00:00.000Z","path":"Blog/DB/MySQL锁机制/","text":"表级锁行级锁页面锁","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yaoyinglong.github.io/tags/MySQL/"}],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"索引的原理与使用","date":"2019-09-04T16:00:00.000Z","path":"Blog/DB/索引的原理与使用/","text":"","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yaoyinglong.github.io/tags/MySQL/"}],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"位运算","date":"2019-09-02T16:00:00.000Z","path":"Blog/Java/基础/位运算/","text":"字节、字、位、比特1位 = 1比特， 1字节 = 8位，1字=2字节， 1Byte=8bit 1B = 8bit， 1KB = 1024B 位：计算机最小存储单位，简记为b，也成为比特bit，计算机中用0和1来表示数据，一个0或1就代表1位。 比特（bit）：也是二进制数字中的位，信息量的最小单位。 字节（Byte）：计算存储容量的计量单位，一个字节等于八位。习惯上用B表示。 字：计算机进行数据处理时，一次存取、加工和传送的数据长度称为字（word），一个字通常由一个或多个（一般是字节的整数位）字节构成。如286微机的字由2个字节组成；486微机的字由4个字节组成。 位移运算Java中有三个位移运算： &lt;&lt;：左移：正数高位丢弃，低位补0，负数符号位保持不变 &gt;&gt;：右移：正数低位丢弃，高位补0；负数高位补1 &gt;&gt;&gt;：无符号右移：低位丢弃，高位补0，符号位也会跟着一起移动 123456System.out.println(2 &lt;&lt; 1); // 4System.out.println(2 &gt;&gt; 1); // 1System.out.println(2 &gt;&gt;&gt; 1); // 1System.out.println(-2 &lt;&lt; 1); // -4System.out.println(-2 &gt;&gt; 1); // -1System.out.println(-2 &gt;&gt;&gt; 1); // 2147483647 原码、反码、补码原码，利用二进制中的第一位来表示符号位，0表示正数，1表示负数。 反码，正数的反码和原码一样，负数的反码就是在原码的基础上符号位保持不变，其他位取反。 补码，补码是为了解决反码的问题，正数的补码和原码、反码一样，负数的补码就是反码+1。 十进制 原码 反码 补码 2 0000 0010 0000 0010 0000 0010 -2 1000 0010 1111 1101 1111 1110 计算机在进行运算时是不会去管符号位的，计算时用到的时补码，让符号位也参与运算，最后将运算得到的结果再转换成源码即可。 负数位移运算-2用原码表示为10000000 00000000 00000000 00000010 -2用反码表示为11111111 11111111 11111111 11111101 -2用补码表示为11111111 11111111 11111111 11111110 -2 &lt;&lt; 1，表示-2的补码左移一位后为11111111 11111111 11111111 11111100，该补码对应的反码为 12311111111 11111111 11111111 11111100- 1= 11111111 11111111 11111111 11111011 该反码对应的原码为：符号位不变，其他位取反，为10000000 00000000 00000000 00000100，表示-4。所以-2 &lt;&lt; 1 = -4。 -2 &gt;&gt; 1，表示-2的补码右移一位后（高位补1）为11111111 11111111 11111111 11111111，该补码对应的反码为 12311111111 11111111 11111111 11111111- 1= 11111111 11111111 11111111 11111110 该反码对应的原码为：符号位不变，其他位取反，为10000000 00000000 00000000 00000001，表示-1。所以-2 &gt;&gt; 1 = -1。 无符号右移在对补码进行移动时，符号位是固定不动的，而无符号右移是指在进行移动时，符号位也会跟着一起移动。比如-2 &gt;&gt;&gt; 1。 -2用原码表示为10000000 00000000 00000000 00000010 -2用反码表示为11111111 11111111 11111111 11111101 -2用补码表示为11111111 11111111 11111111 11111110 -2的补码右移1位为：01111111 11111111 11111111 11111111 右移后的补码对应的反码、原码为：01111111 11111111 11111111 11111111 ，因为现在的符号位为0表示正数，正数的原、反、补码都相同，所以-2 &gt;&gt;&gt; 1 = 2147483647 ~（取反运算）12345： 00000000 00000000 00000000 00000101~5： 11111111 11111111 11111111 11111010 // 补码形式 11111111 11111111 11111111 11111001 // 反码 10000000 00000000 00000000 00000110 // 原码 基本应用交换内容12345void swap(int a, int b) &#123; a ^= b; b ^= a; a ^= b;&#125; 判断奇偶1(a &amp; 1) == 0 求平均数123int average(int x, int y) &#123; return (x &amp; y) + ((x ^ y) &gt;&gt; 1);&#125; 获取大于等于i的最接近的2的幂123456789101112131415161718192021// 获取数据二进制的最高位，低位全部置0public static int highestOneBit(int i) &#123; i |= (i &gt;&gt; 1); i |= (i &gt;&gt; 2); i |= (i &gt;&gt; 4); i |= (i &gt;&gt; 8); i |= (i &gt;&gt; 16); return i - (i &gt;&gt;&gt; 1);&#125;highestOneBit((number - 1) &lt;&lt; 1) static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125;","tags":[{"name":"位运算","slug":"位运算","permalink":"https://yaoyinglong.github.io/tags/位运算/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"基础","slug":"Java/基础","permalink":"https://yaoyinglong.github.io/categories/Java/基础/"}]},{"title":"注解实现及应用","date":"2019-09-02T16:00:00.000Z","path":"Blog/Java/基础/注解实现及应用/","text":"","tags":[{"name":"注解","slug":"注解","permalink":"https://yaoyinglong.github.io/tags/注解/"}],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"序列化","date":"2019-09-02T16:00:00.000Z","path":"Blog/Java/基础/序列化/","text":"","tags":[{"name":"序列化","slug":"序列化","permalink":"https://yaoyinglong.github.io/tags/序列化/"}],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"ConcurrentHashMap源码分析","date":"2019-09-01T16:00:00.000Z","path":"Blog/Java/基础/ConcurrentHashMap源码分析/","text":"","tags":[{"name":"ConcurrentHashMap","slug":"ConcurrentHashMap","permalink":"https://yaoyinglong.github.io/tags/ConcurrentHashMap/"}],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"CAS原理及使用场景","date":"2019-09-01T16:00:00.000Z","path":"Blog/Java/并发/CAS原理及使用场景/","text":"","tags":[{"name":"CAS","slug":"CAS","permalink":"https://yaoyinglong.github.io/tags/CAS/"},{"name":"并发","slug":"并发","permalink":"https://yaoyinglong.github.io/tags/并发/"}],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"Synchronized总结","date":"2019-09-01T16:00:00.000Z","path":"Blog/Java/并发/Synchronized总结/","text":"","tags":[{"name":"Synchronized","slug":"Synchronized","permalink":"https://yaoyinglong.github.io/tags/Synchronized/"},{"name":"并发","slug":"并发","permalink":"https://yaoyinglong.github.io/tags/并发/"}],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"Volatile源码分析","date":"2019-09-01T16:00:00.000Z","path":"Blog/Java/并发/Volatile源码分析/","text":"","tags":[{"name":"Volatile","slug":"Volatile","permalink":"https://yaoyinglong.github.io/tags/Volatile/"},{"name":"并发","slug":"并发","permalink":"https://yaoyinglong.github.io/tags/并发/"}],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"ThreadLocal原理","date":"2019-09-01T16:00:00.000Z","path":"Blog/Java/并发/ThreadLocal原理/","text":"","tags":[{"name":"并发","slug":"并发","permalink":"https://yaoyinglong.github.io/tags/并发/"},{"name":"ThreadLocal","slug":"ThreadLocal","permalink":"https://yaoyinglong.github.io/tags/ThreadLocal/"}],"categories":[{"name":"hide","slug":"hide","permalink":"https://yaoyinglong.github.io/categories/hide/"}]},{"title":"Win实用工具","date":"2019-07-29T16:00:00.000Z","path":"Blog/杂记/Win实用工具/","text":"PotPlayer非常好用的视频播放器。 Typora轻便简洁的Markdown编辑器，支持即时渲染 TeamViewer用于远程控制的应用程序 Notepad++文本编辑器","tags":[{"name":"工具","slug":"工具","permalink":"https://yaoyinglong.github.io/tags/工具/"}],"categories":[{"name":"杂记","slug":"杂记","permalink":"https://yaoyinglong.github.io/categories/杂记/"}]},{"title":"Linux常用技巧","date":"2019-06-27T09:26:09.588Z","path":"Blog/Linux/Linux常用技巧/","text":"SecureCRT无操作自动登出echo $TMOUT 查看无操作自动登出时间，将该时间稍微调小一点设置到SecureCRT Session中 SecureCRT文件上传下载rz：将文件从本地上传到服务器 sz [file1] [file2] [dir/*]：本地从服务器上下载文件","tags":[{"name":"Linux","slug":"Linux","permalink":"https://yaoyinglong.github.io/tags/Linux/"}],"categories":[{"name":"Linux","slug":"Linux","permalink":"https://yaoyinglong.github.io/categories/Linux/"}]},{"title":"JAVA实用工具","date":"2019-05-31T16:00:00.000Z","path":"Blog/杂记/JAVA实用工具/","text":"ArthasJava 线上诊断工具 EasyExcel用来对 Java 进行解析、生成 Excel 的框架，它重写了 poi 对 07 版 Excel 的解析，原本一个 3M 的 Excel 用 POI sax 需要 100M 左右内存，EasyExcel 可降低到 KB 级别，并且再大的 excel 也不会出现内存溢出的情况。03 版依赖 POI 的 sax 模式。在上层做了模型转换的封装，让使用者更加简单方便。 Postman接口调试工具 LoadRunner压测工具","tags":[{"name":"工具","slug":"工具","permalink":"https://yaoyinglong.github.io/tags/工具/"}],"categories":[{"name":"杂记","slug":"杂记","permalink":"https://yaoyinglong.github.io/categories/杂记/"}]},{"title":"Hystrix总结","date":"2019-05-25T16:00:00.000Z","path":"Blog/框架/Spring/Hystrix总结/","text":"在项目中需要对某些接口进行限流和熔断处理，防止由于某些接口资源消耗过大影响到整个的所有接口，防止单独的依赖耗尽资源；对一些依赖服务进行隔离，防止当依赖服务不可用或者响应非常缓慢导致整个应用不可用，阻止故障的连锁反应。过载立即切断并快速失败防止排队。 Hystrix有4种参数配置，优先级由低到高分别为：内置全局默认值、动态全局默认属性、内置实例默认值、动态配置实例属性。 基于编程式基于编程式使用Hystrix，只需继承HystrixCommand或HystrixObservableCommand，区别在于HystrixCommand命令逻辑卸载run()方法中，且由新创建线程执行，一个实例只能向调用程序发送单条数据。HystrixObservableCommand命令逻辑写在construct()方法中，由调用程序线程执行，一个实例可以顺序发送多条数据。 HystrixCommand命令有execute()、queue()、observe()、toObservable()4个方法来触发执行run()方法。HystrixObservableCommand命令只有observe()、toObservable()2个方法来触发执行construct()方法。 execute() 以同步堵塞方式执行 queue() 以异步非堵塞方式执行，通过Future.get()获取run()返回结果 observe() 事件注册前执行run()或construct()方法 toObservable() 事件注册后执行run()或construct()方法 继承HystrixCommand实现自己的Command，在构造方法中配置需要的参数，后续章节对具体配置进行详细描述。 123456789101112131415161718192021222324252627282930313233public class HelloWorldCommand extends HystrixCommand&lt;JSONObject&gt; &#123; private DataRequest request; protected HelloWorldCommand(DataRequest request) &#123; HystrixCommandProperties.Setter propertiesSetter = HystrixCommandProperties.Setter() .withCircuitBreakerEnabled(true) .withRequestCacheEnabled(false) .withRequestLogEnabled(false) .withExecutionIsolationStrategy() .withExecutionIsolationSemaphoreMaxConcurrentRequests(80) .withFallbackIsolationSemaphoreMaxConcurrentRequests(80) .withCircuitBreakerRequestVolumeThreshold(30) .withCircuitBreakerSleepWindowInMilliseconds(5000) .withExecutionTimeoutInMilliseconds(timeOut); HystrixCommandGroupKey groupKey = HystrixCommandGroupKey.Factory.asKey(\"requestData\"); HystrixCommand.Setter setter = HystrixCommand.Setter.withGroupKey(groupKey) .andCommandKey(HystrixCommandKey.Factory.asKey(\"data-\"+ Id)) .andCommandPropertiesDefaults(propertiesSetter) .andThreadPoolKey(HystrixThreadPoolKey.Factory.asKey(\"requestData\")); super(setter); this.request = request; &#125; @Override protected JSONObject run() &#123; return request.executeRequest(); &#125; @Override protected JSONObject getFallback() &#123;&#125;&#125; 调用HystrixCommand的执行方法发起实际请求，execute()方法同步调用： 12HelloWorldCommand command = new HelloWorldCommand(request);JSONObject result = command.execute(); queue()方法异步调用： 123HelloWorldCommand command = new HelloWorldCommand(request);Future&lt;JSONObject&gt; future = command.queue();JSONObject result = future.get(10000, TimeUnit.MILLISECONDS); observe()方法，注册观察者事件订阅，事件注册前执行： 12Observable&lt;JSONObject&gt; observable = new HelloWorldCommand(request).observe();observable.subscribe(result1 -&gt; System.out.println(\"Observable call--&gt; \" + result1)); observe()方法，注册完整执行生命周期事件，事件注册前执行： 1234567891011121314Observable&lt;JSONObject&gt; observable = new HelloWorldCommand(request).observe();observable.subscribe(new Observer&lt;JSONObject&gt;() &#123; //onNext/onError完成之后最后回调 @Override public void onCompleted() &#123;&#125; // 当产生异常时回调 @Override public void onError(Throwable throwable) &#123;&#125; // 获取结果后回调 @Override public void onNext(JSONObject s) &#123;&#125;&#125;); toObservable()方法，注册观察者事件订阅，事件注册后执行： 1234567891011121314Observable&lt;JSONObject&gt; toObservable = new HelloWorldCommand(request).toObservable();toObservable.subscribe(new Observer&lt;JSONObject&gt;() &#123; //onNext/onError完成之后最后回调 @Override public void onCompleted() &#123;&#125; // 当产生异常时回调 @Override public void onError(Throwable throwable) &#123;&#125; // 获取结果后回调 @Override public void onNext(JSONObject s) &#123;&#125;&#125;); 基于注解式注解使用方式和编程式大致相同，只是属性参数配置都注解化了。三个核心注解分别为@HystrixCommand、@HystrixProperty和@HystrixCollapser。 注解同步执行： 123456789101112131415public class HelloWorldHystrixAnnotation &#123; @Autowired private DataClient dataClient; @HystrixCommand(groupKey = \"helloWorldHystrixAnnotation\", commandKey = \"helloWorldHystrixAnnotationSync\", fallbackMethod = \"fallback\") public JSONObject executeRequest(String param) &#123; return dataClient.retrieveData(param); &#125; public JSONObject fallback() &#123; return new JSONObject(); &#125;&#125; 注解异步执行： 1234567891011121314151617181920public class HelloWorldHystrixAnnotationAsync &#123; @Autowired private DataClient dataClient; @HystrixCommand(groupKey = \"helloWorldHystrixAnnotation\", commandKey = \"helloWorldHystrixAnnotationAsync\", fallbackMethod = \"fallback\") public Future&lt;JSONObject&gt; run(String param) &#123; return new AsyncResult&lt;JSONObject&gt;() &#123; @Override public JSONObject invoke() &#123; return dataClient.retrieveData(param); &#125; &#125;; &#125; public JSONObject fallback() &#123; return new JSONObject(); &#125;&#125; 注解订阅执行： 123456789101112131415161718192021222324public class HelloWorldHystrixAnnotationObervable &#123; @Autowired private DataClient dataClient; @HystrixCommand(groupKey = \"helloWorldHystrixAnnotation\", commandKey = \"helloWorldHystrixAnnotationObervable\", fallbackMethod = \"fallback\") public Observable&lt;JSONObject&gt; run(String param) &#123; return Observable.create(subscriber -&gt; &#123; try &#123; if (!subscriber.isUnsubscribed()) &#123; subscriber.onNext(dataClient.retrieveData(param)); subscriber.onCompleted(); &#125; &#125; catch (Exception e) &#123; subscriber.onError(e); &#125; &#125;); &#125; public JSONObject fallback() &#123; return new JSONObject(); &#125;&#125; 触发fallback方法的情况 执行抛出异常 执行超时 断路器打开，不尝试执行 线程池拒绝，不尝试执行 信号量拒绝，不尝试执行 Hystrix监控界面参数 基础属性配置CommandGroup：每个命令最少配置的必选参数，不指定ThreadPoolKey的情况下，用于指定线程池的隔离。 实例配置：HystrixCommand.Setter().withGroupKey(HystrixCommandGroupKey.Factory.asKey(&quot;groupKey&quot;)); 注解配置：@HystrixCommand(groupKey = &quot;groupKey&quot;） CommandKey：依赖命名，一般每个CommandKey代表一个依赖抽象，相同依赖使用相同CommandKey名称，依赖隔离的根本就是对相同CommandKey的依赖做隔离，不同的依赖隔离最好使用不同的线程池。 实例配置：HystrixCommand.Setter().andCommandKey(HystrixCommandKey.Factory.asKey(&quot;commandKey&quot;)); 注解配置：@HystrixCommand(commandKey = &quot;commandKey&quot;) ThreadPoolKey：依赖隔离使用的线程池的键值，对同一业务依赖隔离用CommandGroup做区分，对同一依赖的不同远程调用，使用ThreadPoolKey做隔离区分，业务相同的组，需要在资源上做隔离时，使用ThreadPoolKey区分。不同的ThreadPoolKey建议使用不同的CommandKey。 实例配置：HystrixCommand.Setter().andThreadPoolKey(HystrixThreadPoolKey.Factory.asKey(&quot;threadPoolKey&quot;)) 注解配置：@HystrixCommand(threadPoolKey = &quot;threadPoolKey&quot;) 命令属性配置execution.isolation.strategy：用于设置HystrixCommand执行的隔离策略，支持THREAD线程池隔离单独线程执行并发数受限于线程池大小和SEMAPHORE信号量隔离在调用线程中执行通过信号量来限制并发数。 实例配置：HystrixCommandProperties.Setter().withExecutionIsolationStrategy(ExecutionIsolationStrategy.THREAD) 注解配置：@HystrixCommand(commandProperties = {@HystrixProperty(name = &quot;execution.isolation.strategy&quot;,value = &quot;SEMAPHORE&quot;)}) 默认值：THREAD execution.timeout.enabled：是否启用超时限制。 实例配置：HystrixCommandProperties.Setter().withExecutionTimeoutEnabled(true) 注解配置：@HystrixCommand(commandProperties = {@HystrixProperty(name = &quot;execution.timeout.enabled&quot;, value = &quot;true&quot;)}) 默认值：true execution.isolation.thread.timeoutInMilliseconds：执行超时时间，超时会作用在HystrixCommand.queue()，即使没有调用get()获得Future对象。 实例配置：HystrixCommandProperties.Setter().withExecutionTimeoutInMilliseconds(2000) 注解配置：@HystrixCommand(commandProperties = {@HystrixProperty(name = &quot;execution.isolation.thread.timeoutInMilliseconds&quot;, value = &quot;2000&quot;)}) 默认值：1000ms execution.isolation.thread.interruptOnTimeout：使用线程隔离时，对执行超时的线程是否被中断。 实例配置：HystrixCommandProperties.Setter().withExecutionIsolationThreadInterruptOnTimeout(true) 注解配置：@HystrixCommand(commandProperties = {@HystrixProperty(name = &quot;execution.isolation.thread.interruptOnTimeout&quot;, value = &quot;true&quot;)}) 默认值：true（THREAD模式有效） execution.isolation.semaphore.maxConcurrentRequests：使用信号量策略时，允许的最大并发请求数。 实例配置：HystrixCommandProperties.Setter().withExecutionIsolationSemaphoreMaxConcurrentRequests(50) 注解配置：@HystrixCommand(commandProperties = {@HystrixProperty(name = &quot;execution.isolation.semaphore.maxConcurrentRequests&quot;, value = &quot;50&quot;)}) 默认值：10（SEMAPHORE模式有效） Fallbackfallback.enabled：当接口异常或者拒绝时，是否调用Fallback方法处理，线程池和信号量策略都支持。 实例配置：HystrixCommandProperties.Setter().withFallbackEnabled(true) 注解配置：@HystrixCommand(commandProperties = {@HystrixProperty(name = &quot;fallback.enabled&quot;, value = &quot;true&quot;)}) 默认值：true fallback.isolation.semaphore.maxConcurrentRequests：Fallback方法最大并发数。超过该配置的请求将被拒绝，若没有实现回退，则抛出异常。线程池和信号量策略都支持。 实例配置：HystrixCommandProperties.Setter().withFallbackIsolationSemaphoreMaxConcurrentRequests(20) 注解配置：@HystrixCommand(commandProperties = {@HystrixProperty(name = &quot;fallback.isolation.semaphore.maxConcurrentRequests&quot;, value = &quot;20&quot;)}) 默认值：10（SEMAPHORE模式有效） circuitBreaker.enabled：断路器是否生效。 实例配置：HystrixCommandProperties.Setter().withCircuitBreakerEnabled(true) 注解配置：@HystrixCommand(commandProperties = {@HystrixProperty(name = &quot;circuitBreaker.enabled&quot;, value = &quot;true&quot;)}) 默认值：true 断路器circuitBreaker.requestVolumeThreshold：滚动窗口中，打开断路器的最少请求数。 实例配置：HystrixCommandProperties.Setter().withCircuitBreakerRequestVolumeThreshold(20) 注解配置：@HystrixCommand(commandProperties = {@HystrixProperty(name = &quot;circuitBreaker.requestVolumeThreshold&quot;,value = &quot;20&quot;)}) 默认值：20 circuitBreaker.sleepWindowInMilliseconds：拒绝请求到再次不被拒绝的请求时间间隔。 实例配置：HystrixCommandProperties.Setter().withCircuitBreakerSleepWindowInMilliseconds(10) 注解配置：@HystrixCommand(commandProperties = {@HystrixProperty(name = &quot;circuitBreaker.sleepWindowInMilliseconds&quot;, value = &quot;5000&quot;)}) 默认值：5000ms circuitBreaker.errorThresholdPercentage：断路器启动回退逻辑的错误比率。 实例配置：HystrixCommandProperties.Setter().withCircuitBreakerErrorThresholdPercentage(50) 注解配置：@HystrixCommand(commandProperties = {@HystrixProperty(name = &quot;circuitBreaker.errorThresholdPercentage&quot;, value = &quot;50&quot;)}) 默认值：50 circuitBreaker.forceClosed：强制断路器进入关闭状态，将允许所有的请求，无视错误率。 实例配置：HystrixCommandProperties.Setter().withCircuitBreakerForceClosed(false) 注解配置：@HystrixCommand(commandProperties = {@HystrixProperty(name = &quot;circuitBreaker.forceClosed&quot;, value = &quot;false&quot;)}) 默认值：false circuitBreaker.forceOpen：强制断路器进入打开状态，将会拒绝所有的请求。优先级比circuitBreaker.forceClosed高。 实例配置：HystrixCommandProperties.Setter().withCircuitBreakerForceOpen(false) 注解配置：@HystrixCommand(commandProperties = {@HystrixProperty(name = &quot;circuitBreaker.forceOpen&quot;, value = &quot;false&quot;)}) 默认值：false 线程池hystrix.threadpool.default.coreSize：设置核心线程池大小，与ThreadPoolExecutor的coreSize的含义不一样 实例配置：HystrixThreadPoolProperties.Setter().withCoreSize(10) 注解配置：@HystrixCommand(threadPoolProperties = {@HystrixProperty(name = &quot;coreSize&quot;, value = &quot;10&quot;)}) 默认值：10 hystrix.threadpool.default.maximumSize：设置线程池最大值，不开始拒绝HystrixCommand的情况下支持的最大并发数，设置allowMaximumSizeToDrivergeFromCoreSize后生效。 实例配置：HystrixThreadPoolProperties.Setter().withMaximumSize(10) 注解配置：@HystrixCommand(threadPoolProperties = {@HystrixProperty(name = &quot;maximumSize&quot;, value = &quot;10&quot;)}) 默认值：10 hystrix.threadpool.default.maxQueueSize：最大的队列值，若设置为-1使用SynchronousQueue，否则使用LinkedBlockingQueue。 实例配置：HystrixThreadPoolProperties.Setter().withMaxQueueSize(10) 注解配置：@HystrixCommand(threadPoolProperties = {@HystrixProperty(name = &quot;maxQueueSize&quot;, value = &quot;10&quot;)}) 默认值：-1 hystrix.threadpool.default.queueSizeRejectionThreshold：设置队列拒绝的阈值，maxQueueSize值为-1时，该属性不生效。 实例配置：HystrixThreadPoolProperties.Setter().withQueueSizeRejectionThreshold(5) 注解配置：@HystrixCommand(threadPoolProperties = {@HystrixProperty(name = &quot;queueSizeRejectionThreshold&quot;, value = &quot;5&quot;)}) 默认值：5 hystrix.threadpool.default.keepAliveTimeMinutes：设置存活时间，单位分钟，如果coreSize小于maximumSize，则该属性控制一个线程从使用完成到被释放的时间。 实例配置：HystrixThreadPoolProperties.Setter().withKeepAliveTimeMinutes(1) 注解配置：@HystrixCommand(threadPoolProperties = {@HystrixProperty(name = &quot;keepAliveTimeMinutes&quot;, value = &quot;1&quot;)}) 默认值：1 hystrix.threadpool.default.allowMaximumSizeToDivergeFromCoreSize ：允许maximumSize起作用。 实例配置：HystrixThreadPoolProperties.Setter().withAllowMaximumSizeToDivergeFromCoreSize(false) 注解配置：@HystrixCommand(threadPoolProperties = {@HystrixProperty(name = &quot;allowMaximumSizeToDivergeFromCoreSize&quot;, value = &quot;false&quot;)}) 默认值：false","tags":[{"name":"Hystrix，限流，熔断，降级","slug":"Hystrix，限流，熔断，降级","permalink":"https://yaoyinglong.github.io/tags/Hystrix，限流，熔断，降级/"}],"categories":[{"name":"框架","slug":"框架","permalink":"https://yaoyinglong.github.io/categories/框架/"},{"name":"Spring","slug":"框架/Spring","permalink":"https://yaoyinglong.github.io/categories/框架/Spring/"}]},{"title":"Java8时间及日期","date":"2019-05-21T16:00:00.000Z","path":"Blog/Java/基础/时间及日期总结/","text":"旧的日期类是可变且线程不安全的，Java8中引入了一套全新的日期API，java.time包中的类是不可变且线程安全。 LocalDatejava.time.LocalDate是用来表示日期的，不包含具体的时间，默认按照yyyy-MM-dd格式。 获取当前日期：LocalDate.now() 根据年月日构建日期：LocalDate.of(2018, 01, 30) 字符串转换日期：LocalDate.parse(&quot;2018-01-30&quot;)，也可以自定义格式，如：LocalDate.parse(&quot;2018年01月30日&quot;, DateTimeFormatter.ofPattern(&quot;uuuu年MM月dd日&quot;)) 本月第一天：localDate.with(TemporalAdjusters.firstDayOfMonth()) 本月第二天：localDate.withDayOfMonth(2) 本月最后一天：localDate.with(TemporalAdjusters.lastDayOfMonth()) 明天：localDate.plusDays(1L) 昨天：localDate.minusDays(1L) 获取本年第120天：localDate.withDayOfYear(120) 计算两个日期间的天数：localDate.until(localDate1, ChronoUnit.DAYS) 计算两个日期间的周数：localDate.until(localDate1, ChronoUnit.WEEKS) LocalTimeLocalTime与LocalDate相反，其仅表示时间，不包含日期。 获取当前时间（包含毫秒数）：LocalTime.now() 构建指定时间：LocalTime.of(12, 15, 30) 获取指定时间（不包含毫秒数）：localTime.withNano(0) 字符串转为时间 LocalTime.parse(&quot;12:15:30&quot;) LocalTime.parse(&quot;12:15:30.233&quot;) LocalTime.parse(&quot;12:15&quot;) LocalTime.parse(&quot;12时15分30秒&quot;, DateTimeFormatter.ofPattern(&quot;HH时mm分ss秒&quot;)) LocalDateTimeLocalDateTime和旧的java.util.Date类是，既包含日期，又包含时间，且经常与DateTimeFormatter一起使用。 获取当前年月日时分秒：LocalDateTime.now() 通过LocalDate和LocalTime构建：LocalDateTime.of(LocalDate.now(), LocalTime.now()) 时间差计算相差的天数： 123456789101112public static long getDaysBetween(LocalDate firstDate, LocalDate secondDate) &#123; if (firstDate == secondDate) &#123; return 0; &#125; if (firstDate == null) &#123; firstDate = LocalDate.now(); &#125; if (secondDate == null) &#123; secondDate = LocalDate.now(); &#125; return Math.abs(firstDate.toEpochDay() - secondDate.toEpochDay());&#125; 计算相差的小时数： 12345678910111213public static long getHoursBetween(LocalDateTime firstDate, LocalDateTime secondDate) &#123; if (firstDate == secondDate) &#123; return 0; &#125; if (firstDate == null) &#123; firstDate = LocalDateTime.now(); &#125; if (secondDate == null) &#123; secondDate = LocalDateTime.now(); &#125; Long diffHours = Math.abs(Duration.between(firstDate, secondDate).toHours()); return diffHours;&#125; Date与JAVA8时间类互转12345678910111213141516171819//Date与Instant的相互转化Instant instant = Instant.now();Date date = Date.from(instant);Instant instant2 = date.toInstant(); //Date转为LocalDateTimeDate date2 = new Date();LocalDateTime localDateTime2 = LocalDateTime.ofInstant(date2.toInstant(), ZoneId.systemDefault()); //LocalDateTime转DateLocalDateTime localDateTime3 = LocalDateTime.now();Instant instant3 = localDateTime3.atZone(ZoneId.systemDefault()).toInstant();Date date3 = Date.from(instant);//LocalDate转Date//因为LocalDate不包含时间，所以转Date时，会默认转为当天的起始时间，00:00:00LocalDate localDate4 = LocalDate.now();Instant instant4 = localDate4.atStartOfDay().atZone(ZoneId.systemDefault()).toInstant();Date date4 = Date.from(instant);","tags":[{"name":"Java8","slug":"Java8","permalink":"https://yaoyinglong.github.io/tags/Java8/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"基础","slug":"Java/基础","permalink":"https://yaoyinglong.github.io/categories/Java/基础/"}]},{"title":"方法调用","date":"2019-03-13T16:00:00.000Z","path":"Blog/Java/VM/方法调用/","text":"方法调用并不等同于方法执行，方法调用阶段唯一任务是确定被调用方法的版本，暂时不涉及方法内部具体运行过程。程序运行时，进行方法调用是最普遍最频繁的操作。 Class文件编译过程中不包含传统编译中的连接步骤，一切方法的调用在Class文件中存储的都只是符号引用，而非方法在实际运行内存布局中的入口地址（直接引用）。该特性带来了强大的动态扩展性，但同时使得方法调用过程变得相对复杂，需要在类加载期间、甚至运行期间才能确定目标方法的直接引用。 解析调用所有方法调用中的目标方法在Class文件里面都是一个常量池中的符号引用，在类加载的解析阶段，会将其中在编译期可知，运行期不可变的方法的符号引用转化为直接引用。 编译器可知，运行期不可变的方法主要包括：静态方法、私有方法、实例构造器、父类方法、final修饰的方法。这类方法被称为非虚方法，其他方法称为虚方法。 虚拟机提供5条方法调用字节码指令，前四条指令的分派逻辑是固化在Java虚拟机内部的，而invokedynamic的分派逻辑是由用户所设定的引导方法决定的： invokestatic：调用静态方法 invokespecial：调用实例构造器&lt;init&gt;方法、私有方法、父类方法 invokevirtual：调用所有的虚方法，以及final修饰的方法。 invokeinterface：调用接口方法，在运行时再确定一个实现此接口的对象 invokedynamic：在运行时动态解析出调用点限定符所引用的方法，然后再执行该方法 只要能被invokestatic和invokespecial指令调用的方法，都可以在解析阶段确定唯一的调用版本，包括了静态方法、私有方法、实例构造器、父类方法4类。 解析调用一定是一个静态过程，编译器就可以完全确定，在类装载的解析阶段就会把涉及的符号引用全部转变为可确定的直接引用，不会延迟到运行期去完成。 分派调用分派调用可能是静态的也可能是动态的，根据宗量（方法的接收者和方法的参数统称为方法的宗量）分为单分派和多分派，两类分派方式两两组合就构成了：静态单分派、静态多分派、动态单分派、动态多分派。 分派的调用过程其实就是Java多态的实现原理，如重写和重载在Java虚拟机中是如何实现的。 静态分派说到静态分派，首先先说一下变量的静态类型或者叫外观类型，以及变量的实际类型。假设有抽象类Human和其实现类Man、Woman，若Human man = new Man();,则Human是man的静态类型，Man是其实际类型。 静态类型和实际类型在程序中都可能发生一些变化，静态类型的变化仅仅在使用时发生，变量本身的静态类型不会被改变，且最终的静态类型是在编译器可知的；实际类型的变化结果在运行期才可以确定，编译器在编译程序时并不知道对象的实际类型是什么。 123456// 实际类型的变化Human man = new Man();man = Woman();// 静态类型的变化sr.sayHello((Man) man);sr.sayHello((Woman) man); 虚拟机（编译器）在调用重载（Overload）时是通过参数的静态类型而不是实际类型作为判定依据，在编译阶段Javac编译器会根据参数的静态类型来确定具体调用哪个重载版本的方法。 所有依赖 静态类型来定位方法执行版本的分派动作称为静态分派，静态分派的典型应用是方法重载。 静态分派发生在编译阶段，因此确定静态分派的动作实际上不是由虚拟机来执行的，编译器虽然能确定方法的重载版本，但很多情况下这个重载版本并不唯一，往往只能确定一个更加合适的版本，主要原因是字面量不需要定义，所以字面量是没有显式的静态类型，其静态类型只能通过语言上的规则去理解和推断。 动态分派动态分派与多态的另一个重要体现重写（Override）有着密切的关联。 动态分派其实就是invokevirtual指令的多态查找的过程。由于该指令第一步就是在运行其确定接收者的实际类型，所以对于不同的调用，该指令会将常量池中的类方法符号引用解析到不同的直接引用上，该过程就是Java中方法重写的本质。 我们将这种在运行期根据实际类型确定方法执行版本的分派过程称为动态分派。 解析和分派这两者之间的关系并不是二选一的排他关系，它们是在不同层次上去筛选、确定目标方法的过程。 单分派与多分派单分派是根据一个宗量对目标方法进行选择，多分派是根据多个宗量对目标方法进行选择。到目前为止可以说Java语言是一门静态多分派、动态单分派的语言。 虚拟机动态分派的实现由于动态分派是非常频繁的动作，而且动态分派的方法版本的选择过程需要运行时在类的方法元数据中搜索合适的目标方法，在虚拟机的实际实现中基于性能考虑会对其进行一些优化，最常用的稳定优化手段是为类在方法区中建立一个虚方法表或接口方法表，使用虚方法表索引来代替元数据查找提高性能。 虚方法表中存放着各个方法的实际入口地址。具有相同签名的方法，在之类和父类的虚方法表中都应当具有相同的索引序号，在类型变换时便于查找。 虚拟机除了使用方法表之外，在条件允许下，还会使用内联缓存和基于类型继承关系分析技术的守护内联两种非稳定的优化手段来获取更高的性能。 动态类型语言支持动态类型语言的关键特征是它的类型检查的主体过程是在运行期而不是编译期。变量无类型而变量值才有类型这也是动态语言的一个重要特征。 静态类型语言在编译期确定类型，可以提供严谨的类型检查，与类型相关的问题在编码时就能及时发现，利于稳定性及代码达到更大规模； 动态类型语言在运行期确定类型，为开发人员提供更大的灵活性，代码会更加清晰简单，也意味着高效的开发效率。 Reflection与MethodHandlerJDK7提供了java.lang.invoke包，其主要目的是用于提供一种新的动态确定目标方法的机制，称为MethodHandler。 1234567891011121314static class ClassA &#123; public void println(String string) &#123; System.out.println(string); &#125;&#125;public static void main(String[] args) throws Throwable &#123; Object obj = System.currentTimeMillis() % 2 == 0 ? System.out : new ClassA(); MethodType methodType = MethodType.methodType(void.class, String.class); MethodHandle methodHandle = MethodHandles.lookup().findVirtual(obj.getClass(), \"println\", methodType).bindTo(obj); methodHandle.invokeExact(\"param\");&#125; MethodHandler的使用方法与Reflection有众多相似之处，以及以下区别： 本质上MethodHandler和Reflection都是在模拟方法调用，Reflection是在模拟Java层次的方法调用，MethodHandler是在模拟字节码层次的方法调用。 Reflection中的Method对象远比MethodHandler中的MethodHandler对象所包含的信息多。Method包含了方法签名、描述符、方法属性表中各种属性、以及执行权限等运行期信息。而MethodHandler仅包含与执行该方法相关的信息。 MethodHandler理论上可以采用类似虚拟机在字节码上做的各种优化思路。而Reflection不行。 Reflection仅支持Java语言，MethodHandler支持所有语言。","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"运行时栈帧结构","date":"2019-03-10T16:00:00.000Z","path":"Blog/Java/VM/运行时栈帧结构/","text":"栈帧是用于支持虚拟机进行方法调用和方法执行的数据结构，是虚拟机运行时数据区中的虚拟机栈的栈元素。每个方法从调用开始至执行完成的过程，都对应一个栈帧在虚拟机栈中从入栈到出栈的过程。 栈帧存储了方法的局部变量表、操作数栈、动态连接、方法返回地址和一些额外的附加信息。在编译程序代码时，栈帧中需要多大的局部变量表、多深的操作数栈都已完全确定，并写入到方法表的Code属性中了。因此栈帧需要分配多少内存，不受运行期变量数据影响，仅取决于具体的虚拟机实现。 对于执行引擎来说，在活动线程中，只有当前栈帧（位于栈顶的栈帧）才有效，与该栈帧关联的方法称为当前方法。执行引擎运行的所有字节码指令都是针对当前栈帧进行操作。 局部变量表局部变量表是一组变量值存储空间，用于存放方法参数和方法内部定义的局部变量。在程序被编译成Class文件时，就在方法区的Code属性的max_locals数据项中确定了该方法所需要分配的局部变量表的最大容量。 局部变量表容量以变量槽Slot为最小单位，一个Slot可存放一个32位以内的数据类型，Java中占用32位以内的数据类型有boolean、byte、char、short、int、float、reference、returnAddress 8种类型，64位的数据类型只有long和double两种。 reference类型表示对一个对象实例的引用，一是从此引用中直接或间接地查找到对象在Java堆中的数据存放的起始地址索引，二是次引用中直接或间接地查找到对象所属数据类型在方法区中存储的类型信息。 局部变量表建立在线程的堆栈上，是线程私有的数据，无论读写的Slot是否为原子操作，都不会引起数据安全问题。 方法在执行时，虚拟机是使用局部变量表完成参数值到参数变量列表的传递过程，若执行的是实例方法，局部变量表中第0位索引默认是用于传递方法所属对象实例的引用，可通过this关键字来访问该隐含参数。 类变量有两次赋初始值的过程，在准备阶段赋系统初始值，在初始化阶段赋定义初始值。但局部变量没有赋初始值就不能使用。 操作数栈Java虚拟机解释执行引擎称为基于栈的执行引擎，其中的栈就是操作数栈，操作数栈也称为操作栈，是一个后入先出栈，最大深度在编译时写入Code属性的max_stacks数据项中。操作数栈的每个元素可以是任意Java数据类型，包括long和double，32位数据类型占1个栈容量，64位数据类型占2个栈容量。操作数栈中元素的数据类型必须与字节码指令序列严格匹配。 方法开始执行时，该方法的操作数栈为空，方法在执行过程中，会有各种字节码指令往操作数栈中写入和提取内容，也就是入栈和出栈操作。在算数运算时通过字节码指令将最接近栈顶的两个元素出栈并进行计算，然后将计算结果入栈，在调用其他方法时通过操作数栈来进行参数传递。 概念模型中两个栈帧作为虚拟机的元素是完全独立的，但大多数虚拟机都进行了一些优化，令两个栈帧出现部分重叠，在进行方法调用时可共享一部分数据。 动态连接每个栈帧都包含了一个指向运行时常量池中该栈帧所属方法的引用，持有该引用是为了支持方法调用过程中的动态连接。Class文件常量池中存有大量的符号引用，字节码中的方法调用指令就以常量池中指向方法的符号引用作为参数， 这些符号引用的一部分会在类加载阶段或者第一次使用时转化为直接引用，这种转化称为静态解析。另一部分将在每一次运行期间转化为直接引用，这部分称为动态连接。 方法返回地址当方法开始执行后，只有两种方式可以推出该方法，方式一执行引擎遇到任意一个方法返回的字节码指令，可能有返回值传递给上层方法调用者，是否有返回值和返回值类型将根据遇到何种方法返回指令来决定。方式二方法在执行过程中遇到异常，且该异常在方法体中没得到处理。 无论哪种方式退出，都需要返回到方法被调用的位置，方法返回时可能需要在栈帧中保存一些信息，用来帮助恢复它的上层方法的执行状态。方法正常退出时，调用者的PC计数器的值可作为返回地址，栈帧中很可能会保存该PC计数器值；方法异常退出时，返回地址要通过异常处理器来确定，栈帧中一般不会保存这部分信息。 方法退出过程实际上等同于当前栈帧出栈，退出可能执行的操作有，恢复上层方法的局部变量表和操作数栈，若有返回值把返回值压入调用者栈帧的操作数栈中，调整PC计数器的值以指向方法调用指令后面的一条指令等。 附加信息虚拟机规范允许具体的虚拟机实现增加一些规范种没有描述的信息到栈帧中，例如调试相关的信息。实际开发中一般会把动态连接、方法的返回地址、与其他附加信息全部归类为一类，称为栈帧信息。","tags":[{"name":"JVM，栈帧","slug":"JVM，栈帧","permalink":"https://yaoyinglong.github.io/tags/JVM，栈帧/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"Maven插件编写","date":"2019-03-02T16:00:00.000Z","path":"Blog/Maven/Maven插件编写/","text":"一般步骤 创建maven-plugin项目，打包方式必须为maven-plugin，可使用maven-archetype-plugin快速创建 编写插件目标，每个插件必须包含一个或多个目标，必须提供一个或多个继承自AbstractMojo的类 为目标提供配置点，编写Mojo时提供可配置的参数。 编写代码实现目标行为，根据实际需要实现Mojo 错误处理及日志，当Mojo异常时，根据情况控制Maven的运行状态 测试插件，编写自动化测试代码测试行为，再实际运行插件验证其行为 案例每个插件目标即Mojo都必须继承AbstractMojo并实现execute()方法，这样Maven才能识别该插件，并执行execute()方法中的行为。当在execute()方法捕获的其他异常时，使用MojoExecutionException对其简单包装后再抛出，Maven执行插件目标时遇到MojoExecutionException会在命令行显示BUILD ERROR. 标注实现方式maven-plugin-api该依赖中包含了插件开发所必需的类。 12345678910111213&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;groupId&gt;com.long.mvnbook.account&lt;/groupId&gt;&lt;artifactId&gt;account-maven-plugin&lt;/artifactId&gt;&lt;packaging&gt;maven-plugin&lt;/packaging&gt;&lt;name&gt;Maven Mojo&lt;/name&gt;&lt;url&gt;http://maven.apache.org&lt;/url&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.maven&lt;/groupId&gt; &lt;artifactId&gt;maven-plugin-api&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 默认使用的是Java1.4风格的标注 12345678910111213141516171819/** * @goal touch * @phase process-sources */public class MyMojo extends AbstractMojo &#123; /** * @parameter expression=\"$&#123;project.build.directory&#125;\" * @required */ private File outputDirectory; /** * @parameter */ private String[] includes; public void execute() throws MojoExecutionException &#123; &#125;&#125; 注解实现方式1234567891011121314151617181920&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;groupId&gt;com.long.mvnbook.account&lt;/groupId&gt;&lt;artifactId&gt;account-maven-plugin&lt;/artifactId&gt;&lt;packaging&gt;maven-plugin&lt;/packaging&gt;&lt;name&gt;Maven Mojo&lt;/name&gt;&lt;url&gt;http://maven.apache.org&lt;/url&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.maven&lt;/groupId&gt; &lt;artifactId&gt;maven-core&lt;/artifactId&gt; &lt;version&gt;3.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.maven.plugin-tools&lt;/groupId&gt; &lt;artifactId&gt;maven-plugin-annotations&lt;/artifactId&gt; &lt;version&gt;3.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 使用注解的方式，具体实现代码示例 12345678910111213@Mojo(name = \"touch\", defaultPhase = LifecyclePhase.PROCESS_SOURCES)@Execute(goal = \"\", phase = \"\", lifecycle = \"\")public class MyMojo extends AbstractMojo &#123; @Parameter(defaultValue = \"$&#123;project.build.directory&#125;\", required = true) private File outputDirectory; @parameter private String[] includes; public void execute() throws MojoExecutionException &#123; &#125;&#125; 使用插件12345678910&lt;plugin&gt; &lt;groupId&gt;com.long.mvnbook.account&lt;/groupId&gt; &lt;artifactId&gt;account-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;includes&gt; &lt;include&gt;&lt;/include&gt; &lt;include&gt;&lt;/include&gt; &lt;/includes&gt; &lt;/configuration&gt;&lt;/plugin&gt; Mojo标注 @goal &lt;name&gt; 每个Mojo都必须使用该标注注明目标名称，对应注解方式@Mojo(name = &quot;&quot;） @phase &lt;phase&gt; 将目标绑定至Default生命周期的某个阶段 @requiresDependencyResolution &lt;scope&gt; 运行该Mojo前必须解析所有指定范围的依赖，默认为runtime @requiresProject &lt;true/false&gt; 该目标是否必须在Maven项目中运行 @requiresDirectInvocation &lt;true/false&gt; 是否只能通过命令行调用 @requiresOnline &lt;true/false&gt; 是否要求Maven必须是在线状态，默认false @requiresReports &lt;true/false&gt; 是否要求项目报告已经生成，默认false @aggregator 在多模块项目中，表示只会在顶层模块中运行 @execute goal = &quot;&lt;goal&gt;&quot; 运行该目标前先运行另一个目标，本插件目标直接使用目标名，否则使用prefix:goal @execute phase= &quot;&lt;phase&gt;&quot; 运行该目标前线运行一个并行的生命周期到指定阶段 @execute lifecycle= &quot;&lt;lifecycle&gt;&quot; 运行该目标前线运行一个自定义生命周期到指定阶段 Mojo参数可以使用@parameter将Mojo的某个字段标注为可配置的参数即Mojo参数。Maven支持Boolean、Integer、Float、String、Date、File、URL、多值数组、Collection、Map、Properties等多种Mojo参数。 Boolean1234@parameter private boolean sampleBoolean;// 对应配置&lt;sampleBoolean&gt;true&lt;/sampleBoolean&gt; Integer1234@parameter private int sampleInt;// 对应配置&lt;sampleInt&gt;6&lt;/sampleInt&gt; Float1234@parameter private int sampleFloat;// 对应配置&lt;sampleFloat&gt;6.5&lt;/sampleFloat&gt; String1234@parameter private int sampleString;// 对应配置&lt;sampleString&gt;HW&lt;/sampleString&gt; Date12345@parameter private int sampleDate;// 对应配置,格式为yyyy-MM-dd HH:mm:ss.Sa或yyyy-MM-dd HH:mm:ssa&lt;sampleDate&gt;2019-03-03 11:28:55.1 PM&lt;/sampleDate&gt; &lt;sampleDate&gt;2019-03-03 11:28:55PM&lt;/sampleDate&gt; File1234@parameter private int sampleFile;// 对应配置&lt;sampleFile&gt;c:\\tmp&lt;/sampleFile&gt; URL1234@parameter private int sampleURL;// 对应配置&lt;sampleURL&gt;https://yaoyinglong.github.io&lt;/sampleURL&gt; 数组1234567@parameter private String[] includes;// 对应配置&lt;includes&gt; &lt;include&gt;&lt;/include&gt; &lt;include&gt;&lt;/include&gt;&lt;/includes&gt; Collection1234567@parameter private List includes;// 对应配置&lt;includes&gt; &lt;include&gt;&lt;/include&gt; &lt;include&gt;&lt;/include&gt;&lt;/includes&gt; Map1234567@parameter private Map sampleMap;// 对应配置&lt;sampleMap&gt; &lt;key1&gt;&lt;/key1&gt; &lt;key2&gt;&lt;/key2&gt;&lt;/sampleMap&gt; Properties12345678910111213@parameter private Properties sampleProperties;// 对应配置&lt;sampleProperties&gt; &lt;properties&gt; &lt;name&gt;&lt;/name&gt; &lt;value&gt;&lt;/value&gt; &lt;/properties&gt; &lt;properties&gt; &lt;name&gt;&lt;/name&gt; &lt;value&gt;&lt;/value&gt; &lt;/properties&gt;&lt;/sampleProperties&gt; 除此之外@parameter还提供一些额外的属性 @parameter alias = &quot;&quot;给参数配置别名 @parameter expression= &quot;${aSystemProperty}&quot;使用系统属性表达式给参数赋值 @parameter default-value= &quot;aValue/${anExpression}&quot;若未配置才参数，就提供一个默认值 @readonly 参数只读 @required 必须参数","tags":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/tags/Maven/"}],"categories":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/categories/Maven/"}]},{"title":"Maven属性","date":"2019-02-24T16:00:00.000Z","path":"Blog/Maven/Maven属性/","text":"Maven为了支持构建的灵活性，内置了属性、Profile、资源过滤三大特性。 Maven属性Maven共有6类属性，分别为内置属性、POM属性、自定义属性、Settings属性、Java系统属性、环境变量属性。正确使用这些属性可以帮助简化POM配置和维护工作。 内置属性主要有两个常用内置属性： ${basedir}：包含pom.xml文件的目录。即项目的根目录。 ${version}：项目的版本号 POM属性用户可以使用POM属性引用POM文件中对应的元素值。常用POM属性： ${project.build.sourceDirectory}：项目主源码目录，默认为src/main/java/ ${project.build.testScoreDirectory}：项目测试源码目录，默认为src/test/java/ ${project.build.directory}：项目构建输出目录，默认target/ ${project.outputDirectory}：项目代码编译输出目录，默认/target/classes/ ${project.testOutputDirectory}：项目测试代码编译输出目录，默认/target/test-classes/ ${project.groupId}：项目groupId ${project.artifactId}：项目artifactId ${project.version}：项目version，与${version}等价 ${project.build.finalName}：项目打包输出文件名称，默认为${project.artifactId}-${project.version} 自定义属性在POM文件中的properties元素下定义的Maven属性。 Setting属性与POM属性同理，使用setting.开头的属性引用setting.xml文件中XML元素的值。例如${setting.localRepository}引用本地仓库地址 Java系统属性所有Java系统属性都可以使用Maven属性引用。例如${user.home}引用用户目录。 可以使用mvn help:system命令查看所有的Java系统属性 环境变量属性所有环节变量都可以使用以env.开头的Maven属性引用。例如${env.JAVA_HOME}引用JAVA_HOMR环境变量的值。 可以使用mvn help:system命令查看所有的环境变量 Profile为了应对环境的变化，Maven属性可以将变化的部分提取出来。针对不同环境设置不同的属性或插件。 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;dev&lt;/id&gt; &lt;properties&gt; &lt;release.file&gt;test&lt;/release.file&gt; &lt;/properties&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.22.1&lt;/version&gt; &lt;configuration&gt; &lt;skipTests&gt;false&lt;/skipTests&gt; &lt;testFailureIgnore&gt;true&lt;/testFailureIgnore&gt; &lt;excludes&gt; &lt;exclude&gt;com.long.model.IT.**&lt;/exclude&gt; &lt;/excludes&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/profile&gt; &lt;profile&gt; &lt;id&gt;product&lt;/id&gt; &lt;properties&gt; &lt;release.file&gt;product&lt;/release.file&gt; &lt;/properties&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.22.1&lt;/version&gt; &lt;configuration&gt; &lt;skipTests&gt;true&lt;/skipTests&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/profile&gt;&lt;/profiles&gt; Maven3支持pom.xml、用户setting.xml、全局setting.xml三种Profile。pom.xml中声明的Profile只对当前项目有效，用户setting.xml对本机上该用户的所有项目有效，全局setting.xml对本机上所有项目有效。 Maven支持多种方式激活Profile，可以通过mvn clean install -Pdev, test激活dev和test两个Profile；可以在setting文件或者POM中通过如下配置显示激活。 123&lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt;&lt;/activation&gt; 通过系统属性激活，当系统属性test存在且值等于x时激活，value可以没有，用户也可以通过命令行设置系统属性mvn clean install -Dtest=x从而激活配置。 12345678910&lt;profiles&gt; &lt;profile&gt; &lt;activation&gt; &lt;property&gt; &lt;name&gt;test&lt;/name&gt; &lt;value&gt;x&lt;/value&gt; &lt;/property&gt; &lt;/activation&gt; &lt;/profile&gt;&lt;/profiles&gt; 操作系统环境激活，name、arch、version可以通过查看环境中的系统属性获取。 123456789101112&lt;profiles&gt; &lt;profile&gt; &lt;activation&gt; &lt;os&gt; &lt;name&gt;Windows XP&lt;/name&gt; &lt;family&gt;Windows&lt;/family&gt; &lt;arch&gt;x86&lt;/arch&gt; &lt;version&gt;5.1.2600&lt;/version&gt; &lt;/os&gt; &lt;/activation&gt; &lt;/profile&gt;&lt;/profiles&gt; 文件存在与否激活，如下所示当x文件不存在y文件存在时激活。 12345678910&lt;profiles&gt; &lt;profile&gt; &lt;activation&gt; &lt;file&gt; &lt;missing&gt;x.properties&lt;/missing&gt; &lt;exists&gt;x.properties&lt;/exists&gt; &lt;/file&gt; &lt;/activation&gt; &lt;/profile&gt;&lt;/profiles&gt; 若项目中有很多profile，其激活方式各异，用户可以通过mvn help:active-profiles命令查看当前激活的profile，也可以通过mvn help:all-profiles列出当前所有的profile。","tags":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/tags/Maven/"}],"categories":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/categories/Maven/"}]},{"title":"IT测试总结","date":"2019-02-23T16:00:00.000Z","path":"Blog/Test/IT测试总结/","text":"IT测试主要测试模块之间的接口和接口数据传递关系，以及模块组合后的整体功能。 在做集成测试时，若涉及到数据库的数据变更的，最好在测试过后将数据还原，可以先构建一条新的数据测试完成后删除，防止印象到数据库中原有的数据。 Controller层测试对于SpringBoot项目，Controller层的IT测试可以通过在类上加@AutoConfigureMockMvc注解并直接注入MockMvc的方式进行测试。 若对于一些特殊的测试，需要使用不同的配置的可使用@TestPropertySource(locations=&quot;classpath:test.application.properties&quot;)注解指定特定的配置文件。 123456789101112131415161718@RunWith(SpringRunner.class)@SpringBootTest@AutoConfigureMockMvcpublic class DashboardControllerTest &#123; @Autowired private MockMvc mockMvc; @Test public void get_method_test() throws Exception &#123; this.mockMvc.perform(get(\"/test//v1\") .param(\"param1\", \"value1\") .param(\"param2\", \"value2\") .header(\"uid\", \"123456\")) .andExpect(status().isOk()) .andExpect(content().string(containsString(\"&#123;\\\"response_code\\\":\\\"00\\\"\"))); &#125;&#125; 对于MockMvc的使用还可以通过如下方式，这样可以不用在类上添加@AutoConfigureMockMvc注解： 12345678910@Autowiredprivate WebApplicationContext context;private MockMvc mvc;@Beforepublic void setUp() throws Exception &#123; mvc = MockMvcBuilders.webAppContextSetup(context) .addFilter(new BaseParamCheckFilter()).build();&#125; mockMvc.perform需要传入的是一个RequestBuilder，可以将其封装好了再传入，需要放入RequestBody中的参数可以通过content进行参数构造： 12345678910HttpHeaders httpHeaders = new HttpHeaders();httpHeaders.add(\"uuid\", \"68A\");httpHeaders.add(\"Content-Type\", \"application/json\");RequestBuilder request = post(\"/test/v1\") .headers(httpHeaders) .content(\"&#123;\\\"uuid\\\": \\\"68A\\\",\\\"param1\\\":\\\"aa\\\"&#125;\") .accept(MediaType.APPLICATION_JSON);mockMvc.perform(request).andExpect(status().isOk()).andDo(print()).andExpect( content().string(containsString(\"&#123;\\\"response_code\\\":\\\"02\\\",\\\"message\\\":\\\"请求参数缺失\\\"\"))); 对于返回结果的严重可以使用上面的示例通过MockMvcResultMatchers结合Matchers中的方法进行验证，也可以通过以下方式获取到具体结果后进行验证。 123String responseString = mvc.perform(request) .andExpect(status().isOk()) .andReturn().getResponse().getContentAsString(); perform：执行一个RequestBuilder请求，会自动执行SpringMVC的流程并映射到相应的控制器执行处理； andExpect：添加ResultMatcher验证规则，验证控制器执行完成后结果是否正确； andDo：添加ResultHandler结果处理器，比如调试时打印结果到控制台； andReturn：最后返回相应的MvcResult；然后进行自定义验证/进行下一步的异步处理； 测试文件上传对于文件大小限制的测试可以直接构建一个指定大小的byte数组。 1234567MockMultipartFile xmlFile = new MockMultipartFile(\"xmlFile\", \"emptyModel.xml\", \"text/plain\", new byte[1024 * 1024 * 200 + 1]);this.mockMvc.perform(MockMvcRequestBuilders.fileUpload(\"/test/config/add\") .file(xmlFile).param(\"mid\", mid).param(\"status\", \"1\")) .andExpect(status().isOk()) .andExpect(content().string(containsString(\"&#123;\\\"message\\\":\\\"上传文件异常\\\"\"))); 如果对于真实的文件上传测试可以读取真实的文件传输： 12345678910111213141516171819URL url = this.getClass().getClassLoader().getResource(\"test/errorFileType.txt\");File file = new File(url.getPath());MockMultipartFile xmlFile = new MockMultipartFile(\"xmlFile\", \"errorFileType.txt\", \"text/plain\", getByte(file));private byte[] getByte(File file) throws IOException &#123; FileInputStream fis = new FileInputStream(file); ByteArrayOutputStream bos = new ByteArrayOutputStream(); byte[] b = new byte[1000]; int n; while ((n = fis.read(b)) != -1) &#123; bos.write(b, 0, n); &#125; fis.close(); bos.close(); return bos.toByteArray(); &#125;&#125; 使用TestRestTemplate 对象测试12345678910@Autowiredprivate TestRestTemplate template;@Testpublic void testController()&#123; // template.getForObject() 会得到 controller 返回的 json 值 String content = template.getForObject(\"/show/100\", String.class); // 使用断言测试，使用正确的断言 Assert.assertEquals(\"show100\", content);&#125; 非Controller层测试对于非Controller测试一般更简单一些，只需要注入相关的类构造入参进行具体的方法调用测试，输出结果进行严重即可。 123456789101112131415161718192021@RunWith(SpringRunner.class)@SpringBootTest(webEnvironment = NONE)public class ITConfigServiceTest &#123; @Autowired private TestBusiConfigMapper testBuisConfigMapper; @Autowired private otherConfigService otherConfigService; @Test public void getConfigTest() &#123; List&lt;Config&gt; configList = testBuisConfigMapper.getAllConfigs(); assertNotNull(configList); assertEquals(true, configList.size() &gt; 0); for (Config config : configList) &#123; Config config = otherConfigService.getConfig(config.getId()); assertNotNull(config); &#125; &#125;&#125;","tags":[{"name":"Test","slug":"Test","permalink":"https://yaoyinglong.github.io/tags/Test/"}],"categories":[{"name":"Test","slug":"Test","permalink":"https://yaoyinglong.github.io/categories/Test/"}]},{"title":"UT测试总结","date":"2019-02-23T16:00:00.000Z","path":"Blog/Test/UT测试总结/","text":"UT测试主要测试单元内部的数据结构、逻辑控制、异常处理等。单元测试实现容易、运行速度快、能完全控制被测试的单元不包含外部依赖、测试用例相互独立无依赖关系。能够帮助发现代码缺陷、修改或者重构代码时确保没有影响现有功能。 对于一些对Bean没有依赖的类的测试（例如一些工具类），仅使用JUnit即可完成单元测试。 对于一些依赖Bean的类进行测试，若其复杂度低，在上层一两个IT测试即可覆盖掉，可以使用IT测试；若其复杂度比较高，可以使用JUnit加Mockito来完成单元测试，通过使用Mock技术测试可以无视代码依赖关系去测试代码的有效性，mock技术的目的和作用就是模拟一些在应用中不容易构造或者比较复杂的对象，从而把测试与测试边界以外的对象隔离开，对于依赖的Bean进行Mock处理，模拟构造各种Bean的输出来以及待测试方法的输入来覆盖当前方法的所有分支。 Mockito基础必须使用@RunWith(MockitoJUnitRunner.class)注解，否则Mock的依赖Bean将为空。@Mock将创建一个Mock，@InjectMocks创建一个实例且自动实例化，mockito会自动注入mock或spy成员。UserBaseServiceImpl中通过@Autowired注解或者构造方法等方式注入了IUserBaseDao，就可以通过如下方式使用。 12345678@RunWith(MockitoJUnitRunner.class)public class UserBaseServiceTest &#123; @Mock private IUserBaseDao userBaseDao; @InjectMocks private UserBaseServiceImpl userBaseService;&#125; @Mock与@Spy的区别使用@Mock生成的类，所有方法都不是真实的方法，而且返回值都是NULL。通常在设置测试桩时通过如下方式设置，对于多次调用返回不同值，可以通过多次设置thenReturn： 123456LinkedList mockedList = mock(LinkedList.class);mockedList.add(11);assertEquals(null, mockedList.get(0));when(mockedList.get(0)).thenReturn(\"first\").thenReturn(\"second\");assertEquals(\"first\", mockedList.get(0)); 使用@Spy生成的类，所有方法都是真实方法，返回值都是和真实方法一样的。测试桩设置与@Mock方式有所区别： 123456LinkedList mockedList = spy(LinkedList.class);mockedList.add(11);assertEquals(11, mockedList.get(0));doReturn(\"foo\").when(spy).get(0);assertEquals(\"foo\", mockedList.get(0)); Redis测试有时在进行Mock测试时会遇到redisTemplate，通常在应用中会使用redisTemplate.boundValueOps或者redisTemplate.boundHashOps生成一个BoundValueOperations或者BoundHashOperations对象，再来继续调用具体的处理方法。在设置测试桩时，需要进行两次设置。 12when(redisTemplate.boundValueOps(redisKey)).thenReturn(mock(BoundValueOperations.class));when(redisTemplate.boundValueOps(redisKey).increment(anyLong())).thenReturn(10L); 参数捕捉有时会出现一大串复杂的逻辑处理后生成一个或几个参数，用于调用其他的依赖Bean，这时可以通过参数捕捉来验证逻辑中各种情况下生产的参数是否满足预期。若简单参数也可以通过verify直接验证。 123456789BoundHashOperations boundHashOperations = mock(BoundHashOperations.class);when(redisTemplate.boundHashOps(anyString())).thenReturn(boundHashOperations);ArgumentCaptor&lt;Map&gt; argument = ArgumentCaptor.forClass(Map.class); verify(boundHashOperations, times(2)).putAll(argument.capture());Map&lt;String, CaseFlow&gt; map = new HashMap&lt;&gt;();assertEquals(map, argument.getValue()); 方法调用次数验证当验证的方法中存在循环、或者复杂度比较高等，导致方法在不同条件下可能存在多次调用的情况，最好验证一下方法的调用次数。或者是用于验证某个逻辑没有被执行或方法没有别调用。 12345verify(mock, times(1)).someMethod();// 至少调用2次verify(mock, atLeast(2)).someMethod();// 至多调用5次verify(mock, atMost(5)).someMethod(); 异常处理在进行一些会抛出异常的测试时，可以通过捕获异常在进行后续校验，可以使用@Test(expected = Exception.class)，若有多个地方抛出相同异常但异常信息不同时，该测试方法就不适用了，可以通过如下方式进行异常捕获后进行相关的验证。 1234567891011doThrow(new RuntimeException()).when(mockedList).clear();when(redisTemplate.boundValueOps(any())).thenThrow(new RuntimeException());Exception error = null;try &#123; baselineModelHandler.output(segment, modelData);&#125; catch (Exception e) &#123; error = e;&#125;assertNotNull(error);assertEquals(\"\", error.getMessage()); 验证调用顺序123456789101112List firstMock = mock(List.class);List secondMock = mock(List.class);firstMock.add(\"was called first\");secondMock.add(\"was called second\");//创建多个mock对象的inOrderInOrder inOrder = inOrder(firstMock, secondMock);//验证firstMock先于secondMock调用inOrder.verify(firstMock).add(\"was called first\");inOrder.verify(secondMock).add(\"was called second\"); 实现ApplicationContextAware接口的类测试1234Map&lt;String, Object&gt; map = new HashMap&lt;&gt;();map.put(\"outputServiceImpl\", new OutputServiceImpl(requestService, updateCache, mock(ICache.class)));when(applicationContext.getBeansWithAnnotation(InvokeListener.class)).thenReturn(map);dataInvokeService.setApplicationContext(applicationContext);","tags":[{"name":"Test","slug":"Test","permalink":"https://yaoyinglong.github.io/tags/Test/"}],"categories":[{"name":"Test","slug":"Test","permalink":"https://yaoyinglong.github.io/categories/Test/"}]},{"title":"SonarQube配置总结","date":"2019-02-19T16:00:00.000Z","path":"Blog/杂记/SonarQube配置总结/","text":"SonarQube的安装很简单，这里不做赘述。主要总结一下SonarQube的一些实际应用。 SonarQube Jenkins配置安装并配置好SonarQube后，在Jenkins插件管理中添加SonarQube Scanner for Jenkins插件，然后在Jenkins系统设置中设置SonarQube servers信息。 最后在具体的项目配置中的Post Steps中添加Execute SonarQube Scanner： 这样配置后在Jenkins上构建项目时会自动执行SonarQube代码扫描，但是由于很多时候Jenkins上Build中都配置-Dmaven.test.skip=true跳过测试，这样就统计不出测试覆盖率。 SonarQube本地化由于Jenkins上配置扫描不出测试覆盖率，最后考虑直接在POM中配置插件，通过开发人员自己来进行代码扫描。首先需要配置sonar-maven-plugin插件，这里将插件的sonar目标绑定到Maven的default生命周期的post-integration-test阶段，是为了方便代码扫描，也可以不进行绑定直接执行mvn sonar:sonar。 1234567891011121314&lt;plugin&gt; &lt;groupId&gt;org.sonarsource.scanner.maven&lt;/groupId&gt; &lt;artifactId&gt;sonar-maven-plugin&lt;/artifactId&gt; &lt;version&gt;3.6.0.1398&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;sonar-scan&lt;/id&gt; &lt;phase&gt;post-integration-test&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;sonar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 这里使用的jacoco-maven-plugin来进行代码测试覆盖率的统计，该插件的report目标也是绑定在Maven的default生命周期的test阶段，将该插件声明在sonar-maven-plugin的前面，让其先执行覆盖率统计工作，以便sonar-maven-plugin插件使用覆盖率统报告。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485&lt;plugin&gt; &lt;groupId&gt;org.jacoco&lt;/groupId&gt; &lt;artifactId&gt;jacoco-maven-plugin&lt;/artifactId&gt; &lt;version&gt;0.8.3&lt;/version&gt; &lt;configuration&gt; &lt;excludes&gt; &lt;exclude&gt;**/support/xml/*&lt;/exclude&gt; &lt;/excludes&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;!-- Prepares the property pointing to the JaCoCo runtime agent which is passed as VM argument when Maven the Surefire plugin is executed. --&gt; &lt;execution&gt; &lt;id&gt;pre-unit-test&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;prepare-agent&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;!-- Sets the path to the file which contains the execution data. --&gt; &lt;destFile&gt;$&#123;project.build.directory&#125;/coverage-reports/jacoco-ut.exec&lt;/destFile&gt; &lt;!-- Sets the name of the property containing the settings for JaCoCo runtime agent. --&gt; &lt;propertyName&gt;surefireArgLine&lt;/propertyName&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;!-- Ensures that the code coverage report for unit tests is created after unit tests have been run. --&gt; &lt;execution&gt; &lt;id&gt;post-unit-test&lt;/id&gt; &lt;phase&gt;test&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;report&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;!-- Sets the path to the file which contains the execution data. --&gt; &lt;dataFile&gt;$&#123;project.build.directory&#125;/coverage-reports/jacoco-ut.exec&lt;/dataFile&gt; &lt;!-- Sets the output directory for the code coverage report. --&gt; &lt;outputDirectory&gt;$&#123;project.reporting.outputDirectory&#125;/jacoco-ut&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;!-- Prepares the property pointing to the JaCoCo runtime agent which is passed as VM argument when Maven the Failsafe plugin is executed. --&gt; &lt;execution&gt; &lt;id&gt;pre-integration-test&lt;/id&gt; &lt;phase&gt;pre-integration-test&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;prepare-agent&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;!-- Sets the path to the file which contains the execution data. --&gt; &lt;destFile&gt;$&#123;project.build.directory&#125;/coverage-reports/jacoco-it.exec&lt;/destFile&gt; &lt;!-- Sets the name of the property containing the settings for JaCoCo runtime agent. --&gt; &lt;propertyName&gt;failsafeArgLine&lt;/propertyName&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;!-- Ensures that the code coverage report for integration tests after integration tests have been run. --&gt; &lt;execution&gt; &lt;id&gt;post-integration-test&lt;/id&gt; &lt;phase&gt;post-integration-test&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;report&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;!-- Sets the path to the file which contains the execution data. --&gt; &lt;dataFile&gt;$&#123;project.build.directory&#125;/coverage-reports/jacoco-it.exec&lt;/dataFile&gt; &lt;!-- Sets the output directory for the code coverage report. --&gt; &lt;outputDirectory&gt;$&#123;project.reporting.outputDirectory&#125;/jacoco-it&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 使用maven-surefire-plugin来执行单元测试。 将surefireArgLine赋值给argLine参数，以保证在测试执行时Jacoco agent处于运行状态。 12345678910111213&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.22.1&lt;/version&gt; &lt;configuration&gt; &lt;argLine&gt;$&#123;surefireArgLine&#125;&lt;/argLine&gt; &lt;skipTests&gt;false&lt;/skipTests&gt; &lt;testFailureIgnore&gt;true&lt;/testFailureIgnore&gt; &lt;excludes&gt; &lt;exclude&gt;com.long.model.IT.**&lt;/exclude&gt; &lt;/excludes&gt; &lt;/configuration&gt;&lt;/plugin&gt; 使用maven-failsafe-plugin来执行集成测试。 将failsafeArgLine赋值给argLine参数，以保证在测试执行时Jacoco agent处于运行状态。若集成测试用例和单元测试用例放在同一个项目里，必须在单元测试的surefire中exclude所有集成测试用例。 通过additionalClasspathElements标签将/target/classes添加为一个额外的classpath元素，因为在classes文件夹中一些资源没有添加到jar中，但是测试使用了这些资源，若不加这个额外的classpath，则maven-failsafe-plugin插件的integration-test将不能正常执行。 12345678910111213141516171819202122232425&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-failsafe-plugin&lt;/artifactId&gt; &lt;version&gt;2.19.1&lt;/version&gt; &lt;configuration&gt; &lt;!-- Sets the VM argument line used when integration tests are run. --&gt; &lt;argLine&gt;$&#123;failsafeArgLine&#125;&lt;/argLine&gt; &lt;skipTests&gt;false&lt;/skipTests&gt; &lt;testFailureIgnore&gt;true&lt;/testFailureIgnore&gt; &lt;additionalClasspathElements&gt; &lt;additionalClasspathElement&gt;$&#123;basedir&#125;/target/classes&lt;/additionalClasspathElement&gt; &lt;/additionalClasspathElements&gt; &lt;parallel&gt;none&lt;/parallel&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;integration-test&lt;/id&gt; &lt;phase&gt;integration-test&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;integration-test&lt;/goal&gt; &lt;goal&gt;verify&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 最后需要配置SonarQube配置信息，可以配置在Maven的setting.xml配置文件中，也可以配置在项目的中，当然可以不用profiles直接配置在properties中。 1234567891011121314151617181920212223242526&lt;profiles&gt; &lt;profile&gt; &lt;id&gt;sonar&lt;/id&gt; &lt;activation&gt; &lt;activeByDefault&gt;true&lt;/activeByDefault&gt; &lt;/activation&gt; &lt;properties&gt; &lt;sonar.jdbc.url&gt;jdbc:mysql://192.168.3.113:3306/sonar&lt;/sonar.jdbc.url&gt; &lt;sonar.jdbc.driver&gt;com.mysql.jdbc.Driver&lt;/sonar.jdbc.driver&gt; &lt;sonar.jdbc.username&gt;yao_yinglong&lt;/sonar.jdbc.username&gt; &lt;sonar.jdbc.password&gt;yao_yinglong_passwd&lt;/sonar.jdbc.password&gt; &lt;sonar.host.url&gt;http://172.16.21.200:9000&lt;/sonar.host.url&gt; &lt;sonar.binaries&gt;src/main/java&lt;/sonar.binaries&gt; &lt;sonar.sources&gt;src/main/java&lt;/sonar.sources&gt; &lt;sonar.tests&gt;src/test/java&lt;/sonar.tests&gt; &lt;sonar.language&gt;java&lt;/sonar.language&gt; &lt;sonar.coverage.exclusions&gt;**/support/xml/**, **/entity/**&lt;/sonar.coverage.exclusions&gt; &lt;sonar.cpd.exclusions&gt;**/support/xml/**&lt;/sonar.cpd.exclusions&gt; &lt;sonar.dynamicAnalysis&gt;reuseReports&lt;/sonar.dynamicAnalysis&gt; &lt;sonar.junit.reportsPath&gt;src/test/java&lt;/sonar.junit.reportsPath&gt; &lt;sonar.java.coveragePlugin&gt;jacoco&lt;/sonar.java.coveragePlugin&gt; &lt;sonar.jacoco.reportPaths&gt;target/coverage-reports/jacoco-ut.exec&lt;/sonar.jacoco.reportPaths&gt; &lt;sonar.jacoco.itReportPath&gt;target/coverage-reports/jacoco-it.exec&lt;/sonar.jacoco.itReportPath&gt; &lt;/properties&gt; &lt;/profile&gt;&lt;/profiles&gt; 当然为了简化配置可以不配置jacoco-maven-plugin的集成测试相关执行目标，也没有必要配置maven-failsafe-plugin插件，去掉maven-surefire-plugin插件中排除的集成测试，同时可以将sonar.jacoco.itReportPath配置为target/coverage-reports/jacoco-ut.exec甚至不配。 但是即使这样以上的配置还是过于庞杂，如果很多项目使用该类容，可以创建一个超级POM，将这些内容放在超级POM中，用到的项目集成该超级POM即可极大的简化配置。 但是这样配置，项目在测试环境、预发布环境、生产环境或者一些其他的不需要使用导SonarQube的环境，也会执行SonarQube扫描。有可能这些环境与搭建的SonarQube的服务网络不通，导致项目不能正常构建。在构建参数中添加-Dsonar.skip=true命令即可跳过SonarQube正常构建项目。如果使用Jenkins可以在Build的Goals and options中进行添加该命令。","tags":[{"name":"SonarQube","slug":"SonarQube","permalink":"https://yaoyinglong.github.io/tags/SonarQube/"},{"name":"jacoco","slug":"jacoco","permalink":"https://yaoyinglong.github.io/tags/jacoco/"}],"categories":[{"name":"杂记","slug":"杂记","permalink":"https://yaoyinglong.github.io/categories/杂记/"}]},{"title":"Maven聚合与继承","date":"2019-02-18T16:00:00.000Z","path":"Blog/Maven/Maven聚合与继承/","text":"聚合Maven聚合又称为多模块，该特性是为了一次构件多个项目，而不用到每个项目下分别执行mvn命令。且聚合模块其打包方式packaging必须为pom否则无法构建。 modules元素是实现聚合最核心的配置，用户可以通过在一个打包方式为pom的Maven项目中声明任意数量的module元素来实现模块的聚合。且每一个module的值都是一个当前POM的相对目录。为了方便快速定位内容，模块所处目录名称应当与其artifactId一致。 为了方便构建项目，通常将聚合模块放在项目目录最顶层，其他模块作为聚合模块的子目录，聚合模块仅仅是帮助聚合其他模块构件的工具，其本身并无实质内容。 Maven在构件聚合项目时，首先会解析聚合模块的POM、分析要构建的模块、并计算出一个反应堆构建顺序，然后根据这个顺序依次构建各个模块，反应堆是所有模块组成的一个构建结构。 1234567891011&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;groupId&gt;com.long.mvnbook.account&lt;/groupId&gt;&lt;artifactId&gt;account-aggregator&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;pom&lt;/packaging&gt;&lt;name&gt;Account Aggregator&lt;/name&gt;&lt;modules&gt; &lt;module&gt;account-email&lt;/module&gt; &lt;module&gt;account-persist&lt;/module&gt;&lt;/modules&gt; 继承继承是为了抽取出重复的配置，需要创建POM的父子结构，在父POM中声明一些配置供子POM继承，以实现一处声明多处使用。 与聚合一样父模块的POM其打包类型packaging必须为pom，父模块只是为了消除配置的重复，因此其本身不包含除POM以外的项目文件。 123456&lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;&lt;groupId&gt;com.long.mvnbook.account&lt;/groupId&gt;&lt;artifactId&gt;account-aggregator&lt;/artifactId&gt;&lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;packaging&gt;pom&lt;/packaging&gt;&lt;name&gt;Account Aggregator&lt;/name&gt; 在子模块中使用parent元素声明父模块，groupId、artifactId和version指定了父模块的坐标，且这三个元素是必须的，元素relativePath表示父模块POM的相对路径，当构建时Maven首先会根据relativePath检查父POM，若找不到则从本地仓库查找，relativePath默认值是../pom.xml。 123456&lt;parent&gt; &lt;artifactId&gt;account-aggregator&lt;/artifactId&gt; &lt;groupId&gt;com.long.mvnbook.account&lt;/groupId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;relativePath&gt;../pom.xml&lt;/relativePath&gt;&lt;/parent&gt; 可继承的POM元素： groupId：项目组ID，项目坐标的核心元素 version：项目版本号，项目坐标的核心元素 description：项目描述信息 organization：项目组织信息 inceptionYear：项目创始年份 url：项目url地址 developers：项目开发者信息 contributors：项目贡献者信息 distributionManagement：项目部署配置 issueManagement：项目缺陷跟踪系统信息 ciManagement：项目持续集成系统信息 scm：项目的版本控制系统信息 mailingLists：项目的邮件列表信息 properties：自定义的Maven属性 dependencies：项目的依赖配置 dependencyManagement：项目的依赖管理配置， repositories：项目的仓库配置 build：包括项目的源码目录、输出目录、插件配置、插件管理配置等 reporting：包括项目的报告输出目录配置、报告插件配置等 依赖管理dependencyManagement既能让子模块继承到父类模块的依赖配置，又能保证子模块依赖使用的灵活性，该元素下的依赖声明不会引入实际的依赖，不过能约束dependencies下的依赖使用。 123456789101112131415161718&lt;!-- 父模快account-parent中声明 --&gt;&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt;&lt;!-- 子模块account-email中使用 --&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;/dependency&gt;&lt;/dependencies&gt; dependencies中的依赖配置比原来简单了，junit依赖省去了version和scope，这样能统一项目范围中依赖的版本，当依赖版本在父POM中声明之后，子模块使用依赖时无需声明版本号，也不会发生多个子模块使用依赖版本不一致的情况。子模块不声明依赖的使用，即使该依赖已经在父POM的dependencyManagement中声明，也不会产生任何实际效果。 import依赖范围的依赖只在dependencyManagement元素下有效，使用该范围的依赖通常指向一个POM，作用是将目标POM中的dependencyManagement配置导入并合并到当前POM的dependencyManagement元素中。 若多个项目使用的依赖版本一致，则可以定义一个使用dependencyManagement专门管理依赖的POM，然后在各个项目中导入这些依赖管理配置。 1234567891011&lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.long.mvnbook.account&lt;/groupId&gt; &lt;artifactId&gt;account-parent&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 插件管理Maven提供了pluginManagement元素来帮助管理插件，在该元素中配置的依赖不会造成实际的插件调用行为，当POM中配置了真正的plugin元素，且其groupId和artifactId与pluginManagement中配置的插件匹配时，pluginManagement才会影响实际的插件行为。 123456789101112131415161718192021222324252627282930&lt;!-- 父模快account-parent中声明 --&gt;&lt;build&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.sonarsource.scanner.maven&lt;/groupId&gt; &lt;artifactId&gt;sonar-maven-plugin&lt;/artifactId&gt; &lt;version&gt;3.6.0.1398&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;sonar-scan&lt;/id&gt; &lt;phase&gt;test&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;sonar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt;&lt;/build&gt;&lt;!-- 子模块account-email中使用 --&gt;&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.sonarsource.scanner.maven&lt;/groupId&gt; &lt;artifactId&gt;sonar-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 若子模块需要不同的插件配置，可以自行配置以覆盖父模块的pluginManagement配置，当项目中多个模块有相同的插件配置时，应当将配置移到父POM的pluginManagement元素中。 聚合与继承的关系对于聚合模块，它知道被聚合的模块，但被聚合的模块不知道这个聚合模块的存在。 对于继承关系的父POM，它不知道哪些子模块继承了它，但子模块都必须知道自己的父POM。 聚合POM与继承关系中的父POM的packaging都必须时pom，且都是除POM之外没有实际的内容。 约定优于配置Maven提倡约定优于配置，使用约定可以大量减少配置，遵循约定虽然损失一定的灵活性，但却能减少配置，且能帮助遵守构建标准。 任何一个Maven项目都隐式地继承超级POM，Maven 3中超级POM文件在$MAVEN_HOME/lib/maven-model-builder-x.x.x.jar中的org/apache/maven/model/pom-4.0.0.xml路径下。Maven 2中超级POM文件在$MAVEN_HOME/lib/maven-x.x.x-uber.jar中的org/apache/maven/project/pom-4.0.0.xml路径下。 超级POM定义了仓库及插件仓库，都关闭了SNAPSHOT的支持。 反应堆在一个多模块的Maven项目中，反应堆时指所有模块组成的一个构建结构，对于单模块项目，反应堆就是该模块本身，多模块的项目，反应堆就包括了各个模块之间的继承与依赖关系，从而能自动计算出合理的模块构建顺序。 Maven按序读取POM，若该POM没有依赖模块，则构建该模块，否则先构建依赖模块，若该依赖模块还依赖其他模块，则进一步先构建依赖的依赖。 模块间的依赖关系会将反应堆构成一个有向非循环图，各个模块是该图的节点，依赖关系构成了有向边，且该图不允许出现循环，当出现A模块依赖于B，B又依赖于A时，Maven会报错。 若仅仅构建完整反应堆中的某些模块，则需要实时的裁剪反应堆。Maven提供很多命令行选项支持裁剪反应堆: -am, --also-make 同时构建所列模块的依赖模块 -amd -also-make-dependents 同时构建依赖于所列模块的模块 -pl, --project &lt; arg &gt; 构建指定的模块，模块间用逗号隔开 -rf -resume-from &lt;args&gt; 从指定模块回复反应堆","tags":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/tags/Maven/"}],"categories":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/categories/Maven/"}]},{"title":"Maven插件基础","date":"2019-01-02T16:00:00.000Z","path":"Blog/Maven/Maven插件基础/","text":"Maven核心仅仅定义了抽象的生命周期，具体任务交给插件来完成，插件以独立的构件形式存在，Maven核心分发包不到3M大小，Maven会在需要时下载并使用插件。如maven-dependency-plugin能分析项目依赖，找出潜在无用依赖，列出项目依赖树，分析依赖来源等 生命周期的阶段与插件的目标相互绑定，来完成某个具体的构建任务，例如项目编译任务对应了default生命周期的compile阶段，而maven-compiler-plugin插件的compile目标能完成该任务，将其绑定能实现项目编译目的 插件的每个目标都对应一个功能，如dependency:analyze、dependency:tree、dependency:list，冒号前面是插件前缀，冒号后面是插件目标 插件绑定Maven核心默认为一些主要的生命周期阶段内置绑定了很多插件目标，当调用生命周期阶段时，对应的插件目标就会执行相应的任务。 生命周期阶段 插件目标 执行任务 pre-clean - - clean maven-clean-plugin:clean 删除项目输出目录 post-clean - - pre-site - - site maven-site-plugin:site 生成项目站点 post-site - - site-deploy maven-site-plugin:deploy 将项目站点部署到远程服务器 pro-resources maven-resources-plugin:resources 复制主资源文件至主输出目录 compile maven-compiler-plugin:compile 编译主代码至主输出目录 process-test-resources maven-resources-plugin:testResources 复制测试资源文件至测试输出目录 test-compile maven-compiler-plugin:testCompile 编译测试代码至测试输出目录 test maven-surefire-plugin:test 执行测试用例 package maven-jar-plugin:jar 创建项目jar包 install maven-install-plugin:install 将项目输出构件安装到本地仓库 deploy maven-deploy-plugin:deploy 将项目输出构件部署到远程仓库 上表只列出了clean和site生命周期插件绑定关系，以及default生命周期拥有插件绑定关系的阶段，default生命周期还有很多其他阶段，默认没有绑定任何插件，故无任何实际行为。 还可以自定义将某个插件目标绑定到生命周期的某个阶段上，可以通过phrase标签将goals标签中指定的插件目标绑定到具体的生命周期阶段上。 12345678910111213&lt;plugin&gt; &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt; &lt;artifactId&gt;xml-maven-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;xslt-generate&lt;/id&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;transform&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; executions下每一个execution都可以用来配置执行一个任务，通过phase将xml-maven-plugin的transform目标绑定到default生命周期的compile阶段上。goals用于配置指定要执行的插件目标。 很多插件目标在编写时已定义了默认绑定阶段，即使不通过phase元素配置生命周期阶段，也能绑定到生命周期中去。 当多个插件目标绑定到同一个生命周期阶段时，插件声明的先后顺序决定了目标执行的顺序。 插件配置完成插件目标和声明周期阶段绑定后，还能配置插件目标参数，几乎所有插件目标都有一些可配置的参数，可通过命令行和POM配置等方式来配置。 Maven命令行中可以使用：-D参数键=参数值，来配置插件目标参数。例如：mvn install -Dmaven.test.skip=true 并非所有插件参数都适合命令行配置，可以在插件声明时，对插件进行全局配置，所有基于该插件的目标任务都会使用全局配置。还可以为插件的某个目标配置特定的参数。 1234567891011121314151617181920212223&lt;plugin&gt; &lt;groupId&gt;org.jvnet.jaxb2.maven2&lt;/groupId&gt; &lt;artifactId&gt;maven-jaxb2-plugin&lt;/artifactId&gt; &lt;!-- 全局配置 --&gt; &lt;configuration&gt; &lt;schemaDirectory&gt;src/main/resources/xsd&lt;/schemaDirectory&gt; &lt;generateDirectory&gt;src/main/java/&lt;/generateDirectory&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;xsd1-generate&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;generate&lt;/goal&gt; &lt;/goals&gt; &lt;!-- 特定目标任务配置 --&gt; &lt;configuration&gt; &lt;schemaIncludes&gt; &lt;include&gt;test.xsd&lt;/include&gt; &lt;/schemaIncludes&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 获取插件信息主要的插件都来自Apache和Codehaus，文档链接分别为 http://maven.apache.org/plugin/index.html 和 http://mojo.codehaus.org/plugins.html，下载地址分别为 http://repo1.maven.org/maven2/org/apache/maven/plugins 和 http://repository.codehaus.org/org/codehuas/mojo 可以使用maven-help-plugin查看插件详细信息。查看插件目标默认绑定阶段：mvn help:目标-DgroupId:artifactId:version，例如：mvn help:describe-Dplugin = org.apache.maven.plugins:maven-source-plugin:2.1.1，可以省去版本信息，可以使用插件目标前缀替换坐标，加上goal参数仅查询描述插件目标信息，加上detail参数查询详细信息，例如：mvn help:describe-Dplugin=compiler[-Dgoal=compiler][-Ddetail] 明显可以发现命令行传入参数不同于该插件目标参数名称，命令行参数是由插件参数表达式（Expression）决定的，例如surefire:test skip参数表达式为${maven.test.skip}。并非所有插件目标都有表达式，一些插件目标参数只能在POM中配置。 插件解析机制与依赖构件一样，插件构件同样基于坐标存储在Maven仓库中。需要时，Maven会从本地仓库寻找插件，若不存在，则从远程仓库查找，找到后下载到本地仓库使用。 1234567891011121314&lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;central&lt;/id&gt; &lt;name&gt;Central Repository&lt;/name&gt; &lt;url&gt;https://repo.maven.apache.org/maven2&lt;/url&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;releases&gt; &lt;updatePolicy&gt;never&lt;/updatePolicy&gt; &lt;/releases&gt; &lt;/pluginRepository&gt;&lt;/pluginRepositories&gt; 所有子元素表达含义与依赖远程仓库配置完全一样。 若插件的groupId为org.apache.maven.plugins表示为官方插件，在配置插件信息时可以省略groupId，不推荐使用。 插件版本的解析与依赖版本解析类似，未提供版本会自动解析版本，Maven在超级POM中为所有核心插件设定了版本，在使用核心插件时即使不做任何配置，其版本已经确定了。 若某个插件未设定版本，又不是核心插件，Maven会检查所有仓库中可用版本，然后做出选择，选择版本方式与依赖类似，都是到归并后的元数据文件中确定版本。 插件解析元数据时，会默认使用org.apache.maven.plugins和org.codehaus.mojo两个groupId，也可以通过settings配置让Maven检查其他groupId上的插件仓库元数据。 123&lt;pluginGroups&gt; &lt;pluginGroup&gt;com.your.plugins&lt;/pluginGroup&gt;&lt;/pluginGroups&gt; 基于该配置Maven不仅会检查org/apache/maven/plugins/maven-metadata.xml 和 org/codehaus/mojo/maven-metadata.xml 还会检查 com/your/plugins/maven-metadata.xml 1234567891011121314&lt;metadata&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;name&gt;Apache Maven ACR Plugin&lt;/name&gt; &lt;prefix&gt;acr&lt;/prefix&gt; &lt;artifactId&gt;maven-acr-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;name&gt;Apache Maven Ant Plugin&lt;/name&gt; &lt;prefix&gt;ant&lt;/prefix&gt; &lt;artifactId&gt;maven-ant-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/metadata&gt; prefix表示插件前缀，当Maven解析到类似dependency:tree命令时，先基于默认groupId归并所有插件仓库元数据，再检查归并后的元数据，根据prefix找到对应的artifactId，然后结合当前元数据的groupId解析得到version，就得到了完整的坐标。若org/apache/maven/plugins/maven-metadata.xml没有记录该插件前缀，则接着检查剩下的两个元数据。若所有元数据都不包含该前缀则报错。","tags":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/tags/Maven/"}],"categories":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/categories/Maven/"}]},{"title":"Maven生命周期","date":"2018-12-31T16:00:00.000Z","path":"Blog/Maven/Maven生命周期/","text":"Maven的生命周期是抽象的，生命周期本身不做任何实际的工作，其实际行为都由插件来完成，生命周期和插件两者协同工作，密不可分。每个生命周期步骤都可以绑定一个或多个插件行为，且Maven为大多数构建步骤编写并绑定了默认插件。 Maven拥有三套相互独立的生命周期，分别为clean、default和site。clean的目的是清理项目，default的目的是构建项目，site的目的是建立项目站点。每个生命周期包含一些有序的阶段，且后面的阶段依赖于前面的阶段，用户和Maven最直接的交互方式就是调用这些生命周期阶段。三套生命周期本身是相互独立的，可单独调用任何一个生命周期的任何一个阶段。 clean生命周期 阶段 描述 pre-clean 执行一些清理前需要完成的工作 clean 清理上一次构建生成的文件 post-clean 执行一些清理后需要完成的工作 default生命周期 阶段 描述 validate 验证项目是否正确，并提供所有必要信息 initialize 初始化构建状态，例如设置属性或创建目录 generate-sources 生成任何包含在编译中的源代码 process-sources 处理项目主资源文件，例如变量替换等 generate-resources 生成包含在包中的资源 process-resources 将资源复制并处理到目标目录，准备打包 compile 编译项目的源代码 process-classes 从编译中对生成的文件进行后续处理，例如对Java类进行字节码增强 generate-test-sources 生成任何包含在编译中的测试源代码 process-test-sources 处理测试源代码，例如过滤某些值 generate-test-resources 创建用于测试的资源 process-test-resources 将资源复制并处理到测试目标目录中 test-compile 将测试源代码编译到测试目标目录中 process-test-classes 对来自测试编译的生成文件进行后续处理，例如对Java类进行字节码增强 test 使用合适的单元测试框架运行测试 prepare-package 在实际包装之前执行准备包装所需的任何操作。例如解包，版本处理 package 获取已编译的代码并将其打包为可分发的格式，例如JAR、WAR pre-integration-test 执行集成测试之前执行所需操作。例如设置所需环境。 integration-test 如有必要，将程序包处理并部署到可以运行集成测试的环境中 post-integration-test 执行集成测试后执行所需的操作。例如清理环境 verify 运行检查以验证包是否有效并符合质量标准 install 将软件包安装到本地存储库中，以便在本地用作其他项目的依赖项 deploy 将最终包复制到远程存储库以与其他开发人员和项目共享 site生命周期 阶段 描述 pre-site 在实际项目站点生成之前执行所需的过程 site 生成项目的站点文档 post-site 执行完成站点生成所需的进程，并准备站点部署 site-deploy 将生成的站点文档部署到指定的Web服务器 命令行与生命周期从命令行执行Maven任务最主要方式就是调用Maven生命周期。 mvn clean：调用clean生命周期的per-clean和clean阶段 mvn test：调用default生命周期的validate到test的所有阶段 mvn clean install：调用clean生命周期的per-clean和clean阶段和default生命周期的validate到install的所有阶段","tags":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/tags/Maven/"}],"categories":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/categories/Maven/"}]},{"title":"XSD实用总结","date":"2018-12-31T16:00:00.000Z","path":"Blog/杂记/XSD使用总结/","text":"类生成插件配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475&lt;!-- 将XSD文件自动生成POJO对象，每次变更用Maven重新编译一下 --&gt;&lt;plugin&gt; &lt;groupId&gt;org.jvnet.jaxb2.maven2&lt;/groupId&gt; &lt;artifactId&gt;maven-jaxb2-plugin&lt;/artifactId&gt; &lt;version&gt;0.14.0&lt;/version&gt; &lt;configuration&gt; &lt;schemaDirectory&gt;src/main/resources/xsd&lt;/schemaDirectory&gt; &lt;generateDirectory&gt;src/main/java/&lt;/generateDirectory&gt; &lt;packageLevelAnnotations&gt;false&lt;/packageLevelAnnotations&gt; &lt;noFileHeader&gt;true&lt;/noFileHeader&gt; &lt;episode&gt;false&lt;/episode&gt; &lt;readOnly&gt;true&lt;/readOnly&gt; &lt;!-- 如果不加生成的类注释会中文乱码 --&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;!-- 设置生成的类的注解语言en为英文 --&gt; &lt;locale&gt;en&lt;/locale&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;xsd1-generate&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;generate&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;args&gt; &lt;!-- 使用XJC给生成Java类添加注解 --&gt; &lt;arg&gt;-Xannotate&lt;/arg&gt; &lt;!-- 使用XJC给生成Java类添加父类 --&gt; &lt;arg&gt;-Xinheritance&lt;/arg&gt; &lt;!-- 给生成Java类添加equals方法 --&gt; &lt;arg&gt;-Xequals&lt;/arg&gt; &lt;!-- 给生成Java类添加hashCode方法 --&gt; &lt;arg&gt;-XhashCode&lt;/arg&gt; &lt;arg&gt;-Xvalue-constructor&lt;/arg&gt; &lt;arg&gt;-nv&lt;/arg&gt; &lt;/args&gt; &lt;extension&gt;true&lt;/extension&gt; &lt;schemaIncludes&gt; &lt;include&gt;test.xsd&lt;/include&gt; &lt;/schemaIncludes&gt; &lt;bindingIncludes&gt; &lt;include&gt;test.xjb&lt;/include&gt; &lt;/bindingIncludes&gt; &lt;generatePackage&gt;com.test.support.xml&lt;/generatePackage&gt; &lt;plugins&gt; &lt;!-- 基础插件依赖 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.jvnet.jaxb2_commons&lt;/groupId&gt; &lt;artifactId&gt;jaxb2-basics&lt;/artifactId&gt; &lt;version&gt;1.11.1&lt;/version&gt; &lt;/plugin&gt; &lt;!-- -Xequals和-XhashCode参数用于生成equals和hashcode方法使用 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.jvnet.jaxb2_commons&lt;/groupId&gt; &lt;artifactId&gt;jaxb2-value-constructor&lt;/artifactId&gt; &lt;version&gt;3.0&lt;/version&gt; &lt;/plugin&gt; &lt;!-- 使用XJC给生成Java类添加注解 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.jvnet.jaxb2_commons&lt;/groupId&gt; &lt;artifactId&gt;jaxb2-basics-annotate&lt;/artifactId&gt; &lt;version&gt;1.0.2&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.22&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/plugin&gt; 用于生成equals和hashcode方法的依赖 12345&lt;dependency&gt; &lt;groupId&gt;org.jvnet.jaxb2_commons&lt;/groupId&gt; &lt;artifactId&gt;jaxb2-basics-runtime&lt;/artifactId&gt; &lt;version&gt;1.11.1&lt;/version&gt;&lt;/dependency&gt; 用于实现生成的类中加注解和实现继承等关系 1234567891011121314151617181920212223242526272829303132333435&lt;?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"yes\"?&gt;&lt;jaxb:bindings xmlns:jaxb=\"http://java.sun.com/xml/ns/jaxb\" xmlns:xs=\"http://www.w3.org/2001/XMLSchema\" xmlns:xjc=\"http://java.sun.com/xml/ns/jaxb/xjc\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:annox=\"http://annox.dev.java.net\" xmlns:inheritance=\"http://jaxb2-commons.dev.java.net/basic/inheritance\" xsi:schemaLocation=\"http://java.sun.com/xml/ns/jaxb http://java.sun.com/xml/ns/jaxb/bindingschema_2_0.xsd\" jaxb:extensionBindingPrefixes=\"xjc annox inheritance\" version=\"2.1\"&gt; &lt;jaxb:bindings schemaLocation=\"test.xsd\" node=\"/xs:schema\"&gt; &lt;!-- 给生成的类添加serialVersionUID --&gt; &lt;jaxb:globalBindings&gt; &lt;jaxb:serializable uid=\"3710395777932380425\"/&gt; &lt;/jaxb:globalBindings&gt; &lt;!-- 给匹配的类添加注解 --&gt; &lt;jaxb:bindings node=\"//xs:complexType\" multiple=\"true\"&gt; &lt;annox:annotateClass&gt;@lombok.Data&lt;/annox:annotateClass&gt; &lt;annox:annotateClass&gt;@lombok.EqualsAndHashCode&lt;/annox:annotateClass&gt; &lt;/jaxb:bindings&gt; &lt;jaxb:bindings node=\"//xs:element\" multiple=\"true\"&gt; &lt;annox:annotateClass&gt;@lombok.Data&lt;/annox:annotateClass&gt; &lt;annox:annotateClass&gt;@lombok.EqualsAndHashCode&lt;/annox:annotateClass&gt; &lt;/jaxb:bindings&gt; &lt;!-- 给匹配的类添加父类 --&gt; &lt;jaxb:bindings node=\"//xs:element[@name='BaselineModel']/xs:complexType\"&gt; &lt;inheritance:extends&gt;com.test.support.AbstractModel&lt;/inheritance:extends&gt; &lt;/jaxb:bindings&gt; &lt;jaxb:bindings node=\"//xs:element[@name='RuleModel']/xs:complexType\"&gt; &lt;inheritance:extends&gt;com.test.support.AbstractModel&lt;/inheritance:extends&gt; &lt;/jaxb:bindings&gt; &lt;/jaxb:bindings&gt;&lt;/jaxb:bindings&gt; 如果schema文件和binding文件有变动只需要通过maven编译一下","tags":[{"name":"XSD","slug":"XSD","permalink":"https://yaoyinglong.github.io/tags/XSD/"}],"categories":[{"name":"杂记","slug":"杂记","permalink":"https://yaoyinglong.github.io/categories/杂记/"}]},{"title":"Maven仓库","date":"2018-12-31T16:00:00.000Z","path":"Blog/Maven/Maven仓库/","text":"坐标和依赖是任何一个构件在Maven世界中的逻辑表示方式，任何一个构件都有一组坐标唯一标识，而构件的物理表示方式是文件，Maven通过仓库来统一管理这些文件。 仓库布局任何一个构件都有其唯一的坐标，根据这个坐标可以定义其在仓库中的唯一存储路径，且存储路径大致对应关系为groupId/artifactId/version/artifactId-version[-classifier].packaging，这便是Maven的仓库布局。 Maven仓库是基于简单的文件系统存储的，当遇到一些仓库问题时，能很方便地查找相关文件，方便问题定位。 仓库分类仓库只分为本地仓库和远程仓库两类。Maven根据坐标寻找构件时，先查看本地仓库，若存在直接使用；若不存在或需要查看是否有更新的构件版本，再去远程仓库查找，发现后下载到本地仓库再使用。若本地仓库和远程仓库都没有Maven就会报错。 中央远程仓库是Maven核心的自带的远程仓库，其包含了绝大部分开源构件。默认使用中央仓库。 私服是另一种特殊的远程仓库，为了节省带宽和时间，应在局域网内架设一个私有的仓库服务器，使其代理所有外部远程仓库，且内部项目还能部署到私服上供其他项目使用。 除中央仓库和私服外还有很多其他公开的远程仓库，Java.net Maven库 和 JBoss Maven库 中央仓库Maven安装文件自带中央仓库的配置，在$M2_HOME/lib/maven-model-builder-3.3.9.jar/org/apache/maven/pom-4.0.0.xml中，且这段配置的文件是所有Maven项目都会继承的超级POM： 12345678910111213141516171819202122232425262728&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;central&lt;/id&gt; &lt;name&gt;Central Repository&lt;/name&gt; &lt;url&gt;https://repo.maven.apache.org/maven2&lt;/url&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;snapshots&gt; &lt;!-- 不从中央仓库下载快照版本的构件 --&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt;&lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;central&lt;/id&gt; &lt;name&gt;Central Repository&lt;/name&gt; &lt;url&gt;https://repo.maven.apache.org/maven2&lt;/url&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;snapshots&gt; &lt;!-- 不从中央仓库下载快照版本的构件 --&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;releases&gt; &lt;updatePolicy&gt;never&lt;/updatePolicy&gt; &lt;/releases&gt; &lt;/pluginRepository&gt;&lt;/pluginRepositories&gt; 私服私服代理广域网上的远程仓库，下载构件时从私服请求，若不存在则从外部远程仓库下载，缓存到私服后再提供下载服务，一些无法从外部下载的构件也能从本地上传到私服共大家使用。 降低中央仓库负荷 节省外网带宽：私服能消除大量对外部仓库的重复请求，从而节省带宽 加速Maven构件：Maven快照更新检查等机制要求在执行构件时不停检查远程仓库数据，若配置了很多外部远程仓库，由于不停的连接请求外部远程仓库非常耗时，导致构件速度大大降低，使用私服只需要检查局域网私服的数据 部署第三方构件：如一些组织内部私有构件无法从外部仓库获取，但又不能发布到公共仓库，可以发布到私服中，供内部的Maven项目使用 提高稳定性增强控制：Maven构建高度依赖远程仓库，当网络不稳定时，Maven构建会非常不稳定，甚至无法构建 远程仓库配置若默认中央仓库无法满足项目需求，需配置其他远程仓库： 12345678910111213141516&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;bintray&lt;/id&gt; &lt;url&gt;http://dl.bintray.com/andsel/maven/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;updatePolicy&gt;always&lt;/updatePolicy&gt; &lt;checksumPolicy&gt;warn&lt;/checksumPolicy&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;updatePolicy&gt;always&lt;/updatePolicy&gt; &lt;checksumPolicy&gt;warn&lt;/checksumPolicy&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt; repositories元素下，可以使用repository子元素声明一个或多个远程仓库，且任何一个仓库声明的id必须唯一，且Maven自带中央仓库id为central，若其它仓库声明也使用该id，会覆盖中央仓库的配置。 url指仓库地址，一般都基于http协议。 releases和snapshots元素用来控制Maven对于发布版本构件和快照版本构件的下载，releases的enabled值为true表示开启仓库发布版本下载支持，snapshots的enabled值为false表示关闭仓库快照版本下载支持。 updatePolicy元素用来配置Maven从远程仓库检查更新的频率，默认daily每天检查更新一次，never表示从不检查更新，always表示每次构件都检查更新，interval：X表示每隔X分钟检查更新一次（X为任意整数） checksumPolicy元素用来配置Maven检查检验和文件的策略，当构件部署到Maven仓库时，会同时部署对应的检验和文件，下载构件时会验证校验和文件。checksumPolicy默认值为warn表示校验和文件验证失败在执行构建时输出警告信息，fail表示让构建失败，ignore表示完全忽略校验和错误。 远程仓库认证配置认证信息与配置仓库信息不同，仓库信息可直接配置在项目的POM文件中，但认证信息必须配置在setting.xml文件中，这样更为安全。 1234567&lt;servers&gt; &lt;server&gt; &lt;id&gt;deploymentRepo&lt;/id&gt; &lt;username&gt;repouser&lt;/username&gt; &lt;password&gt;repopwd&lt;/password&gt; &lt;/server&gt;&lt;/servers&gt; servers元素下同样可以配置多个server，这里的id元素必须与POM中需要认证的repository元素的id完全一致。 部署至远程仓库要将项目生成的构件部署到仓库，需要在项目pom.xml中配置distributionManagement元素 123456789101112&lt;distributionManagement&gt; &lt;repository&gt; &lt;id&gt;company-deploy&lt;/id&gt; &lt;name&gt;company-deploy&lt;/name&gt; &lt;url&gt;https://nexus.company.com/repository/company-deploy/&lt;/url&gt; &lt;/repository&gt; &lt;snapshotRepository&gt; &lt;id&gt;company-snapshot-deploy&lt;/id&gt; &lt;name&gt;company-snapshot-deploy&lt;/name&gt; &lt;url&gt;https://nexus.company.com/repository/company-snapshot-deploy/&lt;/url&gt; &lt;/snapshotRepository&gt;&lt;/distributionManagement&gt; distributionManagement元素包含repository发布版本构件仓库和snapshotRepository快照版本仓库，id为该仓库的唯一标识，name为了方便阅读，url为该仓库地址。 命令行运行mvn clean deploy，Maven就会将项目构建输出的构件部署到配置对应的远程仓库，若当前版本是快照版本，则部署到快照版本仓库地址，反之部署到发布版本仓库地址。 快照版本任何一个项目或构件都必须有自己的版本，版本的值可能是1.0.0、1.3-alpha-4、3.0、2.1-SNAPSHOT或2.1-20091216.221212-13。1.0.0、1.3-alpha-4和3.0是稳定发布版本，2.1-SNAPSHOT和2.1-20091216.221212-13是不稳定快照版本。 使用快照版本，避免了在协同开发多个相互依赖的模块时，各个模块频繁更新POM，以及频繁代码更新造成的版本好滥用。 当构件A的版本好设置为快照版本如2.1-SNAPSHOT时，在发布私服过程中，Maven会自动为构件打上时间戳，若构件B依赖与构件A的2.1-SNAPSHOT版本，当构建模块B时Maven会自动从远程仓库检查模块A的2.1-SNAPSHOT的最新构件，当发现更新时下载。默认每天检查一次，也可通过命令mvn clean install-U强制让Maven检查更新。 快照版本只应该在组织内部的项目或模块间依赖使用，项目不应该依赖与任何组织外部的快照版本依赖，因为快照版本不稳定可能造成潜在风险。 仓库解析依赖机制依赖范围是system时，Maven直接从本地文件系统解析构件。 根据依赖坐标计算仓库路径后，尝试直接从本地仓库寻找构件，若发现构件，则解析成功。 本地仓库不存在，若依赖版本是显示的发布版本构件，遍历所有远程仓库，发现后下载并解析使用。 若依赖版本是RELEASE或LATEST，则基于更新策略读取所有远程仓库的元数据groupId/artifactId/maven-metadata.xml，将其与本地仓库对应的元数据合并后，计算出RELEASE或LATEST真实值，然后基于该真实值检查本地仓库和远程仓库。 若依赖版本是SNAPSHOT，则基于更新策略读取所有远程仓库元数据groupId/artifactId/version/maven-metadata-snapshot.xml，将其与本地仓库对应的元数据合并，得到最新快照版本值，然后基于该值检查本地仓库和远程仓库。 若最后解析得到的构件版本是时间戳格式的快照，则复制其时间戳格式的文件至非时间戳格式，并使用非时间戳格式的构件。 若当前版本不明晰的，如RELEASE、LATEST和SNAPSHOT，Maven需要基于更新远程仓库的更新策略来检查更新。还可以使用-U参数强制检查更新，此时会忽略&lt;updatePolicy&gt;配置。 当Maven检查完更新策略，并决定检查依赖更新时，就需要检查仓库元数据maven-metadata.xml。LATEST指向了元数据中最新的那个版本，RELEASE指向了元数据中最新的发布版本。Maven通过合并多个远程仓库及本地仓库的元数据，就能计算出基于所有仓库的LATEST和RELEASE，然后再解析具体的构件。 不推荐在依赖声明中使用LATEST和RELEASE，因为Maven随时都可能解析到不同的构件。Maven3不再支持在插件配置中使用LATEST和RELEASE。 若不设置插件版本，其效果就和RELEASE一样，Maven会解析最新的发布版本构件。 1234567891011121314151617181920&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;metadata modelVersion=\"1.1.0\"&gt; &lt;groupId&gt;com.test&lt;/groupId&gt; &lt;artifactId&gt;web-core&lt;/artifactId&gt; &lt;version&gt;3.1.0-SNAPSHOT&lt;/version&gt; &lt;versioning&gt; &lt;snapshot&gt; &lt;timestamp&gt;20180831.035005&lt;/timestamp&gt; &lt;buildNumber&gt;11&lt;/buildNumber&gt; &lt;/snapshot&gt; &lt;lastUpdated&gt;20180831035005&lt;/lastUpdated&gt; &lt;snapshotVersions&gt; &lt;snapshotVersion&gt; &lt;extension&gt;jar&lt;/extension&gt; &lt;value&gt;3.1.0-20180831.035005-11&lt;/value&gt; &lt;updated&gt;20180831035005&lt;/updated&gt; &lt;/snapshotVersion&gt; &lt;/snapshotVersions&gt; &lt;/versioning&gt;&lt;/metadata&gt; timestamp和buildNumber分别代表了这一快照的时间戳和构件号。 仓库元数据并不是永远正确的，若无法解析或解析错误，可能出现了元数据错误，可以手工或使用工具修复。 镜像若仓库A能提供仓库B存储的所有内容，则A就是B的一个镜像，任何一个能从B仓库获得的构件都能从镜像中获取。http://maven.net.cn/content/groups/public/ 是中央仓库 http://repo1.maven.org/maven2 在中国的镜像。 12345678&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;mirrorId&lt;/id&gt; &lt;mirrorOf&gt;repositoryId&lt;/mirrorOf&gt; &lt;name&gt;Human Readable Name for this Mirror.&lt;/name&gt; &lt;url&gt;http://my.repository.com/repo/path&lt;/url&gt; &lt;/mirror&gt;&lt;/mirrors&gt; mirrorOf的值为central，表示该配置为中央仓库的镜像，任何对于中央仓库的请求都会转至该镜像。id、name、url与一般仓库配置无异，表示该镜像仓库的唯一标识符、名称以及地址。若需要认证也可以基于该id配置仓库认证。 镜像的一个更常见的用法是结合私服，私服就是所有仓库的镜像。 &lt;mirrorOf&gt;*&lt;/mirrorOf&gt;：匹配所有远程仓库 &lt;mirrorOf&gt;external: *&lt;/mirrorOf&gt;：匹配所有远程仓库，使用localhost的除外，使用file://协议的除外。匹配所有不在本机上的远程仓库。 &lt;mirrorOf&gt;repo1, repo2&lt;/mirrorOf&gt;：匹配仓库repo1、repo2，使用逗号分隔多个远程仓库。 &lt;mirrorOf&gt;*, !repo1&lt;/mirrorOf&gt;：匹配所有远程仓库，repo1 除外，使用感叹号将仓库从匹配中排除。 镜像仓库会完全屏蔽被镜像仓库，当镜像仓库不稳定或停止服务时，Maven无法访问被镜像仓库，因而将无法下载构件。 仓库搜索服务Sonatype Nexus：提供的关键字搜索、类名搜索、坐标搜索、校验和搜索等功能。 Jarvana：提供基于关键字、类名的搜索，构件下载、依赖声明片段等功能。 Mvnbrowser：只提供关键字搜索，能告知用户构件依赖于哪些构件，以及该构件被哪些其他构件依赖。 MVNrepository：界面清新，提供关键字搜索、依赖声明代码片段、构件下载、依赖与被依赖关系信息、构件所包含信息等功能，提供一个简单图标，显示某个构件各个版本间的大小变化。","tags":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/tags/Maven/"}],"categories":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/categories/Maven/"}]},{"title":"Maven基础","date":"2018-12-07T16:00:00.000Z","path":"Blog/Maven/Maven基础/","text":"Maven坐标详解groupId：定义当前Maven项目隶属的实际项目，不应该对应隶属的组织或公司，表示方式与Java包名表示方式类是。 artifactId：定义实际项目中的一个Maven项目（模块），推荐使用实际项目名称作为前缀。 version：项目当前版本号。 type：依赖类型，默认为jar。 scope：依赖范围。 optional：标记依赖是否可选。 exclusions：排除传递性依赖。 packaging：项目打包方式，默认为jar。 classifier：用来帮助定义构建输出的一些附属构件。不能直接定义项目classifier，附属构件不是项目直接默认生成，而是由附加插件帮组生成。附属构件名称一般规则artifactId-version[-classifier].packaging 123456&lt;dependency&gt; &lt;groupId&gt;net.sf.json-lib&lt;/groupId&gt; &lt;artifactId&gt;json-lib&lt;/artifactId&gt; &lt;classifier&gt;jdk15&lt;/classifier&gt; &lt;version&gt;2.1&lt;/version&gt;&lt;/dependency&gt; 依赖范围Maven在编译项目主代码时需使用一套classpath，在编译执行测试时会使用另一套classpath，实际运行项目时又会使用另一套classpath。依赖范围就是用来控制依赖与这三种classpath(编译classpath、测试classpath、运行classpath)的关系，依赖范围还对传递性依赖产生影响。 compile：编译依赖范围，依赖默认值，使用此依赖范围的Maven依赖，对于编译、测试、运行三种classpath都有效。 test：测试依赖范围，只对测试classpath有校，编译和运行时均无效。 provided：以提供依赖范围，对编译和测试classpath有效，运行时无效。 runtime：运行时依赖范围，测试和运行时有效，编译主代码时无效。 system：系统依赖范围，该依赖与三种classpath的关系和provided依赖范围完全一致。但使用该依赖范围必须通过systemPath显示指定依赖文件路径，此依赖不通过Maven仓库解析，往往与本机绑定，可能造成构建的不可移植，且可引用环境变量。 1234567&lt;dependency&gt; &lt;groupId&gt;com&lt;/groupId&gt; &lt;artifactId&gt;rt&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;$&#123;basedir&#125;/src/main/webapp/WEB-INF/lib/rt.jar&lt;/systemPath&gt;&lt;/dependency&gt; import：导入依赖范围，不会对三种classpath产生实际影响。 依赖范围(scope) 对编译classpath有效 对测试classpath有效 对运行时classpath有效 compile √ √ √ test × √ × provided √ √ × runtime × √ √ system √ √ × 传递性依赖Maven传递性依赖能很好的解决引入的依赖包依赖于其他开源类库的情况，大大简化和方便了依赖声明，大部分情况下只需要关心项目直接依赖，Maven会解析各个直接依赖的POM，将必要的间接依赖以传递性依赖的形式引入到当前项目。 A有一个compile范围的B依赖，而B有一个compile范围的C依赖，则C就成了A的compile范围依赖，即C是A的传递性依赖。A对于B是第一直接依赖，B对于C是第二直接依赖，下表种左边第一列表示第一直接依赖范围，第一行表示第二直接依赖范围，中间交叉单元格表示传递性依赖范围。 compile test provided runtime compile compile — — runtime test test — — test provided provided — provided provided runtime runtime — — runtime 当第二直接依赖范围是compile时，传递性依赖范围与第一直接依赖范围一致，当第二传递性依赖范围是test时，依赖不会传递，当第二直接依赖是provided时，只传递第一直接依赖范围为provided的依赖，且传递性依赖范围同样为provided，当第二直接依赖范围是runtime时，传递性依赖范围与第一直接依赖范围一致，但compile例外。 依赖调解当传递性依赖造成问题时，需要清楚的知道该传递性依赖时从哪条依赖路径引入，若项目A有这样的依赖关系：A —&gt; B —&gt; C —&gt; X(1.0)、A —&gt; D —&gt; X(2.0)。X是A的传递性依赖，但两条路径上有两个版本的X，这时Maven的依赖调解就会起作用。这时会用到依赖调解的第一原则：路径最近者优先。 但第一原则不能解决类似：A —&gt; B —&gt; Y(1.0)、A —&gt; C —&gt; Y(2.0)依赖路径长度一样的情况。从Maven 2.0.9开始定义的第二原则：第一声明者优先。 可选依赖若存在A —&gt; B、B —&gt; X(可选)、B —&gt; Y(可选)，由于传递性依赖的定义，X、Y是可选依赖，依赖将不会得以传递。 但为什么要使用可选依赖呢？可能项目B实现了两个互斥特性X和Y，用户不可能同时使用这两个特性。理想情况下不应该使用可选依赖。 排除依赖传递性依赖会给项目隐式地引入很多依赖，极大的简化项目依赖管理的同时也会带来一些问题。若项目A依赖于B，而B又依赖于另一个类库的SNAPSHOP版本，但由于SNAPSHOP的不稳定直接影响到当前项目，这时就需要排除SNAPSHOP引入一个正式版。在依赖冲突时，也需要排除冲突的依赖。 1234567891011&lt;dependency&gt; &lt;groupId&gt;org.jvnet.jaxb2-commons&lt;/groupId&gt; &lt;artifactId&gt;property-listener-injector&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;jaxb-api&lt;/artifactId&gt; &lt;groupId&gt;javax.xml.bind&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; exclusions元素可以包含一个或多个exclusion子元素，声明exclusion时只需要groupId和artifactId不需要version元素，因为Maven解析后的依赖中，不可能存在groupId和artifactId相同version不同的两个依赖。 依赖归类引入的同一项目中的不同模块，这些依赖的版本应该是相同的，最好使用properties元素定义Maven属性，使用美元符号和大括弧环绕的方式引用Maven属性。 依赖优化mvn dependency:list 查看当前项目的已解析依赖 mvn dependency:tree 查看当前项目的依赖树 mvn dependency:analyze 分析当前项目的依赖。Used undeclared dependencies表示使用到了但未显示声明依赖，意味着存在潜在风险，当直接依赖升级相关依赖发生版本变化可能导致当前项目出错。Unused declared dependencies表示未使用但显示声明的依赖。 在IDEA中可以直接使用Maven Helper工具来完成依赖的优化。","tags":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/tags/Maven/"}],"categories":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/categories/Maven/"}]},{"title":"Maven常用工具","date":"2018-12-07T16:00:00.000Z","path":"Blog/Maven/Maven常用工具/","text":"Lombok1234&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt;&lt;/dependency&gt; Mybatis Plus12345&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis-plus.version&#125;&lt;/version&gt;&lt;/dependency&gt; Mybatis 增强工具，在 Mybatis 的基础上只做增强不做改变，简化开发、提高效率。 Okhttp12345&lt;dependency&gt; &lt;groupId&gt;com.squareup.okhttp3&lt;/groupId&gt; &lt;artifactId&gt;okhttp&lt;/artifactId&gt; &lt;version&gt;$&#123;okhttp.version&#125;&lt;/version&gt;&lt;/dependency&gt; 高效的HTTP客户端，默认特性： 支持HTTP/2，允许所有同一个主机地址的请求共享同一个socket连接 连接池减少请求延时 透明的GZIP压缩减少响应数据的大小 缓存响应内容，避免一些完全重复的请求 Java工具包12345&lt;dependency&gt; &lt;groupId&gt;cn.hutool&lt;/groupId&gt; &lt;artifactId&gt;hutool-all&lt;/artifactId&gt; &lt;version&gt;$&#123;hutool.version&#125;&lt;/version&gt;&lt;/dependency&gt; Hutool是一个Java工具包类库，对文件、流、加密解密、转码、正则、线程、XML等JDK方法进行封装，组成各种Util工具类，文档地址：https://www.hutool.cn/ 分页插件1234&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt;&lt;/dependency&gt;","tags":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/tags/Maven/"}],"categories":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/categories/Maven/"}]},{"title":"IDEA实用插件","date":"2018-12-07T16:00:00.000Z","path":"Blog/杂记/IDEA实用插件/","text":"Alibaba Java Coding Guidelines《阿里巴巴Java开发规约》扫描插件 MyBatis plugin将Mybatis中的Mapper文件中的方法和XML中对应的方法相互关联 Lombok通过注解减少很多重复代码的书写，比如说getter/setter/toString等方法的编写 Maven Helper包含的Maven使用命令，以及引入插件的命令，可以通过按钮直接操作，且包含强大Dependency Analyzer功能 String Manipulation把字符串处理成编程时常用的格式 Translation一个牛逼好用翻译插件，不用来回切换翻译软件，直接就能在IDE中使用 iedisredis客户端可视化插件 GsonFormat根据JSON生成POJO GenerateSerialVersionUID生成serialVersionUID的小插件 VisualVM LauncherJava性能分析插件 Cloud Toolkit帮助开发者更高效地开发、测试、诊断并部署应用。通过 Cloud Toolkit，开发者能够方便地将本地应用一键部署到任意机器（本地或云端），并内置 Arthas 诊断、高效执行终端命令和 SQL 等 Mybatis Log Plugin对Mybatis打印的SQL日志进行优化，能直接拷贝使用。 RestfulToolkitRESTful 服务开发辅助工具集，URL 直接跳转到对应的方法定义 ，提供了一个 Services tree 的显示窗口，一个简单的 http 请求工具 Rainbow Brackets彩虹颜色的括号，清除分清括号个数，防止括号错乱。","tags":[{"name":"IDEA","slug":"IDEA","permalink":"https://yaoyinglong.github.io/tags/IDEA/"}],"categories":[{"name":"杂记","slug":"杂记","permalink":"https://yaoyinglong.github.io/categories/杂记/"}]},{"title":"Redis分布式锁实现","date":"2018-11-30T16:00:00.000Z","path":"Blog/框架/Redis分布式锁实现/","text":"锁实现12345678910111213141516171819202122232425262728293031public static final String LOCK_SUCCESS = \"OK\";public static final Long RELEASE_SUCCESS = 1L;public static final String SET_IF_NOT_EXIST = \"NX\";public static final String SET_WITH_EXPIRE = \"PX\";public static final String COMPARE_AND_DELETE = \"if redis.call('get',KEYS[1]) == ARGV[1]\\n\" + \"then\\n\" + \" return redis.call('del',KEYS[1])\\n\" + \"else\\n\" + \" return 0\\n\" + \"end\";@Autowiredprivate StringRedisTemplate stringRedisTemplate;public boolean getLock(String key, String requestId) &#123; String status = stringRedisTemplate.execute((RedisCallback&lt;String&gt;) connection -&gt; &#123; Jedis jedis = (Jedis) connection.getNativeConnection(); return jedis.set(key, requestId, SET_IF_NOT_EXIST, SET_WITH_EXPIRE, 20000); &#125;); return LOCK_SUCCESS.equals(status);&#125;public boolean releaseLock(String key, String requestId) &#123; List&lt;String&gt; keys = Collections.singletonList(key); Object result = stringRedisTemplate.execute(new DefaultRedisScript&lt;&gt;(COMPARE_AND_DELETE, String.class), keys, requestId); return RELEASE_SUCCESS.equals(result);&#125; 使用redission 运用1234567891011121314151617181920212223242526272829303132333435protected void syncUpdateCheck(String pid, Company company) &#123; long beforeTime = System.currentTimeMillis(); Date date = lastUpdateTime(company); if (date == null || System.currentTimeMillis() - date.getTime() &gt; updatePeriod()) &#123; String tag = \"ENT:DATA:UPDATE:CHECK:\" + code() + \":\" + company.getUuid(); long maxSleepMills = System.currentTimeMillis() + 20000; boolean lock = false; try &#123; while (!lock) &#123; lock = redisLockService.getLock(tag, pid); if (lock) &#123; date = lastUpdateTime(company); if (date == null || System.currentTimeMillis() - date.getTime() &gt; updatePeriod()) &#123; requestService.request(pid, company, code()); &#125; break; &#125; else &#123; date = lastUpdateTime(company); if (date != null &amp;&amp; System.currentTimeMillis() - date.getTime() &lt; updatePeriod()) &#123; break; &#125; if (System.currentTimeMillis() &gt; maxSleepMills) &#123; throw new UpdateCheckException(\"syncUpdateCheck获取锁资源等待超时\"); &#125; TimeUnit.MILLISECONDS.sleep(5); &#125; &#125; &#125; catch (InterruptedException e) &#123; LOGGER.error(\"syncUpdateCheck线程wait异常导致中断:\" + e.getMessage()); &#125; finally &#123; redisLockService.releaseLock(tag, pid); date = lastUpdateTime(company); &#125; &#125; &#125; 缓存问题同一时间缓存失效： 将缓存时间散列化 过滤非法请求： 把所有商品全部缓存，去缓存校验 布隆过滤器","tags":[{"name":"分布式锁","slug":"分布式锁","permalink":"https://yaoyinglong.github.io/tags/分布式锁/"}],"categories":[{"name":"框架","slug":"框架","permalink":"https://yaoyinglong.github.io/categories/框架/"}]},{"title":"原子性、可见性、有序性","date":"2018-09-20T16:00:00.000Z","path":"Blog/Java/并发/原子性、可见性、有序性/","text":"Java内存模型是围绕着在并发过程中如何处理原子性、可见性、和有序性这三个特征来建立的。 原子性Java内存模型要求lock、unlock、read、load、assign、use、store、write这八个操作都具有原子性。 Java内存模型直接保存的原子性变量操作有read、load、assign、use、store、write；大致可认为基本数据类型（除long和double）的访问读写具备原子性。 Java内存模型还提供了lock和unlock操作来保证更大范围的原子操作，虚拟机未把lock和unlock操作直接开放给用户使用，但提供了更高层次的字节码指令monitorenter和monitorexit来隐式使用这个操作，这两个字节码指令反映到Java代码中就是同步块synchronized关键字。 可见性当一个线程修改了共享变量值，其他线程能够立即得知这个修改。Java内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值这种依赖主内存作为传递媒介的方式类实现可见性，普通变量和volatile变量都是如此。 普通变量与volatile变量区别：volatile保证了新值能立即同步到主内存，每次使用前立即从主内存刷新，保证了多线程操作时变量的可见性； 除volatile外，Java还可以通过synchronized和final关键字来实现可见性；同步块的可见性是在一个变量执行unlock操作之前，必须先把此变量同步回主内存中；final可见性是指，被final修饰的字段在构造器中一旦初始化完成，并且构造器没有this引用逃逸，在其他线程中能看见final字段的值。 有序性如果在同一线程中所有操作都是有序的，如果在一个线程中观察另一个线程所有操作都是无序的，前半句是指线程内表现为串行语义，后半句指指令重排序现象和工作内存与主内存同步延迟现象。 volatile和synchronized都能保证线程之间操作的有序性，volatile关键字本身包含了禁止指令重排序语义，而synchronized则是由一个变量在同一个时刻只允许一条线程对其进行lock操作，保证了持有同一个锁的两个同步块只能串行进入。 long和double变量的特殊规则虚拟机允许将没有被volatile修饰的64位数据的续写操作划分为两次32位操作，即允许虚拟机实现选择可以不保证64位数据类型的load、store、read、write四个操作的原子性。 若多个线程共享一个未被声明为volatile的long或double类是变量，并行读取修改，某些线程可能读取到一个既非原值，但这种情况非常罕见，且商用Java虚拟机中不会出现，Java内存模型虽然允许虚拟机不把long和double变量的读写实现为原子操作，但允许虚拟机选择把这些操作实现为具有原子性的操作。","tags":[{"name":"多线程，Thread","slug":"多线程，Thread","permalink":"https://yaoyinglong.github.io/tags/多线程，Thread/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://yaoyinglong.github.io/categories/Java/并发/"}]},{"title":"线程安全","date":"2018-09-20T16:00:00.000Z","path":"Blog/Java/并发/线程安全/","text":"Java中各种操作共享数据按照线程安全的安全程度由强至弱分为不可变、绝对线程安全、相对线程安全、线程兼容、线程对立； 不可变不可变的对象一定是线程安全的，只要一个不可变对象被正确构建，没有this引用逃逸，其外部可见状态永远不会改变；Java中符合不可变要求的类型：java.lang.String、枚举类型、java.lang.Number的部分子类（如Long和Double等数值包装类型，BigInteger和BigDecimal等大数据类型），同为Number子类型的原子类AtomicInteger和AtomicLong并非不可变； 若共享数据是基本数据类型，只要在定义时使用final关键字修饰就可以保证是不可变的； 若共享数据是一个对象，保证对象的行为不会对其状态产生任何影响，保证对象行为不影响自己状态的途径有很多种，最简单的方式是将对象中带有状态的变量声明为final； 绝对线程安全一个类要达到不管运行时环境如何，调用者不需要任何额外同步措施通常需要付出很大的代价；Java中标注自己是线程安全的类大多数都不是绝对线程安全的。 代码示例待补充…… 相对线程安全通常意义上的线程安全，它保证对这个对象单独操作是线程安全的，调用时不需要做额外的保障措施，但对一些特定顺序的连续操作，就可能需要在调用端使用额外的同步手段来保证调用的正确性。大部分线程安全的类属于这种类型，例如：Vector、HashTable、Collections的synchronizedCollection()方法包装的集合等； 线程兼容指对象本身不是线程安全的，但是可以通过在调用端正确地使用同步手段来保证对象在并发环境中可以安全地使用。 线程对立指无论调用端是否采取同步措施，都无法再多线程环境中并发使用的代码。例：Thread类的suspend()和resume()方法，两个线程同时持有一个线程对象，一个尝试中断一个尝试恢复，并发时无论是否进行同步，目标线程都存在死锁风险。常见还有System.setIn()、System.setOut()和System.runFinalizersOnExit()等","tags":[{"name":"多线程，Thread","slug":"多线程，Thread","permalink":"https://yaoyinglong.github.io/tags/多线程，Thread/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://yaoyinglong.github.io/categories/Java/并发/"}]},{"title":"线程安全实现方式","date":"2018-09-20T16:00:00.000Z","path":"Blog/Java/并发/线程安全实现方式/","text":"互斥同步同步是指在多个线程并发访问共享数据时，保证共享数据在同一个时刻只被一个线程使用（或者是一些，使用信号量的时候），互斥是实行同步的一种手段，临界区、互斥量和信号量都是主要的互斥实现方式。互斥是因，同步是果，互斥是方法，同步是目的。 Java中最基本的互斥同步手段是使用synchronized关键字，synchronized关键字编译后，会在同步代码块前后分别形成monitorenter和monitorexit字节码指令，这两个字节码都需要一个reference类型的参数来指明要锁定和解锁的对象。若synchronized明确指定了对象参数，那就是这个对象的reference，若没有明确指定，就根据synchronized修饰的是实例方法还是类方法，则取对应的对象实例或Class对象来作为锁对象。 虚拟机规范要求，执行monitorenter指令时，首先尝试获取对象的锁，若对象没有被锁定或当前线程已经拥有这个对象的锁，将锁的计数器加一，执行monitorexit指令时将锁计数器减一，当计数器为零时锁被释放。若获取对象锁失败，当前线程阻塞等待，直到对象锁被另一个线程释放。 synchronized同步块对同一条线程是可重入的，不会将自己死锁。同步块在已进入的线程执行完成之前，会阻塞后面其他线程的进入。Java线程是映射到操作系统原生线程上的，阻塞或唤醒线程都需要操作系统帮忙，需要从用户状态转换到核心态中，因此转态转换需要耗费很多处理器时间。 虚拟机自身进行了一些优化，在通知操作系统阻塞线程之前加入一段自旋等待过程，避免频繁地切入到核心态。 除了synchronized关键字外还可以使用java.lang.concurrent包中的重入锁ReentrantLock来实现同步，基本用法上ReentrantLock与synchronized类似都具备一样的线程重入特性，只是写法上有些许区别，ReentrantLock表现为API层面的互斥锁（lock()和unlock()方法配合try/finally语句来完成），而synchronized表现为原生语法层面的互斥锁。相比synchronized，ReentrantLock增加了等待可中断、公平锁和锁绑定多个条件。 等待可中断：指当持有锁的线程长期不释放时，正在等待的线程可选择放弃等待，改为处理其他事情； 公平锁：指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁，反之则为非公平锁；synchronized是非公平锁，ReentrantLock默认也是非公平锁，但可通过带布尔值构造函数要求使用公平锁。 锁绑定多个条件：指ReentrantLock对象能同时绑定多个Condition对象，在synchronized中所对象的wait()和notify()或notifyAll()方法能实现一个隐含条件，若与多于一个关联条件需要额外添加锁，而ReentrantLock只需要多次调用newCondition()方法。 JDK1.5下synchronized吞吐量下降非常严重，而ReentrantLock能基本保持在用一个比较稳定的水平。JDK1.6及之后synchronized与ReentrantLock性能基本上完全持平，提倡优先考虑使用synchronized进行同步。 互斥同步最主要的问题是进行线程阻塞和唤醒所带来的性能问题，因此也称为阻塞同步，互斥同步属于一种悲观并发策略。 非阻塞同步非阻塞同步是一种基于冲突检测的乐观并发策略，先进行操作，若没有其他线程争用共享数据操作成功，若共享数据有争用产生了冲突，再采取其他补偿措施，最常见的补偿措施就是不断重试直到成功。但乐观并发策略需要硬件指令集的发展才能进行，因为操作和冲突检测两个步骤具备原子性需要硬件来保证。常用硬件指令有： 测试并设置（Test-and-Set） 获取并增加（Fetch-and-Increment） 交换（Swap） 比较并交换（Compare-and-Swap，CAS） 加载链接/条件存储（Load-Linked/Store-Conditional，LL/SC） CAS指令需要三个操作，分别是内存位置、旧预期值和新值。CAS指令在执行时，当且仅当内存位置符合旧预期值时，处理器用新值更新内存位置的值，否则不执行更新，但无论是否更新内存位置，都返回内存位置的旧值，该处理过程是一个原子操作。 在JDK1.5后才能使用CAS操作，该操作由sun.misc.Unsafe类中的compareAndSwapInt()和compareAndSwapLong()等几个方法包装提供，虚拟机内部对这些方法做了特殊处理，即时编译出来的结果是一条平台相关的处理器CAS指令，没有方法调用过程。 但Unsafe类不提供给用户程序调用，若不采用反射只能通过其他Java API间接使用，如J.U.C包中的整数原子类，其中的compareAndSet()和compareAndIncrement()等方法都使用了Unsafe类的CAS操作。 CAS并不完美，存在一个ABA问题的逻辑漏洞，J.U.C包为了解决该问题，提供了一个带标记的原子引用类AtomicStampedReference通过控制变量值的版本来保证CAS正确性。但比较鸡肋，ABA问题大部分情况不会影响正确性，若要解决ABA问题用互斥同步可能更高效。 无同步方案要保证线程安全，并不是一定要进行同步，两者没有因果关系。 可重入代码也加纯代码，能在代码执行的任何时刻中断，转而执行另一段代码，包括递归调用其本身，在控制权返回后原来的程序不会出现任何错误。所有的可重入代码都是线程安全的，相对线程安全来说，可重入性是更根本的特性，但并非所有线程安全的代码都是可重入的。 可重入代码共性：不依赖存储在堆上的数据和公用的系统资源、用到的状态量都是由参数传入、不调用非可重入方法等。 可重入性简单判定原则：若一个方法返回结果可预测，输入相同的数据就能返回相同的结果。 线程本地存储，一段代码所需要的数据必须与其他代码共享，且共享数据的代码能保证在同一个线程中执行，能把共享数据的可见范围限制在同一个线程内。 常见的符合线程本地存储的条件的有：大部分使用消费队列的架构模式、web交互模型中的一个请求对应一个服务器线程。 若变量要被多个线程访问，可使用volatile关键字声明为易变的，若只被某个线程独享，可使用java.lang.ThreadLocal类来实现线程本地存储功能，每个线程的Thread对象中都有一个ThreadLocalMap对象。","tags":[{"name":"多线程，Thread","slug":"多线程，Thread","permalink":"https://yaoyinglong.github.io/tags/多线程，Thread/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://yaoyinglong.github.io/categories/Java/并发/"}]},{"title":"SpringMvc异步原理及实现","date":"2018-08-05T16:00:00.000Z","path":"Blog/框架/Spring/SpringMvc异步/","text":"在实际的项目中，可能会用到HTTP异步请求方式来提高系统的吞吐量。 同步请求客户端发起同步HTTP请求时，线程进入等待状态，直到接受到一个response对象或者请求超时状态 ，往返WEB服务器的过程： HTTP请求在经过DNS服务器的域名解析，到Nginx反向代理转发到我们的WEB服务器（servlet容器，Tomcat），WEB服务器会启动一个请求处理线程来处理请求，完成资源分配处理之后，线程起调后端的处理线程，同时WEB服务器的线程将会进入阻塞状态，直到后端的线程处理完毕，WEB服务器释放请求处理线程的资源，同时返回response对象，客户端接收到response对象，整个请求完成。 若后端处理服务器中进行了大量的IO操作，数据库操作，或者跨网调用等耗时操作，导致请求处理线程进入长时间的阻塞。因为WEB服务器的请求处理线程条个数是有限的，如果同时大量的请求阻塞在WEB服务器中，新的请求将会处于等待状态，甚至服务不可用，connection refused。 异步请求Servlet3的异步web机制的引入，改造接口服务，可以让请求线程(IO线程)和业务处理线程分开，进而对业务进行线程池隔离。 解决tomcat线程池资源消耗，频繁gc，高io，堆内存上升 。还可以根据业务重要性进行业务分级，然后再把线程池分级 。还可以根据这些分级做其它操作比如监控和降级处理。 请求处理线程对后台处理的调用使用了invoke的方式，调invoke方法后直接返回不等待，请求处理线程就释放了，它可以接着去处理别的请求，当后端处理完成后，会钩起一个回调处理线程来处理调用的结果，这个回调处理线程跟请求处理线程也许都是线程池中的某个线程，相互间可以完全没有关系，由这个回调处理线程向浏览器返回内容。 带来的改进是显而易见的，请求处理线程不需要阻塞了，它的能力得到了更充分的使用，带来了服务器吞吐能力的提升。下图是异步请求过程图： Servlet3异步流程 接收到request请求之后，由Tomcat工作线程从HttpServletRequest中获得一个异步上下文AsyncContext对象，然后由Tomcat工作线程把AsyncContext对象传递给业务处理线程，同时Tomcat工作线程归还到工作线程池，这一步就是异步开始。在业务处理线程中完成业务逻辑的处理，生成response返回给客户端。在Servlet3.0中虽然处理请求可以实现异步，但是InputStream和OutputStream的IO操作还是阻塞的，当数据量大的request body 或者 response body的时候，就会导致不必要的等待。从Servlet3.1以后增加了非阻塞IO，需要tomcat8.x支持。 Servlet3的异步使用步骤： 声明Servlet，增加asyncSupported属性，开启异步支持。@WebServlet(urlPatterns = &quot;/simpleAsync&quot;, asyncSupported = true) 通过request获取异步上下文AsyncContext。AsyncContext asyncCtx = request.startAsync(); 开启业务逻辑处理线程，并将AsyncContext 传递给业务线程。executor.execute(new AsyncRequestProcessor(asyncCtx, secs)); 在异步业务逻辑处理线程中，通过asyncContext获取request和response，处理对应的业务。 业务逻辑处理线程处理完成逻辑之后，调用AsyncContext 的complete方法。asyncContext.complete();从而结束该次异步线程处理。 同步异步对比实际写了一个固定延时10秒的Demo，Tomcat的参数设置如下： 1234tomcat: max-threads: 5 accept-count: 10 max-connections: 1000 在500的并发下分别对同步和异步请求进行了测试，通过MBean对Tomcat参数进行监控 同步情况下currentThreadsBusy参数始终是与最大线程数一致，说明线程一致未释放，会导致请求一致阻塞 异步情况由于后台是异步处理的线程马上就释放了，故currentThreadsBusy基本上都是0。在某些情况下能够极大的提升系统吞吐量。 将Tomcat业务线程池的压力转移到系统自定义线程池中。使得更加可控，即使变更应用服务器系统任然兼容。 Spring异步Spring MVC 3.2开始引入了基于Servlet 3的异步请求处理。相比以前，控制器方法已经不一定需要返回一个值，而是可以返回一个java.util.concurrent.Callable对象，并通过Spring MVC所管理的线程来产生返回值。 同时Servlet容器的主线程则可以退出并释放其资源了，同时也允许容器去处理其他的请求。通过一个TaskExecutor，Spring MVC可以在另外的线程中调用Callable。当Callable返回时，请求再携带Callable返回的值，再次被分配到Servlet容器中恢复处理流程。 另一个选择，是让控制器方法返回一个DeferredResult实例。该场景下，返回值可由任何一个线程产生，也包括那些不是由Spring MVC管理的线程。 返回值可能是为了响应某些外部事件所产生的，比如一条JMS的消息，一个计划任务 。 Callable异步请求 控制器先返回一个Callable对象 Spring MVC开始进行异步处理，并把该Callable对象提交给另一个独立线程的执行器TaskExecutor处理 DispatcherServlet和所有过滤器都退出Servlet容器线程，但此时方法的响应对象仍未返回 Callable对象最终产生一个返回结果，此时Spring MVC会重新把请求分派回Servlet容器，恢复处理 DispatcherServlet再次被调用，恢复对Callable异步处理所返回结果的处理 DeferredResult异步请求 控制器先返回一个DeferredResult对象，并把它存取在内存（队列或列表等）中以便存取 Spring MVC开始进行异步处理 DispatcherServlet和所有过滤器都退出Servlet容器线程，但此时方法的响应对象仍未返回 由处理该请求的线程对 DeferredResult进行设值，然后Spring MVC会重新把请求分派回Servlet容器，恢复处理 DispatcherServlet再次被调用，恢复对该异步返回结果的处理 SpringMvc异步实现方式一： 12345678910111213141516171819202122public Callable&lt;String&gt; process(HttpServletResponse response) &#123; return () -&gt; &#123; response.setContentType(\"text/plain;charset=utf-8\"); response.getWriter().write(\"响应内容\"); response.getWriter().close(); return null; &#125;;&#125;// taskService是一个@Service注解类public Callable&lt;Map&lt;String, Object&gt;&gt; process() &#123; Callable&lt;Map&lt;String, Object&gt;&gt; callable = taskService::execute; return callable;&#125;// taskService是一个@Service注解类public Callable&lt;Map&lt;String, Object&gt;&gt; process() &#123; Callable&lt;Map&lt;String, Object&gt;&gt; callable = () -&gt; &#123; return taskService.execute(); &#125;; return callable;&#125; SpringMvc异步实现方式二： 1234567891011// taskService是一个@Service注解类public WebAsyncTask process() &#123; Callable&lt;Map&lt;String, Object&gt;&gt; callable = taskService::execute; return new WebAsyncTask&lt;&gt;(20000, callable);&#125;// taskService是一个@Service注解类public WebAsyncTask process() &#123; Callable&lt;Map&lt;String, Object&gt;&gt; callable = taskService::execute; return new WebAsyncTask&lt;&gt;(callable);&#125; SpringMvc异步实现方式三： 123456public DeferredResult&lt;Map&lt;String, Object&gt;&gt; process() &#123; DeferredResult&lt;Map&lt;String, Object&gt;&gt; deferredResult = new DeferredResult&lt;&gt;(); CompletableFuture.supplyAsync(taskService::execute) .whenCompleteAsync((result, throwable) -&gt; deferredResult.setResult(result)); return deferredResult;&#125; 方式一和方式二Spring返回的Callable被RequestMappingHandlerAdapter拦截，使用SimpleAsyncTaskExecutor线程池处理，每当任务被提交到此线程池时，线程池产生一个新的线程去执行Callable中的代码， 每次都产生新的线程而且没有上上限(默认没有上限的，可以设置concurrencyLimit属性来设置线程数的大小) 但：SimpleAsyncTaskExecutor 线程池性能不好，可使用自定义的线程池来代替。 方式三使用的是CompletableFuture.supplyAsync，在completablefuture的supplyasync方法将在ForkJoinPool池运行任务。也可以使用任何其他的线程池来执行。 若不自定线程池，MvcAsync线程数会飙涨： 自定义MVC Callable线程池： 123456789101112131415161718192021222324252627282930313233@Bean@ConfigurationProperties(prefix = \"spring.task.mvcPool\")public TaskPoolConfig mvcPoolConfig() &#123; return new TaskPoolConfig();&#125;@Beanpublic AsyncTaskExecutor mvcTaskExecutor(TaskPoolConfig mvcPoolConfig) &#123; ThreadPoolTaskExecutor threadPool = new ThreadPoolTaskExecutor(); threadPool.setCorePoolSize(mvcPoolConfig.getCorePoolSize()); threadPool.setMaxPoolSize(mvcPoolConfig.getMaxPoolSize()); threadPool.setQueueCapacity(mvcPoolConfig.getQueueCapacity()); threadPool.setAllowCoreThreadTimeOut(mvcPoolConfig.isAllowCoreThreadTimeOut()); threadPool.setWaitForTasksToCompleteOnShutdown( mvcPoolConfig.isWaitForTasksToCompleteOnShutdown()); threadPool.setKeepAliveSeconds(mvcPoolConfig.getKeepAliveSeconds()); threadPool.setThreadNamePrefix(\"Mvc-Thread-\"); threadPool.setRejectedExecutionHandler(rejectedExecutionHandler); threadPool.initialize(); return threadPool;&#125;@Beanpublic WebMvcConfigurerAdapter webMvcConfigurerAdapter(AsyncTaskExecutor mvcTaskExecutor) &#123; return new WebMvcConfigurerAdapter() &#123; @Override public void configureAsyncSupport(AsyncSupportConfigurer configurer) &#123; configurer.setTaskExecutor(mvcTaskExecutor); super.configureAsyncSupport(configurer); &#125; &#125;;&#125; 请求由Tomcat业务线程池转移到系统自定义线程池中，从下面的示例中可以明显得看出Tomcat的处理线程非常快的就结束了，而由自定义线程池中的线程去处理任务，等任务结束后再由Tomcat线程响应给用户： 1234567891011121314151617[nio-8011-exec-4] c.i.ent.controller.DashboardController : async start[nio-8011-exec-4] c.i.ent.controller.DashboardController : async end[nio-8011-exec-3] c.i.ent.controller.DashboardController : async start[nio-8011-exec-3] c.i.ent.controller.DashboardController : async end[nio-8011-exec-5] c.i.ent.controller.DashboardController : async start[nio-8011-exec-5] c.i.ent.controller.DashboardController : async end[nio-8011-exec-2] c.i.ent.controller.DashboardController : async start[nio-8011-exec-2] c.i.ent.controller.DashboardController : async end[ Mvc-Thread-4] c.i.ent.service.impl.TaskServiceImpl : Mvc-Thread-4执行进度:task：0/10[ Mvc-Thread-2] c.i.ent.service.impl.TaskServiceImpl : Mvc-Thread-2执行进度:task：0/10[ Mvc-Thread-7] c.i.ent.service.impl.TaskServiceImpl : Mvc-Thread-7执行进度:task：0/10[ Mvc-Thread-5] c.i.ent.service.impl.TaskServiceImpl : Mvc-Thread-5执行进度:task：0/10[ Mvc-Thread-3] c.i.ent.service.impl.TaskServiceImpl : Mvc-Thread-3执行进度:task：0/10[ Mvc-Thread-1] c.i.ent.service.impl.TaskServiceImpl : Mvc-Thread-1执行进度:task：0/10[ Mvc-Thread-6] c.i.ent.service.impl.TaskServiceImpl : Mvc-Thread-6执行进度:task：0/10[ Mvc-Thread-8] c.i.ent.service.impl.TaskServiceImpl : Mvc-Thread-8执行进度:task：0/10[ Mvc-Thread-9] c.i.ent.service.impl.TaskServiceImpl : Mvc-Thread-9执行进度:task：0/10 异步多线程池在实际中可能会用到不同的异步接口使用不同的线程池，以下代码是自定义多个线程池给不同的接口使用的示例代码： 多线程池的配置如下，这里做了快、中、慢三个线程池： 1234567891011121314151617181920spring: task: slowMvcPool: corePoolSize: 10 maxPoolSize: 20 queueCapacity: 125 keepAliveSeconds: 60 allowCoreThreadTimeOut: true middleMvcPool: corePoolSize: 20 maxPoolSize: 40 queueCapacity: 250 keepAliveSeconds: 60 allowCoreThreadTimeOut: true fastMvcPool: corePoolSize: 40 maxPoolSize: 80 queueCapacity: 500 keepAliveSeconds: 60 allowCoreThreadTimeOut: true 通过@Bean方式将各个线程池的参数注入到Spring中： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768@Bean@ConfigurationProperties(prefix = \"spring.task.fastMvcPool\")public TaskPoolConfig fastMvcPoolConfig() &#123; return new TaskPoolConfig();&#125;@Bean@ConfigurationProperties(prefix = \"spring.task.middleMvcPool\")public TaskPoolConfig middleMvcPoolConfig() &#123; return new TaskPoolConfig();&#125;@Bean@ConfigurationProperties(prefix = \"spring.task.slowMvcPool\")public TaskPoolConfig slowMvcPoolConfig() &#123; return new TaskPoolConfig();&#125;@Beanpublic AsyncTaskExecutor slowMvcTaskExecutor(TaskPoolConfig slowMvcPoolConfig) &#123; ThreadPoolTaskExecutor threadPool = new ThreadPoolTaskExecutor(); threadPool.setCorePoolSize(slowMvcPoolConfig.getCorePoolSize()); threadPool.setMaxPoolSize(slowMvcPoolConfig.getMaxPoolSize()); threadPool.setQueueCapacity(slowMvcPoolConfig.getQueueCapacity()); threadPool.setAllowCoreThreadTimeOut(slowMvcPoolConfig.isAllowCoreThreadTimeOut()); threadPool.setWaitForTasksToCompleteOnShutdown( slowMvcPoolConfig.isWaitForTasksToCompleteOnShutdown()); threadPool.setKeepAliveSeconds(slowMvcPoolConfig.getKeepAliveSeconds()); threadPool.setThreadNamePrefix(\"Slow-Mvc-\"); threadPool.setRejectedExecutionHandler(rejectedExecutionHandler); threadPool.initialize(); return threadPool;&#125;@Beanpublic AsyncTaskExecutor middleMvcTaskExecutor(TaskPoolConfig middleMvcPoolConfig) &#123; ThreadPoolTaskExecutor threadPool = new ThreadPoolTaskExecutor(); threadPool.setCorePoolSize(middleMvcPoolConfig.getCorePoolSize()); threadPool.setMaxPoolSize(middleMvcPoolConfig.getMaxPoolSize()); threadPool.setQueueCapacity(middleMvcPoolConfig.getQueueCapacity()); threadPool.setAllowCoreThreadTimeOut(middleMvcPoolConfig.isAllowCoreThreadTimeOut()); threadPool.setWaitForTasksToCompleteOnShutdown( middleMvcPoolConfig.isWaitForTasksToCompleteOnShutdown()); threadPool.setKeepAliveSeconds(middleMvcPoolConfig.getKeepAliveSeconds()); threadPool.setThreadNamePrefix(\"Middle-Mvc-\"); threadPool.setRejectedExecutionHandler(rejectedExecutionHandler); threadPool.initialize(); return threadPool;&#125;@Beanpublic AsyncTaskExecutor fastMvcTaskExecutor(TaskPoolConfig fastMvcPoolConfig) &#123; ThreadPoolTaskExecutor threadPool = new ThreadPoolTaskExecutor(); threadPool.setCorePoolSize(fastMvcPoolConfig.getCorePoolSize()); threadPool.setMaxPoolSize(fastMvcPoolConfig.getMaxPoolSize()); threadPool.setQueueCapacity(fastMvcPoolConfig.getQueueCapacity()); threadPool.setAllowCoreThreadTimeOut(fastMvcPoolConfig.isAllowCoreThreadTimeOut()); threadPool.setWaitForTasksToCompleteOnShutdown( fastMvcPoolConfig.isWaitForTasksToCompleteOnShutdown()); threadPool.setKeepAliveSeconds(fastMvcPoolConfig.getKeepAliveSeconds()); threadPool.setThreadNamePrefix(\"Fast-Mvc-\"); threadPool.setRejectedExecutionHandler(rejectedExecutionHandler); threadPool.initialize(); return threadPool;&#125; 在Controller层中使用自定义的线程池，WebAsyncTask支持多种方式的自定义线程池的使用，可以通过下线程池在Spring中的Bean的名称，也可以直接注入线程池Bean，WebAsyncTask可以设置Timeout以及通过onTimeout方法在超时时响应内容，在使用时最好设置，如不设置如果接口超时会抛出AsyncRequestTimeoutException异常该异常比较难处理： 1234567891011121314151617181920212223242526272829303132333435@GetMapping(\"/slowAsyncTask\")public WebAsyncTask slowAsyncTask(HttpServletResponse response, AsyncTaskExecutor slowMvcTaskExecutor) &#123; logger.info(Thread.currentThread().getName() + \" 进入helloController方法\"); Callable&lt;Map&lt;String, Object&gt;&gt; callable = taskService::execute; WebAsyncTask asyncTask = new WebAsyncTask( ASYNC_REQUEST_TIME_OUT, slowMvcTaskExecutor, callable); return asyncTask;&#125;@GetMapping(\"/middleAsyncTask\")public WebAsyncTask middleAsyncTask(HttpServletResponse response, AsyncTaskExecutor middleMvcTaskExecutor) &#123; logger.info(Thread.currentThread().getName() + \" 进入helloController方法\"); Callable&lt;Map&lt;String, Object&gt;&gt; callable = taskService::execute; WebAsyncTask asyncTask = new WebAsyncTask( ASYNC_REQUEST_TIME_OUT, middleMvcTaskExecutor, callable); return asyncTask;&#125;@GetMapping(\"/fastAsyncTask\")public WebAsyncTask fastAsyncTask(HttpServletResponse response, AsyncTaskExecutor fastMvcTaskExecutor) &#123; logger.info(Thread.currentThread().getName() + \" 进入helloController方法\"); Callable&lt;Map&lt;String, Object&gt;&gt; callable = taskService::execute; WebAsyncTask asyncTask = new WebAsyncTask( ASYNC_REQUEST_TIME_OUT, fastMvcTaskExecutor, callable); return asyncTask;&#125;@GetMapping(\"/fastAsyncTask\")public WebAsyncTask fastAsyncTask(HttpServletResponse response) &#123; logger.info(Thread.currentThread().getName() + \" 进入helloController方法\"); Callable&lt;Map&lt;String, Object&gt;&gt; callable = taskService::execute; WebAsyncTask asyncTask = new WebAsyncTask( ASYNC_REQUEST_TIME_OUT, \"fastMvcTaskExecutor\", callable); return asyncTask;&#125; Servlet3非阻塞IOServlet3.1以后增加了非阻塞IO实现，需要Tomcat8.x以上支持。 非阻塞 IO 仅对在 Servlet 中的异步处理请求有效，否则当调用 ServletInputStream.setReadListener或ServletOutputStream.setWriteListener方法时将抛出IllegalStateException。Servlet3的非阻塞IO是对Servlet3异步的增强。Servlet3的非阻塞是利用java.util.EventListener的事件驱动机制来实现的。 Servlet3.1的非阻塞IO从下面图中可以看出是面对InputStream 和 OutPutStream流的，这里的非阻塞IO跟我们常说的JDK NIO不是一个概念，Servlet3.1的非阻塞是同jdk的事件驱动机制来实现。","tags":[{"name":"Spring，Servlet3.x","slug":"Spring，Servlet3-x","permalink":"https://yaoyinglong.github.io/tags/Spring，Servlet3-x/"}],"categories":[{"name":"框架","slug":"框架","permalink":"https://yaoyinglong.github.io/categories/框架/"},{"name":"Spring","slug":"框架/Spring","permalink":"https://yaoyinglong.github.io/categories/框架/Spring/"}]},{"title":"Tomcat工作原理","date":"2018-08-01T16:00:00.000Z","path":"Blog/框架/Tomcat工作原理/","text":"Tomcat 的总体结构： Connector 和 Container 是Tomcat 两个核心组件。Connector 主要负责对外交流 ，Container 主要处理 Connector 接受的请求，主要是处理内部事务 。Service 只是在 Connector 和 Container 外面多包一层，把它们组装在一起，向外面提供服务，一个 Service 可以设置多个 Connector，但是只能有一个 Container 容器。 在使用tomcat时，经常会遇到连接数、线程数之类的配置问题 ，在此之前必须先了解Tomcat的连接器Connector。 Connector的主要功能是接收客户端发送的TCP连接请求，创建Request和Response对象用于和请求端交换数据；然后产生一个线程来处理这个请求并把产生的 Request 和 Response 对象传给处理这个请求的线程，处理这个请求的线程就是 Container 组件要做的事了。 可以说，Servlet容器处理请求，是需要Connector进行调度和控制的，Connector是Tomcat处理请求的主干，因此Connector的配置和使用对Tomcat的性能有着重要的影响 。 Connector在处理HTTP请求时，会使用不同的protocol。 典型的protocol包括BIO、NIO和APR （Tomcat7中支持这3种，Tomcat8增加了对NIO2的支持，而到了Tomcat8.5和Tomcat9.0，则去掉了对BIO的支持）BIO是Blocking IO，顾名思义是阻塞的IO；NIO是Non-blocking IO，则是非阻塞的IO。而APR是Apache Portable Runtime，是Apache可移植运行库，利用本地库可以实现高可扩展性、高性能；Apr是在Tomcat上运行高并发应用的首选模式，但是需要安装apr、apr-utils、tomcat-native等包。 Connector使用哪种protocol，可以通过connector元素中的protocol属性进行指定 ，指定的protocol取值及对应的协议如下： HTTP/1.1：默认值，使用的协议与Tomcat版本有关 org.apache.coyote.http11.Http11Protocol：BIO org.apache.coyote.http11.Http11NioProtocol：NIO org.apache.coyote.http11.Http11Nio2Protocol：NIO2 org.apache.coyote.http11.Http11AprProtocol：APR Tomcat7自动选取使用BIO或APR（如果找到APR需要的本地库，则使用APR，否则使用BIO） ，Tomcat8自动选取使用NIO或APR（如果找到APR需要的本地库，则使用APR，否则使用NIO），在SpringBoot中可以通过如下方式制定Protocol： 12345678@Beanpublic EmbeddedServletContainerFactory embeddedServletContainerFactory() &#123; TomcatEmbeddedServletContainerFactory tomcatEmbeddedServletContainerFactory = new TomcatEmbeddedServletContainerFactory(); tomcatEmbeddedServletContainerFactory .setProtocol(\"org.apache.coyote.http11.Http11Nio2Protocol\"); return tomcatEmbeddedServletContainerFactory;&#125; BIO与NIO无论是BIO，还是NIO，Connector处理请求的大致流程是一样的： 当客户端向服务器发送请求时，如果客户端与OS完成三次握手建立了连接，则OS将该连接放入accept队列，Connector在accept队列中接收连接，在连接中获取请求的数据生成request；调用servlet容器处理请求；返回response。 在BIO实现的Connector中，处理请求的主要实体是JIoEndpoint对象。JIoEndpoint维护了Acceptor和Worker：Acceptor接收socket，然后从Worker线程池中找出空闲的线程处理socket，如果worker线程池没有空闲线程，则Acceptor将阻塞。其中Worker是Tomcat自带的线程池，如果通过Executor配置了其他线程池，原理与Worker类似。 在NIO实现的Connector中，处理请求的主要实体是NIoEndpoint对象。NIoEndpoint中除了包含Acceptor和Worker外，还是用了Poller，处理流程如下： Acceptor接收socket后，不是直接使用Worker中的线程处理请求，而是先将请求发送给了Poller，而Poller是实现NIO的关键。Acceptor向Poller发送请求通过队列实现，使用了典型的生产者-消费者模式。在Poller中，维护了一个Selector对象；当Poller从队列中取出socket后，注册到该Selector中；然后通过遍历Selector，找出其中可读的socket，并使用Worker中的线程处理相应请求。与BIO类似，Worker也可以被自定义的线程池代替。 通过上述过程可以看出，在NIoEndpoint处理请求的过程中，无论是Acceptor接收socket，还是线程处理请求，使用的仍然是阻塞方式；但在“读取socket并交给Worker中的线程”的这个过程中，使用非阻塞的NIO实现，这是NIO模式与BIO模式的最主要区别。 关键参数acceptCount、maxConnections、maxThreadsacceptCountaccept队列的长度；当accept队列中连接的个数达到acceptCount时，队列满，进来的请求一律被拒绝。默认值是100。 maxConnectionsTomcat在任意时刻接收和处理的最大连接数。当Tomcat接收的连接数达到maxConnections时，Acceptor线程不会读取accept队列中的连接；这时accept队列中的线程会一直阻塞着，直到Tomcat接收的连接数小于maxConnections。如果设置为-1，则连接数不受限制。 虽然tomcat同时可以处理的连接数目是maxConnections，但服务器中可以同时接收的连接数为maxConnections + acceptCount 默认值与连接器使用的协议有关：NIO的默认值是10000，APR/native的默认值是8192，而BIO的默认值为maxThreads（如果配置了Executor，则默认值是Executor的maxThreads）。 maxThreads请求处理线程的最大数量，Tomcat7和8默认值都是200。如果该Connector绑定了Executor，这个值会被忽略，因为该Connector将使用绑定的Executor，而不是内置的线程池来执行任务。 实测数据下面是对这几个参数的实测数据，测试的是同一个接口，接口固定sleep 10秒，最后两列是接口的平均响应时间（这里说所的同步异步是指在Controller层中接口是否使用Servlet3.0提供的异步HTTP请求）： acceptCount maxConnections maxThreads 并发 同时处理线程数 同步结果 异步结果 1 9 1 10 1 55263 11130 1 9 2 10 2 30044 11611 1 9 3 10 3 22329 11207 1 9 4 10 4 18027 11303 1 9 5 10 5 15412 11111 9 1 1 10 1线程1请求 55087 55324 9 1 2 10 2线程1请求 50261 55151 9 1 3 10 3线程1请求 55082 45471 9 1 4 10 4线程1请求 55276 55156 9 1 5 10 5线程1请求 55074 55314 9 3 1 10 同步1，异步1线程3请求 55289 22082 9 3 2 10 同步2，异步2线程3请求 30046 22266 9 3 3 10 3线程3请求 22235 22089 9 3 4 10 4线程3请求 22292 22034 9 3 5 10 5线程3请求 22249 22083 以上测试出的结果，可以很明显的看出当maxConnections设置为1时，accept队列中的线程会一直阻塞着，通过控制台也可以很明显得看出不论时同步还是异步请求，不论maxThreads设置为几个，处理请求的线程始终为一个。由此可看出tomcat中能够同时被处理的请求数是maxThreads和maxConnections中的较小者。 当正在被处理的请求数量达到maxConnections时，再过来的请求会被接受（TCP连接建立成功），但是没有被处理，被阻塞到serversocket上，接受并被阻塞的socket请求数的最大值为acceptCount；当阻塞达到acceptCount的最大数目时，在发送过来的请求会建立连接refuse，对客户端而言，返回连接被拒绝的错误。 tomcat能接受的最大请求数量为maxConnections，加上acceptCount的数量，其中maxThreads和maxConnections中的较小者是正在被处理的请求数量，acceptCount为等待被处理的请求数量，超过这两者之和的请求会被拒绝。 对数据进行了Mbean监控发现，并发请求进来时先使用maxConnections缓冲队列，当maxConnections队列满了后，再使用acceptCount队列，当acceptCount队列满了后，则多的请求全部拒绝。 该使用的Tomcat配置如下，使用Jmeter做并发测试工具，并发量为300： 1234tomcat: max-threads: 200 accept-count: 100 max-connections: 10000","tags":[{"name":"Tomcat","slug":"Tomcat","permalink":"https://yaoyinglong.github.io/tags/Tomcat/"}],"categories":[{"name":"框架","slug":"框架","permalink":"https://yaoyinglong.github.io/categories/框架/"}]},{"title":"Spring Gzip压缩","date":"2018-07-15T16:00:00.000Z","path":"Blog/框架/Spring/Spring Gzip压缩/","text":"输出Gzip压缩在SpringBoot项目中启用输出Gzip压缩，需要添加如下配置。 123456789101112server: compression: enabled: true min-response-size: 2048 mime-types: - application/json - application/x-www-form-urlencoded - application/xml - text/html - text/xml - text/plain - application/javascript 是否压缩取决于数据大小是否达到min-response-size配置的值且请求方在request header中是否添加Accept-Encoding:gzip,deflate, 一般浏览器会在请求头中默认添加该header。 若提供接口给外部服务，若有使用Nginx，可以通过Nginx反向代理转发到我们的WEB服务器时在请求头中添加Accept-Encoding:gzip,deflate。 验证GZIP是否生效 通过HttpClient的方法验证 12345678910111213141516HttpClient httpClient = new DefaultHttpClient();HttpGet get = new HttpGet(uri);ResponseHandler&lt;String&gt; responseHandler = new BasicResponseHandler();try &#123; get.setHeader(\"Accept-Encoding\", \"gzip,deflate\"); String content = httpClient.execute(get, responseHandler); System.out.println(content); // 如果gzip生效，会打印出乱码 HttpResponse response = httpClient.execute(get); long cLen = response.getEntity().getContentLength(); System.out.println(cLen); // 如果gzip生效，长度值为-1或比原始大小小很多的值&#125; catch(Exception e) &#123; // ignore ...&#125; finally &#123; httpClient.getConnectionManager().shutdown();&#125; 通过浏览器调试工具对比Network中请求的Size 输入Gzip压缩对于请求体比较大的接口，通常会采用压缩的方式进行传输。这里对Gzip踩坑进行一下总结。 对于即支持Gzip压缩调用，也支持非压缩调用的接口，通常做法是在请求头中放入一个字段来判断该字段的值来确定所走流程。通常做法可能很多人会采用标准的请求头参数Content-Encoding，在直接调用不仅过zuul的服务中是没有问题的。但是在有zuul的服务中，zuul默认会将请求头中的Content-Encoding移除，从而导致获取不到Content-Encoding该字段，从而走非Gzip的流程导致bug，在该种情况下最好使用自定义的请头代替标准的请去头。StackOverFlow参考 其次对于程序对Gzip的处理，可能对于很多接口一般都可能是使用@RequestBody将请求体中的内容直接取出来，客户端使用如下方式进行压缩，再将压缩后的内容通过StringEntity放入HttpPost的请求体中： 12345678910public static String compress(String param) throws IOException &#123; if (null == param || param.length() &lt;= 0) &#123; return param; &#125; ByteArrayOutputStream out = new ByteArrayOutputStream(); GZIPOutputStream gzip = new GZIPOutputStream(out); gzip.write(param.getBytes(\"utf-8\")); gzip.close(); return out.toString(\"ISO-8859-1\");&#125; 在服务端将通过@RequestBody获取到的请求体通过如下方式解压出来使用。 12345678910111213141516public static String unCompress(String paramGzip) throws IOException &#123; if (null == paramGzip || paramGzip.length() &lt;= 0) &#123; return paramGzip; &#125; ByteArrayOutputStream out = new ByteArrayOutputStream(); ByteArrayInputStream in = new ByteArrayInputStream(paramGzip.getBytes(\"ISO-8859-1\")); GZIPInputStream gzip = new GZIPInputStream(in); byte[] buffer = new byte[256]; int n = 0; while ((n = gzip.read(buffer)) &gt;= 0)&#123; out.write(buffer, 0, n); &#125; return out.toString(\"utf-8\");&#125; 以上方式的问题在于不通用，如果说使用Python或者其他语言来，或者说如JMeter和LoadRunner之类的工具请求，基本上百分之百会乱码导致请求失败。 优化方案，直接从HttpServletRequest中获取InputStream从而获取到字节数组。并将字节数组解压缩，最后将解压缩后的字节数组转成字符串进行处理。 123456789101112131415public static byte[] unCompressBytes(byte[] bytes) throws IOException &#123; if (null == bytes || bytes.length &lt;= 0) &#123; return bytes; &#125; ByteArrayOutputStream out = new ByteArrayOutputStream(); ByteArrayInputStream in = new ByteArrayInputStream(bytes); GZIPInputStream gzip = new GZIPInputStream(in); byte[] buffer = new byte[256]; int n = 0; while ((n = gzip.read(buffer)) &gt;= 0) &#123; out.write(buffer, 0, n); &#125; gzip.close(); return out.toByteArray();&#125; 对于Java客户端的请求，可以直接使用GzipCompressingEntity标准的请求方式来调用： 12345678HttpPost httpPost = new HttpPost(url);httpPost.setHeader(\"Content-Type\", \"application/json;charset=UTF-8\");httpPost.setHeader(\"AA-Content-Encoding\", \"gzip\");StringEntity entity = new StringEntity(param, \"UTF-8\");httpPost.setEntity(new GzipCompressingEntity(entity));HttpResponse httpResponse = httpClient.execute(httpPost); 当然也可以自己来压缩调用，通过compressByte方法将数据压缩成字节流，再将字节流直接放入到HttpPost的请求体中，中间不要做任何转码： 1234567891011121314151617181920public static byte[] compressByte(String param) throws IOException &#123; if (null == param || param.length() &lt;= 0) &#123; return new byte[0]; &#125; ByteArrayOutputStream out = new ByteArrayOutputStream(); GZIPOutputStream gzip = new GZIPOutputStream(out); gzip.write(param.getBytes(StandardCharsets.UTF_8)); gzip.close(); return out.toByteArray();&#125;HttpPost httpPost = new HttpPost(url);httpPost.setHeader(\"Content-Type\", \"application/json;charset=UTF-8\");httpPost.setHeader(\"AA-Content-Encoding\", \"gzip\");ByteArrayEntity entity = new ByteArrayEntity(bytes);httpPost.setEntity(new GzipCompressingEntity(entity));HttpResponse httpResponse = httpClient.execute(httpPost); 对于Python的调用也很简单： 12345678headers = &#123; \"Content-Type\": \"application/json;charset=utf-8\", \"AA-Content-Encoding\": \"gzip\"&#125;dataGzip = gzip.compress(json.dumps(data).encode(\"utf-8\"))response = requests.post(url=url, headers=headers, data=dataGzip, params=params)","tags":[{"name":"Gzip，Spring","slug":"Gzip，Spring","permalink":"https://yaoyinglong.github.io/tags/Gzip，Spring/"}],"categories":[{"name":"框架","slug":"框架","permalink":"https://yaoyinglong.github.io/categories/框架/"},{"name":"Spring","slug":"框架/Spring","permalink":"https://yaoyinglong.github.io/categories/框架/Spring/"}]},{"title":"MySQL常用SQL总结","date":"2018-06-12T16:00:00.000Z","path":"Blog/DB/MySQL常用SQL总结/","text":"查看索引1show index from compliance_page_info; 创建联合唯一性索引1234567alter table compliance_page_info add unique index unique_index_name(uuid, type);alter table compliance_page_info add unique unique_index_name(uuid, type);alter table compliance_page_info add unique key unique_index_name(uuid, type);alter table compliance_page_info add primary key unique_index_name(uuid, type);create unique index unique_index_name on compliance_page_info(uuid, type);# 创建唯一性索引时表中存在重复记录，删除重复记录后创建唯一性索引alter ignore table compliance_page_info add unique unique_index_name(uuid, type); 创建全文索引1alter table compliance_page_info add fulltext(uuid); 删除索引123alter table compliance_page_info drop index table_unique_index;drop index unique_index_name on compliance_page_info;alter table compliance_page_info drop primary key; 当记录不存在时Insert，存在时update1234insert into compliance_page_info (uuid, total_page, total_count, type) values ('d60bc0d38b7a36fba07b2b9e4177d9cf', 1, 10, 'OVERVIEW-JUDGEMENT')ON DUPLICATE KEY UPDATE total_page = values(total_page), total_count = values(total_count);# 使用replace，记录存在先删除再插入（故受影响的列为2条），不存在直接插入replace into compliance_page_info (uuid, total_page, total_count, type) values ('d60bc0d38b7a36fba07b2b9e4177d9cf', 1, 10, 'OVERVIEW-JUDGEMENT') 查询数据库表结构1234select column_name, column_type, is_nullable, column_key, column_default, extra, column_commentfrom information_schema.columnswhere table_schema = 'ent_compliance' #表所在数据库 and table_name = 'third_page_info' ; #你要查的表 删除重复数据1234# 必须多嵌套一层select否则MySQL报错delete from update_log where id not in ( select * from (select min(id) from update_log group by uuid, did_or_page, type) b); 正则&amp;字符长度查询1delete from update_log where LENGTH(did_or_page) &gt; 30 or did_or_page REGEXP '[0-9]+'; 将一个表中的字段更新到另一表中1234update asset_certificate a, base_static_data b set a.certificate_type = b.code_value, a.certificate_authority = b.extend_valuewhere a.certificate_type_code = b.code_name and a.certificate_type in ('null', '-', '') or a.certificate_type is null;","tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://yaoyinglong.github.io/tags/MySQL/"}],"categories":[{"name":"DB","slug":"DB","permalink":"https://yaoyinglong.github.io/categories/DB/"}]},{"title":"Linux常用命令","date":"2018-05-25T16:00:00.000Z","path":"Blog/Linux/Linux常用命令/","text":"source /etc/profile： 使配置文件生效ps -aux | grep java：查看进程jstat -gcutil 30996 3000 ：每3秒显示一次进程号为30996的Java进程GC情况 压缩&amp;解压tar -cvf jpg.tar *.jpg：将文件打成tar包tar -czf jpg.tar.gz *.jpg： 将文件打成tar包，并将其压缩成gziptar -cjf jpg.tar.bz2 *.jpg：将文件打成tar包，并将其压缩成bzip2tar -cZf jpg.tar.Z *.jpg：将文件打成tar包，并将其压缩成compressrar a jpg.rar *.jpg：rar格式的压缩zip jpg.zip *.jpg：zip格式的压缩 tar zxvf target.gz -C /opt：将压缩包解压到指定目录tar -xvf file.tar：解压tar包tar -xzvf file.tar.gz：解压tar.gz包tar -xjvf file.tar.bz2：解压tar.bz2包tar -xzvf file.tar.Z：解压tar.Z包unrar e file.rar：解压rar包unzip file.zip：解压zip包","tags":[{"name":"Linux","slug":"Linux","permalink":"https://yaoyinglong.github.io/tags/Linux/"}],"categories":[{"name":"Linux","slug":"Linux","permalink":"https://yaoyinglong.github.io/categories/Linux/"}]},{"title":"lambda常用总结","date":"2018-05-19T16:00:00.000Z","path":"Blog/Java/基础/lambda常用总结/","text":"排序在用到Stream做排序时，如果数据存在null值就会抛出空指针异常，可能最理想的方式排除空值的内容进行排序，最后将空值的内容排在最后或者最前面。 下面的示例是使用对象的时间进行排序，如果时间为空则将其排在列表最后面： 1234List&lt;Change&gt; changes = changeList.stream() .sorted(Comparator.comparing( Change::getDate, Comparator.nullsFirst(Date::compareTo)).reversed()) .collect(Collectors.toList()); 去重在很多时候会用到去重，对于实体列表的去重，在没有重写equals和hashCode方法时，要通过Lambda去重比较麻烦和不友好，因为Stream的distinct()方法不支持形如distinct(Change::getDid)这种形式的去重，我自己总结论一个稍微好一点的方式： 1234567List&lt;Change&gt; uniqueList = opList .stream() .collect(Collectors.groupingBy(Change::getDid)) .values() .stream() .flatMap(list -&gt; list.stream().limit(1)) .collect(Collectors.toList());","tags":[{"name":"lambda","slug":"lambda","permalink":"https://yaoyinglong.github.io/tags/lambda/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"基础","slug":"Java/基础","permalink":"https://yaoyinglong.github.io/categories/Java/基础/"}]},{"title":"JMeter日常总结","date":"2018-04-11T16:00:00.000Z","path":"Blog/Test/JMeter日常总结/","text":"断言在对接口进行测试时，通常需要对接口调用结果进行断言，以确定接口调用是否达到预期，同时也可以在结果数中看到接口是否调用成功。响应断言和jp@gc - JSON Path Assertion是比较简单和常用的两个断言器。 在HTTP请求下添加断言 -&gt; 响应断言，可以通过不同的模式匹配规则进行匹配断言。 在HTTP请求下添加断言 -&gt; jp@gc - JSON Path Assertion。目前看来该断言器只能断言其中一个字段。 一般来说以上两种断言器已经基本够用了，如果遇到比较复杂的可以使用BeanShell断言来通过脚本进行断言。 变量提取使用通常在测试时接口需要进行鉴权，这是通过调用登录接口获取到token_id然后在调用具体接口时将token_id作为参数或者放在header中传入。这里就需要将token_id从鉴权接口的响应中提取出来，然后再使用时传入。 对于鉴权接口在JMeter中可以通过在测试计划中添加setUp Thread Group，并将线程数和循环次数设置成1，并在该线程组中添加鉴权接口的HTTP请求。可以添加常规的断言和察看结果树。也可以在线程组中添加逻辑控制器 -&gt; 仅一次控制器将鉴权接口相关类容添加至该逻辑控制器下。 目前我用到的变量提取有JSON Extractor和正则表达式提取器两种。当然还有其他的提取器，目前这两种提取器基本够用了。 JSON Extractor其实是通过XPath从JSON串中取出目标值。 正则表达式提取器当然是通过正则表达式的方式从字符串中提取目标值。 虽然将变量从响应结果中提取出来了，但是并不能直接使用。可以通过BeanShell PostProcessor将参数设置为全局变量，也可以将其存储到本地文件中使用时通过CSV Data Set Config来读取并使用。 设置成全局变量相对简单，只需要在BeanShell PostProcessor中配置${__setProperty(token_id, ${token_id},)}脚本即可。这里的print会将提取到的变量打印到cmd窗口中。在使用变量时通过${__property(token_id)}进行获取。 将变量存储到本地文件中，也是通过BeanShell PostProcessor脚本实现的，只是相对于设置全局变量复杂得多。 1234567891011121314151617181920212223242526272829import java.util.regex.Matcher; import java.util.regex.Pattern; //JMeter的内置API：prev.getResponseData()获取请求的响应内容 byte[] responseData = prev.getResponseData();//定义正则表达式需要匹配的模式提取相关变量Pattern pattern = Pattern.compile(\"\\\"token_id\\\":\\\"(.+?)\\\"\"); Matcher result = pattern.matcher(new String(responseData)); //boolean java.util.regex.Matcher.find()只要找到符合条件的就返回trueif(result.find())&#123; String tokenId += result.group(1)+\"\\r\\n\"; //导出的csv存放位置 String filePath = \"D:/test/token.txt\"; BufferedOutputStream bos = null; FileOutputStream fos = null; try &#123; File file = new File(filePath); fos = new FileOutputStream(file); bos = new BufferedOutputStream(fos); bos.write(tokenId.getBytes()); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; if (bos != null) &#123; bos.close(); &#125; if (fos != null) &#123; fos.close(); &#125; &#125;&#125; 使用时通过CSV Data Set Config来读取到配置中。 JMeter压测的坑在JMeter中通过线程组的方式进行并发压测，但是实际测试中发现，JMeter其实实际上是一个同步的方式去发送请求的，当我们同时压测几个接口时，通过聚合报告很明显的看出JMeter会等到前一个接口结束后才会请求下一个接口。 在单个接口做并发测试时，当我们的并发设置为150时，JMeter的并发请求数确实是150，但是JMeter会等到其中某个请求结束然后再补充一个请求，通俗的将若你的接口延时1分钟，JMeter在这1分钟内只会发150个请求，当其中有请求结束再往里面补充一致维持150个请求。并不能完全模拟真实场景下的高并发。 通过MBean监控Tomcat的collectionCount参数也可以明显的看出这一点： JMeter BindExecption：Address already in use：connect在Windows10环境下，通过JMeter对接口进行压测时，在100的并发下聚合报告中会出现百分之三点几的错误率，在150的并发下出现了百分之三十几的错误率，当然在不同的环境和接口响应速率下这个错误率可能会不一样。 具体原因是由于端口被占用，Windows提供给TCP/IP连接的端口为1024-5000，并且要四分钟来循环回收他们。就导致我们在短时间内跑大量的请求时将端口占满了。 解决方案： cmd中，用regedit打开注册表 在 HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Services\\Tcpip\\Parameters下 右击parameters，添加一个新的DWORD，名字为MaxUserPort 然后双击MaxUserPort，输入数值数据为65534，基数选择十进制。 然后重启电脑！重启电脑！重启电脑！ Gzip压缩请求对于Gzip压缩请求，通常做法是添加JSR223 PreProcessor预处理程序，将请求内容进行压缩。 123456789101112import org.apache.commons.io.IOUtils;import java.util.zip.GZIPOutputStream;String bodyString = sampler.getArguments().getArgument(0).getValue();byte [] requestBody = bodyString.getBytes(\"utf-8\");ByteArrayOutputStream out = new ByteArrayOutputStream(requestBody.length);GZIPOutputStream gzip = new GZIPOutputStream(out);gzip.write(requestBody);gzip.close();sampler.getArguments().getArgument(0).setValue(out.toString(0)); 在上述代码中的getBytes(&quot;utf-8&quot;)最好加上utf-8的编码格式，否正日志可能乱码。 值得注意的是，在HTTP Request中的Content encoding中的编码方式一定不要填，否正很有可能导致乱码，从而导致请求失败。","tags":[{"name":"Test，JMeter","slug":"Test，JMeter","permalink":"https://yaoyinglong.github.io/tags/Test，JMeter/"}],"categories":[{"name":"Test","slug":"Test","permalink":"https://yaoyinglong.github.io/categories/Test/"}]},{"title":"LoadRunner日常总结","date":"2018-04-11T16:00:00.000Z","path":"Blog/Test/LoadRunner日常总结/","text":"HTTPS请求LoadRunner对HTTPS接口进行测试时，最好加上web_set_sockets_option(&quot;SSL_VERSION&quot;,&quot;TLS&quot;)。 LoadRunner在对HTTPS接口进行请求时，可能出现Error -27778: SSL protocol error when attempting to connect with host &quot;XXX&quot; [MsgId: MERR-27778]错误。 设置Vuser -&gt; Run-time Setting找到Internet Protocol -&gt; Preferences -&gt; Advanced勾选winlnet replay instead of sockets(windows only)选项。 日志中文打印通常在请求时想看到请求参数、返回结果等数据，可以在Vuser -&gt; run-time setting -&gt; general -&gt; log勾选extended log且勾选其下的三个选项。但是这种方式不能解决中文乱码问题。 可以将中文数据通过web_reg_save_param单独提取出来lr_convert_string_encoding转码后通过lr_output_message或lr_log_message打印： 1234web_reg_save_param(\"result\", \"LB=message\\\":\\\"\", \"RB=\\\"\", LAST);// web_custom_request请求lr_convert_string_encoding(lr_eval_string(\"&#123;result&#125;\"), \"utf-8\", NULL, \"msg\");lr_output_message(\"message--------%s\",lr_eval_string(\"&#123;msg&#125;\")); 中文参数乱码通常在通过LoadRunner请求接口时，若请求参数中存在中文参数，虽然在Replay Log中打印的内容可能并没有乱码，但是请求到服务器可能就乱码了，从而导致接口请求失败。 为了解决中文参数导致的中文乱码，可以将中文参数提取出来通过lr_convert_string_encoding进行转码后使用。首先通过通过lr_save_string将中文参数参数化，也可以到Parameter List进行设置。然后将参数转成UTF-8，最后将参数转成URL编码。 123456lr_save_string(\"奚姝\",\"name\");lr_convert_string_encoding(lr_eval_string(\"&#123;name&#125;\"), LR_ENC_SYSTEM_LOCALE, LR_ENC_UTF8, \"encode_name\");lr_save_string(lr_eval_string(\"&#123;encode_name&#125;\"),\"name\");web_convert_param(\"name\", \"SourceEncoding=PLAIN\", \"TargetEncoding=URL\", LAST);lr_log_message(\"参数化结果name：%s\", lr_eval_string(\"&#123;name&#125;\")); Web请求LR可以通过web_custom_request函数发送POST或者GET请求。对于普通POST请求，未将请求参数放到RequestBody中的，可以将参数在Body中通过&amp;符号进行拼接。 12345web_custom_request(\"web_custom_request\",\"URL=&#123;url&#125;\",\"Method=POST\", \"Resource=0\",\"RecContentType=Application/json\",\"Referer=\",\"Mode=HTML\", \"EncType=application/x-www-form-urlencoded;charset=UTF-8\", //\"EncType=application/json;charset=UTF-8\", \"Body=name=&#123;name&#125;&amp;phone=&#123;phone&#125;\",LAST); 对于请求参数放到RequestBody中的，可以直接将请求参数转成字符串放到Body中。或者放到RAW_BODY_START和RAW_BODY_END之间，其中200指代参数长度。 123456789web_custom_request(\"web_custom_request\",\"URL=&#123;url&#125;\",\"Method=POST\",\"Resource=0\", \"RecContentType=application/json\",\"Referer=\",\"Mode=HTTP\", \"EncType=application/json;charset=UTF-8\", //RAW_BODY_START, //\"&#123;\\\"id\\\":\\\"&#123;id&#125;\\\",\\\"name\\\":\\\"&#123;name&#125;\\\",\\\"mobile\\\":\\\"&#123;mobile&#125;\\\"&#125;\", //200, //RAW_BODY_END, \"Body=&#123;\\\"id\\\":\\\"&#123;id&#125;\\\",\\\"name\\\":\\\"&#123;name&#125;\\\",\\\"mobile\\\":\\\"&#123;mobile&#125;\\\"&#125;\", LAST); 对于响应结果的提取通过web_reg_save_param(&quot;code&quot;,&quot;LB=response_code\\&quot;:\\&quot;&quot;,&quot;RB=\\&quot;&quot;,LAST);提取出来，用来进行事务成功与否判断。 12345678910111213lr_start_transaction (\"接口A\");web_reg_save_param(\"code\",\"LB=response_code\\\":\\\"\",\"RB=\\\",\\\"\",LAST);web_custom_request(\"web_custom_request\",\"URL=&#123;url&#125;\",\"Method=POST\",\"Resource=0\", \"RecContentType=application/json\",\"Referer=\",\"Mode=HTTP\", \"EncType=application/json;charset=UTF-8\", \"Body=&#123;\\\"id\\\":\\\"&#123;id&#125;\\\",\\\"name\\\":\\\"&#123;name&#125;\\\"&#125;\",LAST);if (strcmp(lr_eval_string(\"&#123;coke&#125;\"), \"00\") == 0)&#123; lr_end_transaction(\"接口A\", LR_PASS);&#125;else&#123; lr_end_transaction(\"接口A\", LR_FAIL);&#125;","tags":[{"name":"Test，LoadRunner","slug":"Test，LoadRunner","permalink":"https://yaoyinglong.github.io/tags/Test，LoadRunner/"}],"categories":[{"name":"Test","slug":"Test","permalink":"https://yaoyinglong.github.io/categories/Test/"}]},{"title":"类加载器","date":"2018-03-19T16:00:00.000Z","path":"Blog/Java/VM/类加载器/","text":"把类加载阶段中通过类的全限定名来获取描述此类的二进制字节流的动作放到Java虚拟机外部去实现，以便让程序自己决定如何去获取所需的类，实现该动作的代码模块称为类加载器。 类加载器是Java技术体系的重要基石，是Java语言的一项创新，也是Java语言流行的重要原因之一，最初是为了满足Java Applet需求而开发的，但目前Java Applet基本上已经死掉，但类加载器却在类层次划分、OSGi、热部署、代码加密等领域大放异彩。 类与类加载器虽然类加载器只用于实现类的加载动作，但在Java程序中的作用远远不限于类加载阶段。 任意一个类都需要由加载它的类加载器和该类本身一同确立其在Java虚拟机中的唯一性，每个类加载器都有一个独立的类名称空间。 比较两个类是否相等，只有两个类是由同一个类加载器加载的前提下才有意义，即使两个类源于同一个Class文件，被同一个虚拟机加载，若加载它们的类加载器不同，这两个类就一定不相等，包括代表类的Class对象的equals()方法、isAssignableFrom()方法、isInstance()方法的返回结果、instanceof关键字做对象所属关系判定等情况。 双亲委派模型从Java虚拟机的角度讲，只存在两种不同的类加载器： 启动类加载器Bootstrap ClassLoader，该类加载器使用C++语言实现，是虚拟机自身的一部分 所有的其他的类加载器，这些类加载器都由Java语言实现，独立于虚拟机外部，其全都继承自抽象类java.lang.ClassLoader 类加载器还可以划分得跟细致一点，一共有三种系统提供的类加载器： 启动类加载器Bootstrap ClassLoader，负责将&lt;JAVA_HOME&gt;\\lib目录中或被-Xbootclasspath参数所指定的路径中的，且是虚拟机识别仅按照文件名识别的类库加载到虚拟机内存中。无法被Java程序直接引用，自定类加载器时，若需把加载请求委派给引导类加载器，直接用null代替。 扩展类加载器Extension ClassLoader由sun.misc.Launcher$ExtClassLoader实现，负责加载&lt;Java_Home&gt;/lib/ext或被java.ext.dir系统变量所指定路径中的所有类库，开发者可直接使用扩展类加载器。 应用程序类加载器Application ClassLoader由sun.misc.Launcher$AppClassLoader实现。该类加载器是ClassLoader中的getSystemClassLoader()方法的返回值，一般称为系统类加载器，负责加载用户类路径ClassPath上所指定的类库，开发者可直接使用这个类加载器，若应用程序中未自定义自己的类加载器，一般情况作为程序中默认的类加载器。 应用程序都是由这3种类加载器互相配合进行加载的，若有必要可加入自定义类加载器。如下图所示，类加载器之间的这种层次关系，称为类加载器的双亲委派模型。 双亲委派模型要求除顶层启动类加载器外，其余类加载器都应当有自己的父类加载器。这里的父子关系一般不会以继承关系来实现，而是使用组合关系来复用父类加载器的代码。并不是强制性的约束模型，是设计者推荐的一种类加载实现方式。 若类加载器收到类加载请求，首先不会自己尝试加载该类，而是把该请求委派给父类加载器去完成，每个层次的类加载器都是如此。所有的类加载请求最终都应该传送到顶层的启动类加载器中，只有父类加载器反馈自己无法完成该加载请求时，即其搜索范围中没找到所需的类，子加载器才会尝试自己加载。 双亲委派模型可以使Java类随其类加载器一起具备一种带有优先级关系的层次关系。如java.lang.Object无论哪个类加载器加载，最终都会委派给处于模型顶端的启动类加载器进行加载，因此Object在各种类加载器环境中都是同一个类。 双亲委派模型实现代码集中在java.lang.ClassLoader的loadClass()方法中，实现简单，其对于保证Java程序稳定运作很重要。 破坏双亲委派模型第一次破坏双亲委派模型是在JDK1.2之后引入的，而类加载器和抽象类java.lang.ClassLoader则在JDK1.0已经存在，为了向前兼容，JDK1.2之后的java.lang.ClassLoader添加了一个protected方法findClass() 在此之前，用户继承java.lang.ClassLoader的唯一目的就是为了重写loadClass()方法，虚拟机在进行类加载时会调用加载器的私有方法loadClassInternal()，该方法仅仅去调用自己的loadClass()方法。 JDK1.2之后不提倡覆盖loadClass()方法，提倡将类加载逻辑写到findClass()中，在loadClass()中若父类加载失败，再调用findClass()中自己的逻辑完成加载。这样即可保证新写的类加载器符合双亲委派规则。 第二次破坏双亲委派模型对于越基础的类由越上层的加载器进行加载，从而很好的解决了各个类加载器的基础类的统一问题，但有一个缺陷，双亲委派模型并不能解决基础类又需要回调用户代码的情况。 如JNDI服务现已经是Java标准服务，其代码由启动类加载器加载，但JNDI的目的是对资源进行集中管理和查找，需要调用独立厂商实现并部署在应用程序中ClassPath下JNDI接口提供者的代码。 为了解决该问题，引入了一个不太优雅的设计：线程上下文类加载器（Thread Context ClassLoader）。 该类加载器可通过java.lang.Thread类的setContextClassLoader()方法进行设置线程上下文类加载器，若创建线程时未设置，将会从父线程中继承一个，若应用程序全局范围内都未设置线程上下文类加载器，则线程上下文类加载器默认为应用程序类加载器。 JNDI服务使用线程上下文类加载器去加载所需的JNDI接口提供者的代码，其实就是通过父类加载器请求子类加载器去完成类加载。该方式打通了双亲委派模型的层次结构来逆向使用类加载器，违背了双亲委派模型一般原则。 Java中所有涉及SPI的加载基本都采用此种方式，如JNDI、JDBC、JCE、JAXB、JBI。 第三次破坏由于用户对程序动态性（代码热替换、模块热部署）的追求，目前OSGi是业界事实上的模块化标准，OSGi实现模块化热部署的关键在于其自定义的类加载器机制的实现，每个模块（OSGi称为Bundle）都有一个自己的类加载器，更换模块时连同类加载器一起替换以实现代码热替换。 OSGi环境下，类加载器不再是双亲委派模型中的树状结构，而进一步发展成了网状结构。OSGi类搜索顺序如下： 将java.*开头的类委派给父类加载器加载 否则，将委派列表名单中的类委派给父类加载器加载 否则，将Import列表中的类委派给Export类的Bundle的类加载器加载 否则，查找当前Bundle的ClassPath，使用自己的类加载器加载 否则，查找类是否在自己的Fragment Bundle中，在，则委派给Fragment Bundle的类加载器加载 否则，查找Dynamic Import列表的Bundle，委派给对应Bundle的类加载器加载 否则，类查找失败 查找顺序中，只有第一二两条符合双亲委派规则，其余都是在平级的类加载器中进行。","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"类加载过程","date":"2018-03-15T16:00:00.000Z","path":"Blog/Java/VM/类加载过程/","text":"加载加载阶段虚拟机要完成3件事：通过类的全限定名来获取定义此类得二进制字节流；将字节流所代表的静态存储结构转化为方法区的运行时数据；在内存中生成一个代表该类的java.lang.Class对象，作为方法区这个类的各种数据访问入口； 虚拟机没有明确规定二进制字节流要从哪里获取，怎样获取，相对于类加载过程的其他阶段，一个非数组类加载阶段中获取类二进制字节流的动作是开发人员可控性最强的，加载阶段既可以使用系统提供的引导类加载器来完成，也可以由自定义的类加载器来控制字节流的获取方式。一些典型的使用场景如下： 从ZIP包中读取，JAR、EAR、WAR格式的基础 从网络中获取，例：Applet 动态代理，java.lang.reflect.Proxy 由其他文件生成，例：由JSP生成对应的Class类 从数据库中读取，例：中间件服务器可选择把程序安装到数据库中来完成在集群间的发布 但数组类有所不同，数组类本身不通过类加载器创建，而是由虚拟机直接创建，但数组类与类加载器任然关系很密切，数组类的元素类型最终是要靠类加载器去创建。数组类的创建过程遵循以下规则： 若数组的组件类型是引用类型，则递归采用加载过程加载该组件类型，数组在加载该组件类型的类加载器的类名称空间上被标识 若数组的组件类型不是引用类型，虚拟机会将数组标记为与引导类加载器关联 数组类的可见性与其组件类型一致，若组件类型不是引用类型，数组类的可见性默认为public 虚拟机外部二进制字节流在加载阶段完成后按照虚拟机所需的格式存储在方法区，然后在内存中实例化一个java.lang.Class类的对象，但并没有明确规定是在Java堆中，对于HotSpot虚拟机而言，Class对象虽然是对象，但存储在方法区中，该对象将作为程序访问方法区中的这些类型数据的外部接口。 加载阶段与连接阶段的部分内容是交叉进行的，例如一部分字节码文件格式校验，加载阶段尚未完成，连接阶段可能就已经开始，但这些夹在加载阶段之中进行的动作任然属于连接阶段内容，两个阶段的开始时间任然保持着固定的先后顺序。 验证验证是连接阶段的第一步，目的是为了确保Class文件的字节流中包含的信息符合当前虚拟机要求，且不会危害虚拟机自身安全。 Class文件并不一定要求用Java源码编译而来，可以使用任何途径产生，甚至包括十六进制编辑器直接编写来产生Class文件，虚拟机如果不检测输入的字节流，很可能会载入有害的字节流而导致系统崩溃。 验证阶段的工作量在虚拟机的类加载子系统中占了相当大的一部分，若验证到输入的字节流不符合Class文件格式的约束，虚拟机会抛出一个java.lang.VerifyError异常或其子类异常，验证阶段大致会完成4个阶段的检验动作：文件格式验证、元数据验证、字节码验证、符号引用验证。 对虚拟机类加载机制来说，验证阶段是一个非常重要但不是一定必要的阶段，对程序运行期没有影响，若所运行的全部代码都已被反复使用和验证过，在实施阶段可以使用-XVerify:none参数来关闭大部分类验证措施，以缩短虚拟机类加载的时间。 文件格式验证验证字节流是否符合Class文件格式的规范，且能被当前版本的虚拟机处理，包括是否以魔数0xCAFEBABE开头，主次版本号是否在当前虚拟机处理范围内，检查常量池常量tag标志的是否有不被支持的常量类型，指向常量的各种索引值中是否有指向不存在常量或不符合类型的常量，CONSTANT_Utf8_info型常量中是否有不符合UTF8编码的数据，Class文件中各个部分及文件本身是否有被删除的或附加的其他信息，等等。 该阶段主要目的是保证输入的字节流能正确地解析并存储于方法区中，格式上符合描述一个Java类型信息的要求，该阶段的验证时基于二进制字节流进行的，只有通过了该阶段的验证，字节流才会进入内存的方法区进行存储，后面的3个验证阶段都是基于方法区的存储结构进行的，不会再直接操作字节流。 元数据验证该阶段对字节码描述的信息进行语义分析，包括验证类是否有父类，类的父类是否继承了不允许被继承的类，类是不是抽象类、是否实现了其父类或接口中要求实现的所有方法，类的字段、方法是否与父类产生矛盾。 该阶段的主要目的是对类的元数据信息进行语义校验，保证不存在不符合Java语言规范的元数据信息。 字节码验证字节码验证是整个验证阶段过程中最复杂的阶段，主要目的是通过数据流和控制流分析，确定程序语义是否合法且符合逻辑，在元数据验证阶段对元数据信息中的数据类型做完校验后，字节码验证阶段将对类的方法体进行校验分析，保证被校验类的方法在运行时不会做出危害虚拟机安全的事件，保证任意时刻操作数栈的数据类型与指令代码序列都能配合工作，不会出现在操作栈放置int类型的数据，使用时按long类型来加载入本地变量表；保证跳转指令不会跳转到方法体以外的字节码指令上；保证方法体中类型转换是有效的； 即使方法体通过了字节码验证，也不能明确其一定就是安全的，通过程序去校验程序逻辑是无法做到绝对准确的，不能通过程序准确地检测出程序是否能在有限时间内结束运行。 数据流验证复杂性高，为了避免过多的时间消耗在字节码验证阶段，JDK1.6之后Javac编译器和Java虚拟机中进行了优化，给方法体的Code属性的属性表中增加了一项名为StackMapTable属性，StackMapTable属性描述了方法体中所有基本块开始时本地变量表和操作栈应有的状态，在字节码验证期间，就不需要根据程序推导这些状态的合法性，只需要检查StackMapTable属性中的记录是否合法。 理论上StackMapTable属性也存在错误或被篡改的可能，在JDK1.6的HotSpot虚拟机中提供-XX:-UseSplitVerifier选项类关闭这项优化，或使用-XX:+FailOverToOldVerifier参数来要求在类型校验失败时退回到旧的类型推导方式进行校验，JDK1.7后对于主版本号大于50的Class文件，只能使用类型检查来完成数据流分析校验，不允许退回到类型推导的校验方式。 符号引用验证符号引用验证发生在虚拟机将符号引用转化为直接引用的时候，该转化动作将在连接的第三阶段——解析阶段中发生，符号引用验证可看做是对类自身以外的信息进行匹配性校验，包括符号引用中通过字符串来描述的全限定名是否能找到对应的类，在指定的类中是否存在符合方法的字段描述符以及简单名称所描述的方法和字段，符号引用中的类、字段、方法的访问权限是否可被当前类访问。 符号引用验证的目的是确保解析动作能正常执行，若无法通过符号引用验证，将抛出java.lang.IncompatibleClassChangeError异常的子类， 准备准备阶段是正式为类变量分配内存并设置类变量初始值的阶段，类变量使用的内存都在方法区中进行分配。这个时候进行内存分配的仅包括被static修饰的类变量，不包括实例变量，实例变量将会在对象实例化时随对象一起分配在堆中，且这里所说的初始值通常情况下是数据类型的零值，例如一个类变量定义为：public static int value = 123;则变量在准备阶段后的初始值为0而不是123,把value赋值为123的putstatic指令是程序被编译后，存放于类构造器&lt;clinit&gt;()方法中，把value赋值为123的动作将在初始化阶段执行。 若类字段属性表中存在ConstantValue属性，在准备阶段变量value会被初始化为ConstantValue属性所指定的值，如public static final int value = 123;编译时Javac将会为value生成ConstantValue属性，在准备阶段虚拟机会根据ConstantValue属性的设置将value赋值为123。 数据类型 零值 数据类型 零值 数据类型 零值 int 0 boolean false char ‘\\u0000’ long 0L float 0.0f reference null short (short)0 double 0.0d byte (byte)0 解析解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。 符号引用在Class文件中以CONSTANT_Class_info、CONSTANT_Fieldref_info、CONSTANT_Methodref_info等类型的常量出现，符号引用以一组符号来描述所引用的目标，符号可以是任意形式的字面量，只要使用时能无歧义定位到目标，符号引用与虚拟机实现的内存布局无关，引用目标并不一定已经加载到内存中，各种虚拟机实现的内存布局各不相同，但能接受的符号引用必须一致，因为符号引用的字面量形式明确定义在Java虚拟机规范的Class文件格式中。 直接引用可以直接指向目标的指针、相对偏移量或是能间接定位到目标的句柄。直接引用与虚拟机实现内存布局相关，如果存在直接引用，则引用的目标必定已存在内存中。 虚拟机规范中并未规定解析阶段发生的具体时间，只要求在执行anewarray、checkcast、getfield、getstatic、instanceof、invokedynamic、invokeinterface、invokespecial、invokestatic、invokevirtual、ldc、ldc_w、multianewarray、new、putstatic这16条用于操作符号引用的字节码指令之前，先对它们所使用的符号引用进行解析，虚拟机实现可以根据需求来判断是在类加载器加载时对常量池中的符号引用解析，还是等到符号引用将要被使用前才去解析。 对同一个符号引用进行多次解析，除invokedynamic指令外，虚拟机可以对第一次解析的结果进行缓存，在运行时常量池中记录直接引用，并把常量标识为已解析状态，从而避免解析动作重复进行，无论是否真正执行多次解析动作，虚拟机需要保证在同一实体中，若一个符号引用之前已经被成功解析过，则后续的引用解析请求应当一直成功，反之亦然。 而invokedynamic指令目的是用于动态语言支持，其所对应的引用称为动态调用点限定符，动态的含义是指必须等到程序实际运行到这条指令的时候，解析动作才进行，且其解析结果对于其他invokedynamic指令并不生效。其余可触发解析指令都是静态的。 类或接口的解析将从未解析过的符号引用解析为类或接口的直接引用，虚拟机完成整个解析过程需要三个步骤： 若符号引用所指向的类或接口为非数组类型，则虚拟机将会将符号引用的全限定名传递给当前类的类加载器去加载这个类或接口，加载过程中，由于元数据验证、字节码验证的需要，可能触发其他相关类的加载，如加载该类的父类或实现的接口。若加载过程出现任何异常，解析过程将失败。 若符号引用所指向的类或接口为数组类型，且数组元素类型为对象，即符号引用的描述符类似[Ljava.lang.Integer的形式，将按照上面的规则加载数组元素类型，若符号引用的描述符为[Ljava.lang.Integer，则加载元素的类型为java.lang.Integer，接着由虚拟机生成一个代表此数组维度和元素的数组对象。 若前面的步骤未出现任何异常，则符号引用所指向的类或接口在虚拟机中实际上已经成为一个有效的类或接口，在解析完成之前需要进行符号引用验证，确认当前类是否具有对符号引用所指向的类或接口的访问权限。若不具备将抛出java.lang.IllegalAccessError异常。 字段解析解析一个未被解析过的字段符号引用，将对字段表内class_index项中索引的CONSTANT_Class_info符号引用进行解析，也就是字段所属的类或接口的符号引用。若解析该类或接口符号引用的过程出现任何异常，都将导致字段符号引用解析失败。 若解析成功，虚拟机将按照以下步骤对该字段所属的类或接口进行字段搜索。若查找过程返回直接引用成功，还将对字段进行权限验证，若不具备访问权限，将抛出java.lang.IllegalAccessError异常。 若字段所属的类或接口本身包含的简单名称和字段描述符都与目标字段匹配，则返回该字段的直接引用，查找结束。 若字段所属的类或接口中实现了接口，将按照继承关系从下往上递归搜索各个接口和它的父接口，若接口中包含的简单名称和字段描述符都与目标字段匹配，则返回该字段的直接引用，查找结束。 若字段所属的类或接口非java.lang.Object，将按照继承关系从下往上递归搜索其父类，若父类中包含的简单名称和字段描述符都与目标字段匹配，则返回该字段的直接引用，查找结束。 否则查找失败，抛出java.lang.NoSuchFieldError异常 实际应用中，虚拟机编译器实现比上述规范要求更加严格，若有同名字段同时出现在字段所属的类或接口的接口和父类中，或同时出现在自己和父类的多个接口中，编译器将拒绝编译。 类方法解析类方法解析需先解析出类方法表的class_index项中索引的方法所属的类或接口的符号引用，若解析成功将按照如下步骤进行类方法搜索： 类方法和接口方法符号引用的常量类型定义是分开的，若在类方法表中发现class_index中索引的方法所属为接口，将抛出java.lang.IncompatibleClassChangeError异常。 在类方法所属的类或接口中查找是否有简单名称和描述符都与目标相匹配的方法，若有则返回该方法的直接引用，查找结束。 在类方法所属的类或接口实现的列表及它们的父类接口中递归查找是否有简单名称和描述符都与目标相匹配的方法，若存在匹配的方法则说明该类是一个抽象类，查找结束，抛出java.lang.AbstractMethodError异常。 否则，方法查找失败，抛出java.lang.NoSuchMethodError异常。 若查找过程成功返回了直接引用，将会对该方法进行权限验证，若不具备访问权限，将抛出java.lang.IllegalAccessError异常。 接口方法解析接口方法解析需先解析出接口方法表的class_index项中索引的方法所属的类或接口的符号引用，若解析成功将按照如下步骤进行类方法搜索： 若在接口方法中发现class_index中的索引的方法所属为类而非接口，将抛出java.lang.IncompatibleClassChangeError异常。 在接口方法所属的类或接口中查找是否有简单名称和描述符都与目标相匹配的方法，若有则返回该方法的直接引用，查找结束。 在接口方法所属的类或接口的父接口中递归查找，直到查找完java.lang.Object类为止，看是否有简单名称和描述符都与目标相匹配的方法，若有则返回该方法的直接引用，查找结束。 否则，方法查找失败，抛出java.lang.NoSuchMethodError异常。 接口中所有方法默认都是public，故不存在访问权限问题，故接口方法符号解析应该不会抛出java.lang.IllegalAccessError异常。 初始化初始化阶段才真正开始执行类中定义的Java程序代码或者说是字节码，除加载阶段用户应用程序能通过自定义类加载器参与外，其余动作完全由虚拟机主导和控制。 在准备阶段变量已经赋值系统要求的初始值，在初始化阶段是执行类构造器&lt;clinit&gt;()方法的过程，主观计划去初始化类变量和其他资源。 &lt;clinit&gt;()方法是由编译器自动收集类中所有变量的赋值动作和静态语句块static{}中的语句合并产生的，编译器收集顺序是由语句在源文件中出现顺序决定的，静态语句块只能访问到定义在静态语句块之前的变量，定义在其后的变量，在静态语句块可以赋值，但不能访问。 &lt;clinit&gt;()方法与实例构造器不同，它不需要显示调用父类构造器，虚拟机会保证子类&lt;clinit&gt;()方法执行前，父类&lt;clinit&gt;()方法已执行完毕。故虚拟机中第一个被执行的&lt;clinit&gt;()方法的类肯定是java.lang.Object。 由于父类的&lt;clinit&gt;()方法先执行，故父类中定义的静态语句块要优先于子类的变量赋值操作。 &lt;clinit&gt;()方法对于类或接口并非是必需的，若类中无静态语句块，也无对变量的赋值操作，编译器将不会为该类生成&lt;clinit&gt;()方法。 接口中不能使用静态语句块，但任然有变量初始化的赋值操作，故接口和类一样都会生成&lt;clinit&gt;()方法，但执行接口的&lt;clinit&gt;()方法不需要先执行父接口的&lt;clinit&gt;()方法，只有父接口中定义的变量使用时才会初始化。接口的实现类在初始化时也不会执行接口的&lt;clinit&gt;()方法。 虚拟机会保证一个类的&lt;clinit&gt;()方法在多线程环境中被正确枷锁、同步，若多个线程同时去初始化一个类，只会有一个线程去执行该类的&lt;clinit&gt;()方法，其他线程都需要阻塞等待，直到活动线程执行&lt;clinit&gt;()方法方法完毕。 组件类型：数组去掉一个维度得类型类必须与类加载器一起确定唯一性不允许被继承的类：被fianl修饰的类类的字段、方法是否与父类产生矛盾：覆盖了父类的final字段，或者出现不符合规则的方法重载类自身以外的信息：例如常量池中各种符号引用","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"类加载的时机","date":"2018-02-24T16:00:00.000Z","path":"Blog/Java/VM/类加载的时机/","text":"Class文件中描述的各种信息最终都需要加载到虚拟机中之后才能运行和使用，虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可被虚拟机直接使用的Java类型。 类型的加载、连接和初始化过程都是在程序运行期间完成的，这虽然会令类加载时稍微增加一些性能开销，但能够提供高度的灵活性，其天生的动态扩展性就是依赖运行期动态加载和动态连接。面向接口的应用程序可以等到运行时再指定其实际的实现类，用户可以通过预定义的和自定义类加载器，让一个本地应用程序可以在运行时从网络或其他地方加载一个二进制流作为程序代码的一部份，如Applet、JSP、OSGi等技术。 类加载的时机类从被加载到虚拟机内存中开始，到卸载出内存的整个生命周期为加载、验证、准备、解析、初始化、使用、卸载7个阶段,验证、准备、解析3个部分统称为连接。 加载、验证、准备、初始化、卸载这5个阶段的顺序是确定的，但解析阶段在某些情况下可以在初始阶段之后，这是为了支持运行时绑定即动态绑定。 初始化阶段虚拟机规范严格规定了有且只有5种情况必须立即对类进行初始化： 遇到new、getstatic、putstatic、invokestatic这4条字节码指令时，若类未进行初始化需先触发其初始化。 使用java.lang.reflect包的方法对类进行反射调用时，若类未进行初始化需先触发其初始化。 当初始化类时其父类未初始化，需先触发其父类初始化。 当虚拟机启动时，用户指定一个执行主类即包含main方法的类，虚拟机会先初始化该类。 若一个java.lang.invoke.MethodHandle实例最后的解析结果是REF_getStatic、REF_putStatic、REF_invokeStatic的方法句柄，且该方法句柄所对应的类未进行过初始化需先触发其初始化。 以上5种场景称为对一个类的主动引用，除此之外所有引用类的方式都不会触发初始化，称为被动引用，被动引用的几种情况： 对于静态字段，只有直接定义这股份字段的类才会被初始化，其子类来引用父类的中定义的静态字段只会触发父类的初始化而不会触发子类的初始化。 通过数组定义来引用类 常量的引用，常量在编译阶段会存入调用类的常量池种，本质上并没有直接引用到定义常量的类 接口的加载过程与类的加载过程稍微有些不同，接口中也有初始化过程，类中可以使用静态语句块static{}，但是接口中不能使用static{}语句块，但编译器任然会为接口生成&lt;clinit&gt;类构造器，用于初始化接口中定义的成员变量；接口与类的真正区别是，当类在初始化时，其父类都已经完成初始化，但接口在初始化时，并不要求其父类接口全部都完成初始化，只有在真正使用到父类接口的时候才会初始化，例如引用父类接口中定义的常量。","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"字节码指令","date":"2018-02-07T16:00:00.000Z","path":"Blog/Java/VM/字节码指令/","text":"Java虚拟机指令是由一个字节长度、代表某种特定操作含义的数字操作码Opcode以及跟随其后的零至多个代表此操作所需参数操作数Operands而构成。但由于Java虚拟机采用面向操作数栈而不是寄存器的架构，所以大多数指令只有一个操作码。 字节码指令集是一种具有鲜明特点、优劣势突出的指令集架构，由于操作码长度为一个字节即0~255，故指令的操作码总数不超过256条； Class文件格式放弃了编译后代码的操作数长度对齐，虚拟机处理超过一个字节的数据时，需在运行时从字节中重建具体数据的结构，如果将16位长度的无符号整数使用两个无符号字节byte1、byte1存储，其值为(byte1 &lt;&lt; 8) | byte2。放弃操作数长度对齐，可以省略很多填充和间隔符号，但在某种程度上会导致解释执行字节码时损失一些性能。 不考虑异常处理的情况下，Java虚拟机的解释器可使用一下伪代码为最基本的执行模型来理解：123456do &#123; 自动计算PC寄存器的值加1; 根据PC寄存器指示位置，从字节码流中取出操作码; if ( 字节码存在操作数 ) 从字节码流中取出操作数; 执行操作码所定义的操作;&#125; where ( 字节码流长度 &gt; 0 ); 字节码与数据类型Java虚拟机指令集中，大多数指令都包含其基本操作所对应的数据类型信息。大部分与数据类型相关的字节码指令，它们的操作码助记符中有特殊字符表示服务的数据类型：i代表int、l代表long、s代表short、b代表byte、c代表char、f代表float、d代表double、a代表reference；但也有指令助记符种没有指名操作类型字母，如arraylength操作数为数组类型的对象、goto无条件跳转指令。 虚拟机指令集对于特定操作只提供了有限的类型相关指令去支持，指令集将会被设计成非完全独立的，即并非每种数据类型和每一种操作都有对应的指令。有一些单独的指令可以在必要的时候用来将一些不支撑的数据类型转换为可被支撑的类型。 大部分指令都没有支撑整数类型byte、char、short甚至没有任何指令支撑boolean类型。编译器会在编译期或运行期将byte和short类型的数据带符号扩展为相应的int类型数据，在c处理boolean、byte、short、char类型的数组时，也会转换为使用对应的int类型字节码指令来处理。 加载和存储指令加载和存储指令用于将数据在栈帧中的局部变量表和操作数栈之间来回传输，存储数据的操作数栈和局部变量表主要由加载和存储指令进行操作，少数访问对象字段或数组元素指令也会向操作数栈传输数据。 将局部变量加载到操作栈：iload、iload_&lt;n&gt;、lload、lload_&lt;n&gt;、fload、fload_&lt;n&gt;、dload、dload_&lt;n&gt;、aload、aload_&lt;n&gt; 将数据从操作数栈存储到局部变量表：istore、istore_&lt;n&gt;、lstore、lstore_&lt;n&gt;、fstore、fstore_&lt;n&gt;、dstore、dstore_&lt;n&gt;、astore、astore_&lt;n&gt; 将常量加载到操作数栈：bipush、sipush、ldc、ldc_w、ldc2_w、aconst_null、iconst_m1、iconst_&lt;i&gt;、lconst_&lt;l&gt;、fconst_&lt;f&gt;、dconst_&lt;d&gt; 扩充局部变量表访问索引：wide。 带有尖括号结尾的指令，指令助记符代表一组指令。 运算指令运算指令用于对两个操作数栈上的值进行某种特定运算，并把结果重新存入操作数栈顶。大体上算数指令分整型数据运算指令和浮点数据运算指令，整数与浮点数的算术指令在溢出和被零除时有各自不同的行为表现。 加法指令：iadd、ladd、fadd、dadd 减法指令：isub、lsub、fsub、dsub 乘法指令：imul、lmul、fmul、dmul 除法指令：idiv、ldiv、fdiv、ddiv 求余指令：irem、lrem、frem、drem 取反指令：ineg、lneg、fneg、dneg 位移指令：ishl、ishr、iushr、lshl、lshr、lushr 按位或指令：ior、lor 按位与指令：iand、land 按位异或指令：ixor、lxor 局部变量自增指令：iinc 比较指令：dcmpg、dcmpl、fcmpg、fcmpl、lcmp 数据运算可能会导致溢出，虚拟机规范没有明确定义整数数据溢出的具体运算结果，仅规定了在处理整数数据时，只有除法指令和求余指令中出现除数为零时会抛出ArithmeticException异常，其余任何整型数运算场景都不应该抛出运行时异常。 Java虚拟机处理浮点数时必须完全支持IEEE 754中定义的非正规浮点数值和逐级下溢的运算规则，所有运算结果都必须舍入到适当精度，非精确的结果必须舍入为可被表示的最接近的精确值，若两种可表示形式与该值一样接近，将优先选择最低有效位为零的。将浮点数转换成整数时，使用的向零舍入模式，舍入结果会导致数字被截断，小数部分有效字节都会被丢弃掉。Java虚拟机在处理浮点数运算时不会抛出任何运行时异常。 对long类型的数值进行比较时，虚拟机采用带符号的比较方式，而浮点数值比较采用无符号比较方法。 类型转换指令类型转换指令能将两种不同数值类型进行相互转换，一般用于实现用户代码中显示类型转换操作，或用来处理字节码指令集中数据类型相关指令无法与数据类型一一对应的问题。 虚拟机直接支持以下数值类型的宽化类型转换，即小范围类型向大范围类型的安全转换，转换时无需显示的转换指令。 int类型到long、float、double类型 long类型到float、double类型 float类型到double类型 处理窄化类型转换时，必须显示使用转换指令来完成，转换指令包括i2b、i2c、i2s、l2i、f2i、f2l、d2i、d2l、d2f。窄化类型转换可能导致类型转换结果产生不同正负号、不同数量级、精度丢失等情况。 int或long类型窄化转换为整数类型T时，仅仅简单地丢弃除最低位N个字节以外的内容，但这也将导致转换结果与输入值有不同正负号。 将浮点值窄化转换为整数类型T时，将遵循以下转换规则： 若浮点值为NaN，转换结果为int或long类型的0 若浮点值非无穷大，浮点值使用向零舍入模式取整，若获得整数值在目标类型int或long的表示范围内，转换结果就是该值 否则，将根据该值的符号，转换为int或long所能表示的最大或最小正数 double类型到float类型的窄化转换，向最接近数舍入模式舍入得到一个可使用float类型表示的数字，若转换结果绝对值太小，返回float类型的正负零；若绝对值太大，将返回float类型的正负无穷大；double类型NoN将按规定转换为float类型的NaN值。 尽管数据类型窄化转换可能发生上限溢出、下限溢出、精度丢失等情况，但虚拟机规范中规定数值类型窄化转换指令永远不可能导致虚拟机抛出运行时异常。 操作数栈管理指令虚拟机提供了以下用于直接操作操作数栈的指令： 将操作数栈栈顶一个或两个元素出栈：pop、pop2 复制栈顶一个或两个数值并将复制值或双份复制值重新压入栈顶：dup、dup2、dup_x1、dup2_x1、dup_x2、dup2_x2 将栈顶两个数值互换：swap 控制转移指令控制转移指令可以让Java虚拟机有条件或无条件从指定位置指令继续执行程序，而不是控制转移指令的下一条指令，可以认为控制转移指令就是在有条件或无条件地修改PC寄存器的值。 条件分支：ifeq、iflt、ifle、ifgt、ifge、ifnull、ifnonull、if_icmpeg、if_icmpne、if_icmplt、if_icmpgt、if_icmple、if_acmpeg、if_acmpne 复合条件分支：tableswitch、lookupswitch 无条件分支：goto、goto_w、jsr、jsr_w、ret 虚拟机有专门的指令集用来处理int和reference类型的条件分支比较操作，也有专门的指令用来检测null值。 对于boolean、byte、char、short等类型的条件分支比较操作，都使用int类型的比较指令来完成，而long、float、double类型的条件分支比较操作，则执行相应类型的比较运算指令，运算指令会返回一个整型值到操作数栈中，随后再执行int类型的条件分支比较操作来完成整个分支跳转。各种类型的比较最终都会转化为int类型的比较操作，所以虚拟机提供的int类型的条件分支指令最丰富最强大。 方法调用和返回指令 invokevirtual指令用于调用对象的实例方法，根据对象实际类型进行分派（虚方法分派） invokeinterface指令用于调用接口方法，运行时搜索一个实现了这个接口方法的对象，找出最合适的方法进行调用 invokespecial指令用于调用一些特殊处理的实例方法，包括实例初始化方法、私有方法、父类方法 invokestatic指令用于调用类方法，即static方法 invokedynamic指令用于在运行时动态解析出调用点限定符所引用的方法，并执行该方法 前4条调用指令分派逻辑都固化在虚拟机内部，而invokedynamic指令分派逻辑是由用户所设定的引导方法决定的。 方法调用指令与数据类型无关，而方法返回指令是根据返回值的类型区分的，包括ireturn（返回值是boolean、byte、char、short、int类型时使用）、lreturn、freturn、dreturn、areturn，以及return指令供void方法、实例初始化方法、类和接口的类初始化方法使用。 异常处理指令程序中通过throw语句显示抛出异常的操作都由athrow指令来实现，除throw显示抛出异常外，虚拟机规范还规定了许多运行时异常会在其他Java虚拟机指令检测到异状况时自动抛出。虚拟机中catch语句处理异常不是由字节码指令来实现的，而是采用异常表来完成的。 同步指令虚拟机支持方法级的同步和方法内部一段指令序列的同步，两种同步都使用管程Monitor来支持的。 方法级的同步是隐式的，无须通过字节码指令来控制，它实现在方法调用和返回操作之中。虚拟机可以从方法常量池的方法结构中的ACC_SYNCHRONIZED访问标志得知方法是否声明未同步方法。当方法调用时，调用的指令将会检查方法的ACC_SYNCHRONIZED访问标志是否被设置，若被设置，执行线程就要求先成功持有管程Monitor，然后才能执行方法，最后当方法执行完成，无论是否正常完成都释放管程Monitor，方法执行期间，执行线程持有了管程Monitor，其他任何线程都无法再获得同一个管程Monitor。若同步方法执行期间抛出异常，且方法内部无法处理异常，同步方法所持有的管程Monitor将在异常抛到同步方法外时自动释放。 同步一段指令集序列通常是通过synchronized语句块来完成，虚拟机的指令集使用monitorenter和monitorexit两条指令来支持synchronized关键字的语义，正确实现synchronized关键字需要Javac编译器和Java虚拟机共同协作支持，编译器必须保证方法通过任何方式完成，方法中调用过的每条monitorenter指令都必须执行其对应的monitorexit指令，无论该方法是否正常结束。 为了保证方法异常完成时monitorenter和monitorexit指令能正确配对执行，编译器会自动产生一个异常处理器，且声明可处理的所有异常，来执行monitorexit指令。 虚拟机两种主要的实现方式： 将输入的Java虚拟机代码在加载或执行时翻译成另一种虚拟机指令集 将输入的Java虚拟机代码在加载或执行时翻译成宿主机CPU的本地指令集，即JIT代码生成技术","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"属性表集合","date":"2018-02-03T16:00:00.000Z","path":"Blog/Java/VM/属性表集合/","text":"在Class文件、字段表、方法表都可以携带自己的属性表集合，属性表集合不要求各个属性表具有严格顺序。 属性名称 使用位置 含义 Code 方法表 Java代码编译成的字节码指令 ConstantValue 字段表 final关键字定义的常量池 Deprecated 类，方法，字段表 被声明为deprecated的方法和字段 Exceptions 方法表 方法抛出的异常 EnclosingMethod 类文件 仅当一个类为局部类或者匿名类时才能拥有该属性，该属性用于标识该类所在的外围方法 InnerClass 类文件 内部类列表 LineNumberTable Code属性 Java源码的行号与字节码指令的对应关系 LocalVariableTable Code属性 方法的局部变量描述 StackMapTable Code属性 JDK1.6新增，供新的类型检查验证器检查和处理目标方法的局部变量和操作数有所需要的类是否匹配 Signature 类，方法表，字段表 用于支持泛型情况下的方法签名 SourceFile 类文件 记录源文件名称 SourceDebugExtension 类文件 用于存储额外的调试信息 Synthetic 类，方法表，字段表 标志方法或字段为编译器自动生成的 LocalVariableTypeTable 类 使用特征签名代替描述符，为了引入泛型语法之后能描述泛型参数化类型而添加 RuntimeVisibleAnnotations 类，方法表，字段表 为动态注解提供支持 RuntimeInvisibleAnnotations 表，方法表，字段表 用于指明哪些注解是运行时不可见的 RuntimeVisibleParameterAnnotation 方法表 作用与RuntimeVisibleAnnotations属性类似，作用对象方法 RuntimeInvisibleParameterAnnotation 方法表 作用与RuntimeInvisibleAnnotations属性类似，作用对象方法参数 AnnotationDefault 方法表 用于记录注解类元素的默认值 BootstrapMethods 类文件 用于保存invokeddynamic指令引用的引导方法限定符 每个属性名称都需要从常量池中引用一个CONSTANT_Utf8_info类型的常量来表示，属性值的结构完全自定义的，只需要通过一个u4长度属性去说明属性值所占用的位数即可。 类型 名称 数量 u2 attribute_name_index 1 u2 attribute_length 1 u1 info attribute_length Code属性Java方法体中代码经过Javac编译器处理后，最终变为字节码指令存储在Code属性内。Code属性出现在方法表的属性集合中，接口和抽象类中的抽象方法不存在Code属性。 Code属性是Class文件中最重要的一个属性，如果把一个Java程序中的信息分为代码（方法体中的代码）和元数据（类、字段、方法定义及其他信息），那整个Class文件中，Code属性用于描述代码，其他数据项目都有于描述元数据。 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 max_stack 1 u2 max_locals 1 u4 code_length 1 u1 code code_length u2 exception_table_length 1 exception_info exception_table exception_length u2 attributes_count 1 attribute_info attributes attributes_count attribute_name_index是指向CONSTANT_Utf8_info型常量的索引，其值固定为Code，代表该属性的属性名称，attribute_length表示属性值长度，属性名称索引与属性长度共6字节。 max_stack代表操作数栈最大深度，虚拟机运行时需要根据该值来分配栈帧中的操作数栈深度。 max_locals代表局部变量表所需内存空间，单位Slot，是虚拟机为局部变量表分配内存所使用的最小单位。byte、char、float、int、short、boolean、returnAddress等长度不超过32位的数据类型，每个局部变量占用1个Slot，而double和long这两种64位的数据类型则占用2个Slot。方法参数包括实例方法中的隐藏参数this、显式异常处理器的参数就是try-catch语句中catch块所定义的异常、方法体中定义的局部变量，都需要使用局部变量表来存放。局部变量中的Slot可以重用，当代码执行超出一个局部变量的作用域时，这个局部变量所占的Slot可以被其他局部变量所使用，Javac编译器会根据变量的作用域来分配Slot给各个变量使用，然后计算出max_locals的大小。 code_length和code用来存储Java源程序编译后生成的字节码指令。code_length代表字节码长度，code用于存储字节码指令的一系列字节流。每个字节码指令都是u1类型的数据，当虚拟机读取code中的字节码时，能够对应找出这个字节码代表的指令，指令后面是否需要跟随参数，参数应该如何理解。u1数据类型取值范围为0x00~0xFF，一共可表达256条指令，目前虚拟机规范定义了约200条编码值对应的指令含义。 code_length虽然是一个u4类型的数据，但虚拟机限制方法不允许超过65535条字节码指令，即它实际上只使用了u2的长度，如果超过限制Javac编译器会拒绝编译。在编译一个很浮渣的JSP文件时，某些JSP编译器会把JSP内容和页面输出信息归并于一个方法，可能因方法生成字节码超长导致编译失败。 123456789101112public com.coms.jvm.ClassFileConstantPool.TestClassA(); flags: ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.\"&lt;init&gt;\":()V 4: return LineNumberTable: line 3: 0 LocalVariableTable: Start Length Slot Name Signature 0 5 0 this Lcom/coms/jvm/ClassFileConstantPool/TestClassA; 从上面的代码可以看到，实例方法明显没有参数，但locals和args_size的值却为1，这是Java程序一个很重要的访问机制，在任何实例方法中，都可以通过this关键字访问到此方法的所属的对象，Javac编译器编译时把对this关键字的访问转变为对一个普通方法参数的访问，在虚拟机调用实例方法时自动传入此参数。 在字节码指令之后是方法的显示异常处理表集合exception_table，它对应Code属性来说并不是必须存在的。 123456Exception table: from to target type 0 4 8 Class java/lang/Exception 0 4 17 any 8 13 17 any 17 19 17 any Exceptions属性Exceptions属性是在方法表中于Code属性平级的属性，区别于前面的Code属性中的异常表。其作用是列举方法中可能抛出的受检查的异常，也就是方法描述时在throws关键字后面列举的异常。 12Exceptions: throws java.lang.Exception, java.sql.SQLException 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 attribute_of_exceptions 1 u2 exception_index_table number_of_exceptions attribute_of_exceptions表示方法可能抛出attribute_of_exceptions种异常，每一种受查异常使用一个exception_index_table项表示，exception_index_table时一个指向常量池种CONSTANT_Class_info型常量索引，代表了该受查异常的类型。 LineNumberTable属性LineNumberTable属性用于描述Java源码行号与字节码行号（字节码偏移量）之间的对应关系。并非运行时必需属性，默认会生成到Class文件中，可以在Javac种使用-g:none或-g:line选项来取消或要求生成该项信息。如果选择不生成该属性，当程序抛出异常时，堆栈中将不会显示出错的行号，在调试程序时也无法按照源码行来设置断点。 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 line_number_table_length 1 line_number_info line_number_table line_number_table_length line_number_table是一个数量为line_number_table_length、类型为line_number_info的集合，line_number_info包括了字节码行号start_pc和Java源码行号line_number两个u2类型的数据。 LocalVeriableTable属性LocalVeriableTable属性用于描述栈帧中局部变量表中的变量与Java源码中定义的变量之间的关系，非运行时必需属性，默认生成到Class文件中，可以在Javac种使用-g:none或-g:vars选项来取消或要求生成该项信息。如果不生成该属性，当其他人引用该方法时，所有参数名称都将丢失，IDE将会使用诸如arg0、arg1之类的占位符代替原有的参数名，虽对程序运行无影响，但对代码编写带来较大不便，且在调试时无法根据参数名称从上下文中获得参数值。 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 local_veriable_table_length 1 local_veriable_info local_veriable_table local_veriable_table_length local_veriable_info代表一个栈帧与源码中局部变量的关联。下表是local_veriable_info项目结构。 类型 名称 数量 u2 start_pc 1 u2 length 1 u2 name_index 1 u2 descriptor_index 1 u2 index 1 start_pc和length属性分别代表这个局部变量的生命周期开始字节码偏移量及其作用范围覆盖长度，两者结合就是该局部变量在字节码之中的作用范围。 name_index和descriptor_index都是指向常量池中CONSTANT_UTF8_info型常量索引，分别代表局部变量名称以及该局部变量的描述符。 index是该局部变量在栈帧局部变量表中Slot位置，当该变量数据类型是64位类型是，它占用的Slot位index和index+1。 LocalVeriableTypeTable属性LocalVeriableTypeTable属性是LocalVeriableTable属性的姐妹属性，其结构与LocalVeriableTable非常相似，仅仅把记录字段描述符的descriptor_index替换成了字段的特征签名，对于非泛型类型来说，描述符和特征签名能描述的信息基本上一致，但泛型中，描述符中泛型的参数化类型被擦除，描述符不能准确描述泛型类型。 SourceFile属性SourceFile属性用于记录生成这个Class文件的源码文件名称，定长属性，非运行时必需属性，默认生成到Class文件中，可以在Javac种使用-g:none或-g:source选项来取消或要求生成该项信息。Java中大多数类的类名和文件名一致，但内部类列外，如果不生成该属性，当抛异常时，堆栈中将不会显示出错误代码所属的文件名。 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 sourcefile_index 1 sourcefile_index数据项是指向常量池中CONSTANT_UTF8_info型常量索引，常量值是源文件的文件名。 ConstantValue属性ConstantValue属性的作用是通知虚拟机自动为静态变量赋值，定长属性，只有被final关键字修饰的变量才可以使用这项属性。对于非static类型的变量赋值时在实例构造器&lt;init&gt;方法中进行的，而static类型变量，有两种方式可以选择，在类构造器&lt;clinit&gt;方法中或者使用ConstantValue属性。目前在Sun Javac编译器中，如果同时使用final和static修饰变量，且该变量数据类型是基本数据类型或者java.lang.String，就生成ConstantValue属性类进行初始化，如果这个变量没有别final修饰或者并非基本类型及字符串，则会在&lt;clinit&gt;方法中进行初始化。 虚拟机规范中只要求了有ConstantValue属性的字段必须设置ACC_STATIC标志，并没有强制要求设置ACC_FINAL标志，对final关键字的要求是Javac编译器自己加入的限制。 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 constantvalue_index 1 constantvalue_index数据项代表了常量池中一个字面量常量的引用，根据字段类型不同，字面量可以是CONSTANT_Long_info、CONSTANT_Float_info、CONSTANT_Double_info、CONSTANT_Integer_info、CONSTANT_String_info InnerClasses属性InnerClasses属性用于记录内部类与宿主类之间的关联，如果类中定义了内部类，编译器将会为它以及它所包含的内部类生成InnerClasses属性。 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 number_of_classes 1 inner_classes_info inner_classes number_of_classes 数据项inner_classes_info代表需要记录多少个内部类信息，每个内部类信息都由一个inner_classes_info表进行描述。 类型 名称 数量 u2 inner_class_info_index 1 u2 other_class_info_index 1 u2 inner_name_index 1 u2 inner_class_access_flags 1 inner_class_info_index和other_class_info_index都是指向常量池中CONSTANT_Class_info型常量索引，分别代表内部类和宿主类的符号引用；inner_name_index是指向常量池中CONSTANT_UTF8_info型常量索引，代表这个内部类的名称，如果是匿名内部类该项值为0；inner_class_access_flags是内部类的访问标志，类似于类的access_flags。 Deprecated &amp; Synthetic属性Deprecated和Synthetic两个属性都属于标志类型的布尔属性，只存在有和没有的区别，没有属性值的概念。 Deprecated属性用于表示某个类、字段、方法，已经被程序作者定为不再推荐使用，通过在代码中使用@deprecated注解进行设置。 Synthetic属性代表此字段或者方法并不是由Java源代码直接生成的，而是由编译器自行添加的，标识一个类、字段或者方法是编译器自动产生的，也可以设置访问标志中的ACC_SYNTHETIC标志位。所有由非用户代码产生的类、方法及字段都应当至少设置Synthetic属性和ACC_SYNTHETIC标志位中的一项，唯一例外是实例构造器&lt;init&gt;和类构造器&lt;clinit&gt;。 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 attribute_length的值必须为0x00000000，因为没有任何属性值需要设置。 StackMapTable属性StackMapTable属性JDK1.6增加到Class文件规范中，在JDK1.7中强制代替原本基于类型推断的字节码验证器，它是一个复杂的变长属性，位于Code属性的attributes属性表中，该属性会在虚拟机类加载的字节码验证阶段被新类型检查验证器使用，目的在于替代以前比较消耗性能的基于数据流分析的类型推导验证器。 新验证器在同样能保证Class文件合法性的前提下，省略了在运行期通过数据流分析去确认字节码的行为逻辑合法性的步骤，而是在编译阶段将一系列的验证类型直接记录在Class文件中，通过检查这些验证类型代替了类型推导过程，从而大幅度提升了字节码验证的性能。 StackMapTable属性中包含0至多个栈映射帧，每个栈映射帧都显式或隐式地代表了一个字节码偏移量，用于表示该执行到该字节码时局部变量表和操作数栈的验证类型。类型检查验证器会通过检查目标方法的局部变量和操作数栈所需要的类型来确定一段字节码指令是否符合逻辑约束。 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 number_of_entries 1 stack_map_frame stack_map_frame_entries number_of_entries 在版本号大于或等于50.0的Class文件中，如果方法的Code属性中没有附带StackMapTable属性，意味着它带有一个隐式的StackMap属性，起作用等同于number_of_entries值为0的StackMapTable属性。一个方法的Code属性最多只能有一个StackMapTable属性，否则将抛出ClassFormatError异常。 Signature属性Signature属性在JDK1.5增加到Class文件规范中，可选定长属性，可以出现于类、字段表和方法表结构的属性表中。任何类、接口、初始化方法或成员的泛型签名如果包含了类型变量或参数化类型，则Signature属性会为它记录泛型签名信息，之所以这样是由于Java的泛型采用的是擦除法实现的伪泛型，在字节码中，泛型信息编译之后类型变量和参数化类型都被擦除了，运行期做反射时无法获得泛型信息。Signature属性就是为了弥补这个缺陷，现在Java的反射API能获取泛型类型，最终的数据类来源为Signature属性。 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 signature_index 1 signature_index值必须时一个对常量池的有效索引，参量池在该索引处必须是CONSTANT_UTF8_info结构，表示类签名、方法类型签名或字段类型签名。Signature属性是类文件属性该结构表示类签名，Signature属性是方法表的属性该结构表示方法类型签名，Signature属性是字段表的属性该结构表示字段类型签名。 BootstrapMethods属性BootstrapMethods属性在JDK1.7增加到Class文件规范中，复杂变长属性，位于类文件属性表中。该属性用于保存invokedynamic指令引用的引导方法限定符。如果某个类文件结构的常量池中曾经出现过CONSTANT_InvokeDynamic_info类型的常量，那该类文件的属性表中必须存在一个明确的BootstrapMethods属性，即使出现多次也最多也只能有一个。 类型 名称 数量 u2 attribute_name_index 1 u4 attribute_length 1 u2 num_bootstrap_methods 1 bootstrap_method bootstrap_methods num_bootstrap_methods num_bootstrap_methods值为bootstrap_methods[]数组中的引导方法限定符的数量，bootstrap_methods[]数组的每个成员都包含一个指向常量池CONSTANT_MethodHandle结构的索引值，它代表示一个引导方法，还包含了该引导方法静态参数的序列。其中num_bootstrap_method表结构如下所示： 类型 名称 数量 u2 bootstrap_method_ref 1 u4 num_bootstrap_arguments 1 u2 bootstrap_arguments num_bootstrap_arguments bootstrap_method_ref值必须是一个对常量池的有效索引，且该索引值必须是一个CONSTANT_MethodHandle_info结构；num_bootstrap_arguments表示bootstrap_arguments[]数组成员的数量；bootstrap_arguments[]数组成员必须是一个对常量池有效的索引，且必须是一下结构之一：CONSTANT_String_info、CONSTANT_Class_info、CONSTANT_Integer_info、CONSTANT_Long_info、CONSTANT_Float_info、CONSTANT_Double_info、CONSTANT_MethodHandle_info、CONSTANT_MothodType_info。","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"Maven标签全解","date":"2018-01-21T16:00:00.000Z","path":"Blog/Maven/Maven标签全解/","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641&lt;project xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://maven.apache.org/POM/4.0.0\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd \"&gt; &lt;!-- 父项目的坐标。如果项目中没有规定某个元素的值，那么父项目中的对应值即为项目的默认值。 坐标包括group ID，artifact ID和 version。 --&gt; &lt;parent&gt; &lt;!-- 被继承的父项目的构件标识符 --&gt; &lt;artifactId/&gt; &lt;!-- 被继承的父项目的全球唯一标识符 --&gt; &lt;groupId/&gt; &lt;!-- 被继承的父项目的版本 --&gt; &lt;version/&gt; &lt;!-- 父项目的pom.xml文件的相对路径。相对路径允许你选择一个不同的路径。默认值是../pom.xml。Maven首先在构建当前项目的地方寻找父项目的pom，其次在文件系统的这个位置（relativePath位置），然后在本地仓库，最后在远程仓库寻找父项目的pom。 --&gt; &lt;relativePath/&gt; &lt;/parent&gt; &lt;!-- 声明项目描述符遵循哪一个POM模型版本。模型本身的版本很少改变，虽然如此，但它仍然是必不可少的，这是为了当Maven引入了新的特性或者其他模型变更的时候，确保稳定性。 --&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- 项目的全球唯一标识符，通常使用全限定的包名区分该项目和其他项目。并且构建时生成的路径也是由此生成， 如com.mycompany.app生成的相对路径为：/com/mycompany/app --&gt; &lt;groupId&gt;asia.banseon&lt;/groupId&gt; &lt;!-- 构件的标识符，它和group ID一起唯一标识一个构件。换句话说，你不能有两个不同的项目拥有同样的artifact ID和groupID；在某个特定的group ID下，artifact ID也必须是唯一的。构件是项目产生的或使用的一个东西，Maven为项目产生的构件包括：JARs，源码，二进制发布和WARs等。 --&gt; &lt;artifactId&gt;banseon-maven2&lt;/artifactId&gt; &lt;!-- 项目产生的构件类型，例如jar、war、ear、pom。插件可以创建他们自己的构件类型，所以前面列的不是全部构件类型 --&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;!-- 项目当前版本，格式为:主版本.次版本.增量版本-限定版本号 --&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt; &lt;!-- 项目的名称, Maven产生的文档用 --&gt; &lt;name&gt;banseon-maven&lt;/name&gt; &lt;!-- 项目主页的URL, Maven产生的文档用 --&gt; &lt;url&gt;http://www.baidu.com/banseon&lt;/url&gt; &lt;!-- 项目的详细描述, Maven 产生的文档用。 当这个元素能够用HTML格式描述时（例如，CDATA中的文本会被解析器忽略，就可以包含HTML标签）， 不鼓励使用纯文本描述。如果你需要修改产生的web站点的索引页面，你应该修改你自己的索引页文件，而不是调整这里的文档。 --&gt; &lt;description&gt;A maven project to study maven.&lt;/description&gt; &lt;!-- 描述了这个项目构建环境中的前提条件。 --&gt; &lt;prerequisites&gt; &lt;!-- 构建该项目或使用该插件所需要的Maven的最低版本 --&gt; &lt;maven/&gt; &lt;/prerequisites&gt; &lt;!-- 项目的问题管理系统(Bugzilla, Jira, Scarab,或任何你喜欢的问题管理系统)的名称和URL，本例为 jira --&gt; &lt;issueManagement&gt; &lt;!-- 问题管理系统（例如jira）的名字， --&gt; &lt;system&gt;jira&lt;/system&gt; &lt;!-- 该项目使用的问题管理系统的URL --&gt; &lt;url&gt;http://jira.baidu.com/banseon&lt;/url&gt; &lt;/issueManagement&gt; &lt;!-- 项目持续集成信息 --&gt; &lt;ciManagement&gt; &lt;!-- 持续集成系统的名字，例如continuum --&gt; &lt;system/&gt; &lt;!-- 该项目使用的持续集成系统的URL（如果持续集成系统有web接口的话）。 --&gt; &lt;url/&gt; &lt;!-- 构建完成时，需要通知的开发者/用户的配置项。包括被通知者信息和通知条件（错误，失败，成功，警告） --&gt; &lt;notifiers&gt; &lt;!-- 配置一种方式，当构建中断时，以该方式通知用户/开发者 --&gt; &lt;notifier&gt; &lt;!-- 传送通知的途径 --&gt; &lt;type/&gt; &lt;!-- 发生错误时是否通知 --&gt; &lt;sendOnError/&gt; &lt;!-- 构建失败时是否通知 --&gt; &lt;sendOnFailure/&gt; &lt;!-- 构建成功时是否通知 --&gt; &lt;sendOnSuccess/&gt; &lt;!-- 发生警告时是否通知 --&gt; &lt;sendOnWarning/&gt; &lt;!-- 不赞成使用。通知发送到哪里 --&gt; &lt;address/&gt; &lt;!-- 扩展配置项 --&gt; &lt;configuration/&gt; &lt;/notifier&gt; &lt;/notifiers&gt; &lt;/ciManagement&gt; &lt;!-- 项目创建年份，4位数字。当产生版权信息时需要使用这个值。 --&gt; &lt;inceptionYear/&gt; &lt;!-- 项目相关邮件列表信息 --&gt; &lt;mailingLists&gt; &lt;!-- 该元素描述了项目相关的所有邮件列表。自动产生的网站引用这些信息。 --&gt; &lt;mailingList&gt; &lt;!-- 邮件的名称 --&gt; &lt;name&gt;Demo&lt;/name&gt; &lt;!-- 发送邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建 --&gt; &lt;post&gt;banseon@126.com&lt;/post&gt; &lt;!-- 订阅邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建 --&gt; &lt;subscribe&gt;banseon@126.com&lt;/subscribe&gt; &lt;!-- 取消订阅邮件的地址或链接，如果是邮件地址，创建文档时，mailto: 链接会被自动创建 --&gt; &lt;unsubscribe&gt;banseon@126.com&lt;/unsubscribe&gt; &lt;!-- 你可以浏览邮件信息的URL --&gt; &lt;archive&gt;http:/hi.baidu.com/banseon/demo/dev/&lt;/archive&gt; &lt;/mailingList&gt; &lt;/mailingLists&gt; &lt;!-- 项目开发者列表 --&gt; &lt;developers&gt; &lt;!-- 某个项目开发者的信息 --&gt; &lt;developer&gt; &lt;!-- SCM里项目开发者的唯一标识符 --&gt; &lt;id&gt;HELLO WORLD&lt;/id&gt; &lt;!-- 项目开发者的全名 --&gt; &lt;name&gt;banseon&lt;/name&gt; &lt;!-- 项目开发者的email --&gt; &lt;email&gt;banseon@126.com&lt;/email&gt; &lt;!-- 项目开发者的主页的URL --&gt; &lt;url/&gt; &lt;!-- 项目开发者在项目中扮演的角色，角色元素描述了各种角色 --&gt; &lt;roles&gt; &lt;role&gt;Project Manager&lt;/role&gt; &lt;role&gt;Architect&lt;/role&gt; &lt;/roles&gt; &lt;!-- 项目开发者所属组织 --&gt; &lt;organization&gt;demo&lt;/organization&gt; &lt;!-- 项目开发者所属组织的URL --&gt; &lt;organizationUrl&gt;http://hi.baidu.com/banseon&lt;/organizationUrl&gt; &lt;!-- 项目开发者属性，如即时消息如何处理等 --&gt; &lt;properties&gt; &lt;dept&gt;No&lt;/dept&gt; &lt;/properties&gt; &lt;!-- 项目开发者所在时区， -11到12范围内的整数。 --&gt; &lt;timezone&gt;-5&lt;/timezone&gt; &lt;/developer&gt; &lt;/developers&gt; &lt;!-- 项目的其他贡献者列表 --&gt; &lt;contributors&gt; &lt;!-- 项目的其他贡献者。参见developers/developer元素 --&gt; &lt;contributor&gt; &lt;name/&gt; &lt;email/&gt; &lt;url/&gt; &lt;organization/&gt; &lt;organizationUrl/&gt; &lt;roles/&gt; &lt;timezone/&gt; &lt;properties/&gt; &lt;/contributor&gt; &lt;/contributors&gt; &lt;!-- 该元素描述了项目所有License列表。 应该只列出该项目的license列表，不要列出依赖项目的 license列表。如果列出多个license，用户可以选择它们中的一个而不是接受所有license。 --&gt; &lt;licenses&gt; &lt;!-- 描述了项目的license，用于生成项目的web站点的license页面，其他一些报表和validation也会用到该元素。 --&gt; &lt;license&gt; &lt;!-- license用于法律上的名称 --&gt; &lt;name&gt;Apache 2&lt;/name&gt; &lt;!-- 官方的license正文页面的URL --&gt; &lt;url&gt;http://www.baidu.com/banseon/LICENSE-2.0.txt&lt;/url&gt; &lt;!-- 项目分发的主要方式： repo，可以从Maven库下载 manual， 用户必须手动下载和安装依赖 --&gt; &lt;distribution&gt;repo&lt;/distribution&gt; &lt;!-- 关于license的补充信息 --&gt; &lt;comments&gt;A business-friendly OSS license&lt;/comments&gt; &lt;/license&gt; &lt;/licenses&gt; &lt;!-- SCM(Source Control Management)标签允许你配置你的代码库，供Maven web站点和其它插件使用。 --&gt; &lt;scm&gt; &lt;!-- SCM的URL,该URL描述了版本库和如何连接到版本库。欲知详情，请看SCMs提供的URL格式和列表。该连接只读。 --&gt; &lt;connection&gt; scm:svn:http://svn.baidu.com/banseon/maven/banseon/banseon-maven2-trunk(dao-trunk) &lt;/connection&gt; &lt;!-- 给开发者使用的，类似connection元素。即该连接不仅仅只读 --&gt; &lt;developerConnection&gt; scm:svn:http://svn.baidu.com/banseon/maven/banseon/dao-trunk &lt;/developerConnection&gt; &lt;!-- 当前代码的标签，在开发阶段默认为HEAD --&gt; &lt;tag/&gt; &lt;!-- 指向项目的可浏览SCM库（例如ViewVC或者Fisheye）的URL。 --&gt; &lt;url&gt;http://svn.baidu.com/banseon&lt;/url&gt; &lt;/scm&gt; &lt;!-- 描述项目所属组织的各种属性。Maven产生的文档用 --&gt; &lt;organization&gt; &lt;!-- 组织的全名 --&gt; &lt;name&gt;demo&lt;/name&gt; &lt;!-- 组织主页的URL --&gt; &lt;url&gt;http://www.baidu.com/banseon&lt;/url&gt; &lt;/organization&gt; &lt;!-- 构建项目需要的信息 --&gt; &lt;build&gt; &lt;!-- 该元素设置了项目源码目录，当构建项目的时候，构建系统会编译目录里的源码。该路径是相对于pom.xml的相对路径。 --&gt; &lt;sourceDirectory/&gt; &lt;!-- 该元素设置了项目脚本源码目录，该目录和源码目录不同：绝大多数情况下，该目录下的内容 会被拷贝到输出目录(因为脚本是被解释的，而不是被编译的)。 --&gt; &lt;scriptSourceDirectory/&gt; &lt;!-- 该元素设置了项目单元测试使用的源码目录，当测试项目的时候，构建系统会编译目录里的源码。该路径是相对于pom.xml的相对路径。 --&gt; &lt;testSourceDirectory/&gt; &lt;!-- 被编译过的应用程序class文件存放的目录。 --&gt; &lt;outputDirectory/&gt; &lt;!-- 被编译过的测试class文件存放的目录。 --&gt; &lt;testOutputDirectory/&gt; &lt;!-- 使用来自该项目的一系列构建扩展 --&gt; &lt;extensions&gt; &lt;!-- 描述使用到的构建扩展。 --&gt; &lt;extension&gt; &lt;!-- 构建扩展的groupId --&gt; &lt;groupId/&gt; &lt;!-- 构建扩展的artifactId --&gt; &lt;artifactId/&gt; &lt;!-- 构建扩展的版本 --&gt; &lt;version/&gt; &lt;/extension&gt; &lt;/extensions&gt; &lt;!-- 当项目没有规定目标（Maven2 叫做阶段）时的默认值 --&gt; &lt;defaultGoal/&gt; &lt;!-- 这个元素描述了项目相关的所有资源路径列表，例如和项目相关的属性文件，这些资源被包含在最终的打包文件里。 --&gt; &lt;resources&gt; &lt;!-- 这个元素描述了项目相关或测试相关的所有资源路径 --&gt; &lt;resource&gt; &lt;!-- 描述了资源的目标路径。该路径相对target/classes目录（例如$&#123;project.build.outputDirectory&#125;）。举个例子，如果你想资源在特定的包里(org.apache.maven.messages)，你就必须该元素设置为org/apache/maven/messages。然而，如果你只是想把资源放到源码目录结构里，就不需要该配置。 --&gt; &lt;targetPath/&gt; &lt;!-- 是否使用参数值代替参数名。参数值取自properties元素或者文件里配置的属性，文件在filters元素里列出。 --&gt; &lt;filtering/&gt; &lt;!-- 描述存放资源的目录，该路径相对POM路径 --&gt; &lt;directory/&gt; &lt;!-- 包含的模式列表，例如**/*.xml. --&gt; &lt;includes/&gt; &lt;!-- 排除的模式列表，例如**/*.xml --&gt; &lt;excludes/&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;!-- 这个元素描述了单元测试相关的所有资源路径，例如和单元测试相关的属性文件。 --&gt; &lt;testResources&gt; &lt;!-- 这个元素描述了测试相关的所有资源路径，参见build/resources/resource元素的说明 --&gt; &lt;testResource&gt; &lt;targetPath/&gt; &lt;filtering/&gt; &lt;directory/&gt; &lt;includes/&gt; &lt;excludes/&gt; &lt;/testResource&gt; &lt;/testResources&gt; &lt;!-- 构建产生的所有文件存放的目录 --&gt; &lt;directory/&gt; &lt;!-- 产生的构件的文件名，默认值是$&#123;artifactId&#125;-$&#123;version&#125;。 --&gt; &lt;finalName/&gt; &lt;!-- 当filtering开关打开时，使用到的过滤器属性文件列表 --&gt; &lt;filters/&gt; &lt;!-- 子项目可以引用的默认插件信息。该插件配置项直到被引用时才会被解析或绑定到生命周期。给定插件的任何本地配置都会覆盖这里的配置 --&gt; &lt;pluginManagement&gt; &lt;!-- 使用的插件列表 。 --&gt; &lt;plugins&gt; &lt;!-- plugin元素包含描述插件所需要的信息。 --&gt; &lt;plugin&gt; &lt;!-- 插件在仓库里的group ID --&gt; &lt;groupId/&gt; &lt;!-- 插件在仓库里的artifact ID --&gt; &lt;artifactId/&gt; &lt;!-- 被使用的插件的版本（或版本范围） --&gt; &lt;version/&gt; &lt;!-- 是否从该插件下载Maven扩展（例如打包和类型处理器），由于性能原因，只有在真需要下载时，该元素才被设置成enabled。 --&gt; &lt;extensions/&gt; &lt;!-- 在构建生命周期中执行一组目标的配置。每个目标可能有不同的配置。 --&gt; &lt;executions&gt; &lt;!-- execution元素包含了插件执行需要的信息 --&gt; &lt;execution&gt; &lt;!-- 执行目标的标识符，用于标识构建过程中的目标，或者匹配继承过程中需要合并的执行目标 --&gt; &lt;id/&gt; &lt;!-- 绑定了目标的构建生命周期阶段，如果省略，目标会被绑定到源数据里配置的默认阶段 --&gt; &lt;phase/&gt; &lt;!-- 配置的执行目标 --&gt; &lt;goals/&gt; &lt;!-- 配置是否被传播到子POM --&gt; &lt;inherited/&gt; &lt;!-- 作为DOM对象的配置 --&gt; &lt;configuration/&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;!-- 项目引入插件所需要的额外依赖 --&gt; &lt;dependencies&gt; &lt;!-- 参见dependencies/dependency元素 --&gt; &lt;dependency&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- 任何配置是否被传播到子项目 --&gt; &lt;inherited/&gt; &lt;!-- 作为DOM对象的配置 --&gt; &lt;configuration/&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;!-- 使用的插件列表 --&gt; &lt;plugins&gt; &lt;!-- 参见build/pluginManagement/plugins/plugin元素 --&gt; &lt;plugin&gt; &lt;groupId/&gt; &lt;artifactId/&gt; &lt;version/&gt; &lt;extensions/&gt; &lt;executions&gt; &lt;execution&gt; &lt;id/&gt; &lt;phase/&gt; &lt;goals/&gt; &lt;inherited/&gt; &lt;configuration/&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;!-- 参见dependencies/dependency元素 --&gt; &lt;dependency&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;goals/&gt; &lt;inherited/&gt; &lt;configuration/&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;!-- 在列的项目构建profile，如果被激活，会修改构建处理 --&gt; &lt;profiles&gt; &lt;!-- 根据环境参数或命令行参数激活某个构建处理 --&gt; &lt;profile&gt; &lt;!-- 构建配置的唯一标识符。即用于命令行激活，也用于在继承时合并具有相同标识符的profile。 --&gt; &lt;id/&gt; &lt;!-- 自动触发profile的条件逻辑。Activation是profile的开启钥匙。profile的力量来自于它 能够在某些特定的环境中自动使用某些特定的值；这些环境通过activation元素指定。activation元素并不是激活profile的唯一方式。 --&gt; &lt;activation&gt; &lt;!-- profile默认是否激活的标志 --&gt; &lt;activeByDefault/&gt; &lt;!-- 当匹配的jdk被检测到，profile被激活。例如，1.4激活JDK1.4，1.4.0_2，而!1.4激活所有版本不是以1.4开头的JDK。 --&gt; &lt;jdk/&gt; &lt;!-- 当匹配的操作系统属性被检测到，profile被激活。os元素可以定义一些操作系统相关的属性。 --&gt; &lt;os&gt; &lt;!-- 激活profile的操作系统的名字 --&gt; &lt;name&gt;Windows XP&lt;/name&gt; &lt;!-- 激活profile的操作系统所属家族(如 'windows') --&gt; &lt;family&gt;Windows&lt;/family&gt; &lt;!-- 激活profile的操作系统体系结构 --&gt; &lt;arch&gt;x86&lt;/arch&gt; &lt;!-- 激活profile的操作系统版本 --&gt; &lt;version&gt;5.1.2600&lt;/version&gt; &lt;/os&gt; &lt;!-- 如果Maven检测到某一个属性（其值可以在POM中通过$&#123;名称&#125;引用），其拥有对应的名称和值，Profile就会被激活。如果值 字段是空的，那么存在属性名称字段就会激活profile，否则按区分大小写方式匹配属性值字段 --&gt; &lt;property&gt; &lt;!-- 激活profile的属性的名称 --&gt; &lt;name&gt;mavenVersion&lt;/name&gt; &lt;!-- 激活profile的属性的值 --&gt; &lt;value&gt;2.0.3&lt;/value&gt; &lt;/property&gt; &lt;!-- 提供一个文件名，通过检测该文件的存在或不存在来激活profile。missing检查文件是否存在，如果不存在则激活 profile。另一方面，exists则会检查文件是否存在，如果存在则激活profile。 --&gt; &lt;file&gt; &lt;!-- 如果指定的文件存在，则激活profile。 --&gt; &lt;exists&gt;/usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/&lt;/exists&gt; &lt;!-- 如果指定的文件不存在，则激活profile。 --&gt; &lt;missing&gt;/usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/&lt;/missing&gt; &lt;/file&gt; &lt;/activation&gt; &lt;!-- 构建项目所需要的信息。参见build元素 --&gt; &lt;build&gt; &lt;defaultGoal/&gt; &lt;resources&gt; &lt;resource&gt; &lt;targetPath/&gt; &lt;filtering/&gt; &lt;directory/&gt; &lt;includes/&gt; &lt;excludes/&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;testResources&gt; &lt;testResource&gt; &lt;targetPath/&gt; &lt;filtering/&gt; &lt;directory/&gt; &lt;includes/&gt; &lt;excludes/&gt; &lt;/testResource&gt; &lt;/testResources&gt; &lt;directory/&gt; &lt;finalName/&gt; &lt;filters/&gt; &lt;pluginManagement&gt; &lt;plugins&gt; &lt;!-- 参见build/pluginManagement/plugins/plugin元素 --&gt; &lt;plugin&gt; &lt;groupId/&gt; &lt;artifactId/&gt; &lt;version/&gt; &lt;extensions/&gt; &lt;executions&gt; &lt;execution&gt; &lt;id/&gt; &lt;phase/&gt; &lt;goals/&gt; &lt;inherited/&gt; &lt;configuration/&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;!-- 参见dependencies/dependency元素 --&gt; &lt;dependency&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;goals/&gt; &lt;inherited/&gt; &lt;configuration/&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;plugins&gt; &lt;!-- 参见build/pluginManagement/plugins/plugin元素 --&gt; &lt;plugin&gt; &lt;groupId/&gt; &lt;artifactId/&gt; &lt;version/&gt; &lt;extensions/&gt; &lt;executions&gt; &lt;execution&gt; &lt;id/&gt; &lt;phase/&gt; &lt;goals/&gt; &lt;inherited/&gt; &lt;configuration/&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;!-- 参见dependencies/dependency元素 --&gt; &lt;dependency&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;goals/&gt; &lt;inherited/&gt; &lt;configuration/&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;!-- 模块（有时称作子项目） 被构建成项目的一部分。列出的每个模块元素是指向该模块的目录的相对路径 --&gt; &lt;modules/&gt; &lt;!-- 发现依赖和扩展的远程仓库列表。 --&gt; &lt;repositories&gt; &lt;!-- 参见repositories/repository元素 --&gt; &lt;repository&gt; &lt;releases&gt; &lt;enabled/&gt; &lt;updatePolicy/&gt; &lt;checksumPolicy/&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled/&gt; &lt;updatePolicy/&gt; &lt;checksumPolicy/&gt; &lt;/snapshots&gt; &lt;id/&gt; &lt;name/&gt; &lt;url/&gt; &lt;layout/&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;!-- 发现插件的远程仓库列表，这些插件用于构建和报表 --&gt; &lt;pluginRepositories&gt; &lt;!-- 包含需要连接到远程插件仓库的信息.参见repositories/repository元素 --&gt; &lt;pluginRepository&gt; &lt;releases&gt; &lt;enabled/&gt; &lt;updatePolicy/&gt; &lt;checksumPolicy/&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled/&gt; &lt;updatePolicy/&gt; &lt;checksumPolicy/&gt; &lt;/snapshots&gt; &lt;id/&gt; &lt;name/&gt; &lt;url/&gt; &lt;layout/&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;!-- 该元素描述了项目相关的所有依赖。 这些依赖组成了项目构建过程中的一个个环节。它们自动从项目定义的仓库中下载。要获取更多信息，请看项目依赖机制。 --&gt; &lt;dependencies&gt; &lt;!-- 参见dependencies/dependency元素 --&gt; &lt;dependency&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- 不赞成使用. 现在Maven忽略该元素. --&gt; &lt;reports/&gt; &lt;!-- 该元素包括使用报表插件产生报表的规范。当用户执行“mvn site”，这些报表就会运行。 在页面导航栏能看到所有报表的链接。参见reporting元素 --&gt; &lt;reporting&gt; &lt;/reporting&gt; &lt;!-- 参见dependencyManagement元素 --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- 参见dependencies/dependency元素 --&gt; &lt;dependency&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!-- 参见distributionManagement元素 --&gt; &lt;distributionManagement&gt; &lt;/distributionManagement&gt; &lt;!-- 参见properties元素 --&gt; &lt;properties/&gt; &lt;/profile&gt; &lt;/profiles&gt; &lt;!-- 模块（有时称作子项目） 被构建成项目的一部分。列出的每个模块元素是指向该模块的目录的相对路径 --&gt; &lt;modules/&gt; &lt;!-- 发现依赖和扩展的远程仓库列表。 --&gt; &lt;repositories&gt; &lt;!-- 包含需要连接到远程仓库的信息 --&gt; &lt;repository&gt; &lt;!-- 如何处理远程仓库里发布版本的下载 --&gt; &lt;releases&gt; &lt;!-- true或者false表示该仓库是否为下载某种类型构件（发布版，快照版）开启。 --&gt; &lt;enabled/&gt; &lt;!-- 该元素指定更新发生的频率。Maven会比较本地POM和远程POM的时间戳。这里的选项是：always（一直），daily（默认，每日），interval：X（这里X是以分钟为单位的时间间隔），或者never（从不）。 --&gt; &lt;updatePolicy/&gt; &lt;!-- 当Maven验证构件校验文件失败时该怎么做：ignore（忽略），fail（失败），或者warn（警告）。 --&gt; &lt;checksumPolicy/&gt; &lt;/releases&gt; &lt;!-- 如何处理远程仓库里快照版本的下载。有了releases和snapshots这两组配置，POM就可以在每个单独的仓库中，为每种类型的构件采取不同的策略。例如，可能有人会决定只为开发目的开启对快照版本下载的支持。参见repositories/repository/releases元素 --&gt; &lt;snapshots&gt; &lt;enabled/&gt; &lt;updatePolicy/&gt; &lt;checksumPolicy/&gt; &lt;/snapshots&gt; &lt;!-- 远程仓库唯一标识符。可以用来匹配在settings.xml文件里配置的远程仓库 --&gt; &lt;id&gt;banseon-repository-proxy&lt;/id&gt; &lt;!-- 远程仓库名称 --&gt; &lt;name&gt;banseon-repository-proxy&lt;/name&gt; &lt;!-- 远程仓库URL，按protocol://hostname/path形式 --&gt; &lt;url&gt;http://192.168.1.169:9999/repository/&lt;/url&gt; &lt;!-- 用于定位和排序构件的仓库布局类型-可以是default（默认）或者legacy（遗留）。Maven 2为其仓库提供了一个默认的布局；然而，Maven 1.x有一种不同的布局。我们可以使用该元素指定布局是default（默认）还是legacy（遗留）。 --&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;!-- 发现插件的远程仓库列表，这些插件用于构建和报表 --&gt; &lt;pluginRepositories&gt; &lt;!-- 包含需要连接到远程插件仓库的信息.参见repositories/repository元素 --&gt; &lt;pluginRepository&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;!-- 该元素描述了项目相关的所有依赖。 这些依赖组成了项目构建过程中的一个个环节。它们自动从项目定义的仓库中下载。要获取更多信息，请看项目依赖机制。 --&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;!-- 依赖的group ID --&gt; &lt;groupId&gt;org.apache.maven&lt;/groupId&gt; &lt;!-- 依赖的artifact ID --&gt; &lt;artifactId&gt;maven-artifact&lt;/artifactId&gt; &lt;!-- 依赖的版本号。 在Maven 2里, 也可以配置成版本号的范围。 --&gt; &lt;version&gt;3.8.1&lt;/version&gt; &lt;!-- 依赖类型，默认类型是jar。它通常表示依赖的文件的扩展名，但也有例外。一个类型可以被映射成另外一个扩展名或分类器。类型经常和使用的打包方式对应，尽管这也有例外。一些类型的例子：jar，war，ejb-client和test-jar。如果设置extensions为 true，就可以在plugin里定义新的类型。所以前面的类型的例子不完整。 --&gt; &lt;type&gt;jar&lt;/type&gt; &lt;!-- 依赖的分类器。分类器可以区分属于同一个POM，但不同构建方式的构件。分类器名被附加到文件名的版本号后面。例如，如果你想要构建两个单独的构件成JAR，一个使用Java 1.4编译器，另一个使用Java 6编译器，你就可以使用分类器来生成两个单独的JAR构件。 --&gt; &lt;classifier&gt;&lt;/classifier&gt; &lt;!-- 依赖范围。在项目发布过程中，帮助决定哪些构件被包括进来。欲知详情请参考依赖机制。 - compile ：默认范围，用于编译 - provided：类似于编译，但支持你期待jdk或者容器提供，类似于classpath - runtime: 在执行时需要使用 - test: 用于test任务时使用 - system: 需要外在提供相应的元素。通过systemPath来取得 - systemPath: 仅用于范围为system。提供相应的路径 - optional: 当项目自身被依赖时，标注依赖是否传递。用于连续依赖时使用 --&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;!-- 仅供system范围使用。注意，不鼓励使用这个元素，并且在新的版本中该元素可能被覆盖掉。该元素为依赖规定了文件系统上的路径。需要绝对路径而不是相对路径。推荐使用属性匹配绝对路径，例如$&#123;java.home&#125;。 --&gt; &lt;systemPath&gt;&lt;/systemPath&gt; &lt;!-- 当计算传递依赖时， 从依赖构件列表里，列出被排除的依赖构件集。即告诉maven你只依赖指定的项目，不依赖项目的依赖。此元素主要用于解决版本冲突问题 --&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; &lt;!-- 可选依赖，如果你在项目B中把C依赖声明为可选，你就需要在依赖于B的项目（例如项目A）中显式的引用对C的依赖。可选依赖阻断依赖的传递性。 --&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- 不赞成使用. 现在Maven忽略该元素. --&gt; &lt;reports&gt;&lt;/reports&gt; &lt;!-- 该元素描述使用报表插件产生报表的规范。当用户执行“mvn site”，这些报表就会运行。 在页面导航栏能看到所有报表的链接。 --&gt; &lt;reporting&gt; &lt;!-- true，则，网站不包括默认的报表。这包括“项目信息”菜单中的报表。 --&gt; &lt;excludeDefaults/&gt; &lt;!-- 所有产生的报表存放到哪里。默认值是$&#123;project.build.directory&#125;/site。 --&gt; &lt;outputDirectory/&gt; &lt;!-- 使用的报表插件和他们的配置。 --&gt; &lt;plugins&gt; &lt;!-- plugin元素包含描述报表插件需要的信息 --&gt; &lt;plugin&gt; &lt;!-- 报表插件在仓库里的group ID --&gt; &lt;groupId/&gt; &lt;!-- 报表插件在仓库里的artifact ID --&gt; &lt;artifactId/&gt; &lt;!-- 被使用的报表插件的版本（或版本范围） --&gt; &lt;version/&gt; &lt;!-- 任何配置是否被传播到子项目 --&gt; &lt;inherited/&gt; &lt;!-- 报表插件的配置 --&gt; &lt;configuration/&gt; &lt;!-- 一组报表的多重规范，每个规范可能有不同的配置。一个规范（报表集）对应一个执行目标 。例如，有1，2，3，4，5，6，7，8，9个报表。1，2，5构成A报表集，对应一个执行目标。2，5，8构成B报表集，对应另一个执行目标 --&gt; &lt;reportSets&gt; &lt;!-- 表示报表的一个集合，以及产生该集合的配置 --&gt; &lt;reportSet&gt; &lt;!-- 报表集合的唯一标识符，POM继承时用到 --&gt; &lt;id/&gt; &lt;!-- 产生报表集合时，被使用的报表的配置 --&gt; &lt;configuration/&gt; &lt;!-- 配置是否被继承到子POMs --&gt; &lt;inherited/&gt; &lt;!-- 这个集合里使用到哪些报表 --&gt; &lt;reports/&gt; &lt;/reportSet&gt; &lt;/reportSets&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/reporting&gt; &lt;!-- 继承自该项目的所有子项目的默认依赖信息。这部分的依赖信息不会被立即解析,而是当子项目声明一个依赖（必须描述group ID和artifact ID信息），如果group ID和artifact ID以外的一些信息没有描述，则通过group ID和artifact ID匹配到这里的依赖，并使用这里的依赖信息。 --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;!-- 参见dependencies/dependency元素 --&gt; &lt;dependency&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!-- 项目分发信息，在执行mvn deploy后表示要发布的位置。有了这些信息就可以把网站部署到远程服务器或者把构件部署到远程仓库。 --&gt; &lt;distributionManagement&gt; &lt;!-- 部署项目产生的构件到远程仓库需要的信息 --&gt; &lt;repository&gt; &lt;!-- 是分配给快照一个唯一的版本号（由时间戳和构建流水号）？还是每次都使用相同的版本号？参见repositories/repository元素 --&gt; &lt;uniqueVersion/&gt; &lt;id&gt;banseon-maven2&lt;/id&gt; &lt;name&gt;banseon maven2&lt;/name&gt; &lt;url&gt;file://$&#123;basedir&#125;/target/deploy&lt;/url&gt; &lt;layout/&gt; &lt;/repository&gt; &lt;!-- 构件的快照部署到哪里？如果没有配置该元素，默认部署到repository元素配置的仓库，参见distributionManagement/repository元素 --&gt; &lt;snapshotRepository&gt; &lt;uniqueVersion/&gt; &lt;id&gt;banseon-maven2&lt;/id&gt; &lt;name&gt;Banseon-maven2 Snapshot Repository&lt;/name&gt; &lt;url&gt;scp://svn.baidu.com/banseon:/usr/local/maven-snapshot&lt;/url&gt; &lt;layout/&gt; &lt;/snapshotRepository&gt; &lt;!-- 部署项目的网站需要的信息 --&gt; &lt;site&gt; &lt;!-- 部署位置的唯一标识符，用来匹配站点和settings.xml文件里的配置 --&gt; &lt;id&gt;banseon-site&lt;/id&gt; &lt;!-- 部署位置的名称 --&gt; &lt;name&gt;business api website&lt;/name&gt; &lt;!-- 部署位置的URL，按protocol://hostname/path形式 --&gt; &lt;url&gt; scp://svn.baidu.com/banseon:/var/www/localhost/banseon-web &lt;/url&gt; &lt;/site&gt; &lt;!-- 项目下载页面的URL。如果没有该元素，用户应该参考主页。使用该元素的原因是：帮助定位那些不在仓库里的构件（由于license限制）。 --&gt; &lt;downloadUrl/&gt; &lt;!-- 如果构件有了新的group ID和artifact ID（构件移到了新的位置），这里列出构件的重定位信息。 --&gt; &lt;relocation&gt; &lt;!-- 构件新的group ID --&gt; &lt;groupId/&gt; &lt;!-- 构件新的artifact ID --&gt; &lt;artifactId/&gt; &lt;!-- 构件新的版本号 --&gt; &lt;version/&gt; &lt;!-- 显示给用户的，关于移动的额外信息，例如原因。 --&gt; &lt;message/&gt; &lt;/relocation&gt; &lt;!-- 给出该构件在远程仓库的状态。不得在本地项目中设置该元素，因为这是工具自动更新的。有效的值有：none（默认），converted（仓库管理员从Maven 1 POM转换过来），partner（直接从伙伴Maven 2仓库同步过来），deployed（从Maven 2实例部署），verified（被核实时正确的和最终的）。 --&gt; &lt;status/&gt; &lt;/distributionManagement&gt; &lt;!-- 以值替代名称，Properties可以在整个POM中使用，也可以作为触发条件（见settings.xml配置文件里activation元素的说明）。格式是&lt;name&gt;value&lt;/name&gt;。 --&gt; &lt;properties/&gt;&lt;/project&gt;","tags":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/tags/Maven/"}],"categories":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/categories/Maven/"}]},{"title":"Maven常用","date":"2018-01-19T16:00:00.000Z","path":"Blog/Maven/Maven常用/","text":"本地Jar包发布将本地的jar包发布到本地的Maven仓库中，-Dfile是需要上传的jar包的绝对路径,-DgroupId构成该jar包在pom.xml的坐标对应&lt;groupId&gt;标签的内容，-DartifactId构成该jar包在pom.xml的坐标对应&lt;artifactId&gt;标签的内容，-Dversion依赖包的版本对应&lt;version&gt;标签的内容，-Dpackaging安装文件的种类。 123456mvn install:install-file -Dfile=E:\\activation-1.0.2.jar -DgroupId=javax.activation -DartifactId=activation -Dversion=1.0.2 -Dpackaging=jar 在项目中使用搭建的私服123456789101112131415161718192021222324252627&lt;repositories&gt; &lt;repository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;nexus&lt;/name&gt; &lt;url&gt;http://192.168.100.10/nexus/content/groups/public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt;&lt;/repositories&gt;&lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;nexus&lt;/id&gt; &lt;name&gt;nexus&lt;/name&gt; &lt;url&gt;http://192.168.100.10/nexus/content/groups/public/&lt;/url&gt; &lt;releases&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/releases&gt; &lt;snapshots&gt; &lt;enabled&gt;true&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/pluginRepository&gt;&lt;/pluginRepositories&gt; Maven打包时跳过测试12345678&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;version&gt;2.18.1&lt;/version&gt; &lt;configuration&gt; &lt;skipTests&gt;true&lt;/skipTests&gt; &lt;/configuration&gt; &lt;/plugin&gt; mvn install -DskipTests mvn install -Dmaven.test.skip=true 使用本地依赖1234567&lt;dependency&gt; &lt;groupId&gt;com&lt;/groupId&gt; &lt;artifactId&gt;rt&lt;/artifactId&gt; &lt;version&gt;1.0&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;$&#123;basedir&#125;/src/main/webapp/WEB-INF/lib/rt.jar&lt;/systemPath&gt;&lt;/dependency&gt;","tags":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/tags/Maven/"}],"categories":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/categories/Maven/"}]},{"title":"Maven常用插件","date":"2018-01-19T16:00:00.000Z","path":"Blog/Maven/Maven常用插件/","text":"打jar包插件Maven提供了三种打包插件： maven-jar-plugin：Maven默认打包插件，用来创建Project JAR maven-shade-plugin：用来打可执行包，fat Jar maven-assembly-plugin：定制化打包 12345678910111213141516&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;!-- 指定添加项目中使用的外部jar的classpath项 --&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;!-- 指定外部jar所在的路径 --&gt; &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt; &lt;!-- 指定本项目jar包的Main-Class --&gt; &lt;mainClass&gt;com.long.ent.DemoApplication&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt;&lt;/plugin&gt; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt; &lt;version&gt;2.4.1&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;shade&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;createDependencyReducedPom&gt;false&lt;/createDependencyReducedPom&gt; &lt;transformers&gt; &lt;transformer implementation=\"org.apache.maven.plugins.shade.resource.AppendingTransformer\"&gt; &lt;resource&gt;META-INF/spring.schemas&lt;/resource&gt; &lt;/transformer&gt; &lt;transformer implementation=\"org.apache.maven.plugins.shade.resource.AppendingTransformer\"&gt; &lt;resource&gt;META-INF/spring.handlers&lt;/resource&gt; &lt;/transformer&gt; &lt;transformer implementation=\"org.springframework.boot.maven.PropertiesMergingResourceTransformer\"&gt; &lt;resource&gt;META-INF/spring.factories&lt;/resource&gt; &lt;/transformer&gt; &lt;!--&lt;transformer implementation=\"org.apache.maven.plugins.shade.resource.ComponentsXmlResourceTransformer\"/&gt;--&gt; &lt;transformer implementation=\"org.apache.maven.plugins.shade.resource.ServicesResourceTransformer\"/&gt; &lt;transformer implementation=\"org.apache.maven.plugins.shade.resource.ManifestResourceTransformer\"&gt; &lt;mainClass&gt;com.icloud.DemoApplication&lt;/mainClass&gt; &lt;/transformer&gt; &lt;transformer implementation=\"com.github.edwgiz.mavenShadePlugin.log4j2CacheTransformer.PluginsCacheFileTransformer\" /&gt; &lt;/transformers&gt; &lt;filters&gt; &lt;filter&gt; &lt;artifact&gt;*:*&lt;/artifact&gt; &lt;excludes&gt; &lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt; &lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt; &lt;/excludes&gt; &lt;/filter&gt; &lt;/filters&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;com.github.edwgiz&lt;/groupId&gt; &lt;artifactId&gt;maven-shade-plugin.log4j2-cachefile-transformer&lt;/artifactId&gt; &lt;version&gt;2.6.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/plugin&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt; &lt;mainClass&gt;com.icloud.DemoApplication&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;!--执行器 mvn assembly:assembly--&gt; &lt;execution&gt; &lt;id&gt;make-jar&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt;&lt;!-- 只运行一次 --&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;skipAssembly&gt;false&lt;/skipAssembly&gt; &lt;appendAssemblyId&gt;false&lt;/appendAssemblyId&gt; &lt;finalName&gt;ex-$&#123;assembly.finalName&#125;&lt;/finalName&gt; &lt;descriptors&gt; &lt;!--描述文件路径--&gt; &lt;descriptor&gt;$&#123;assembly.descriptor1&#125;&lt;/descriptor&gt; &lt;/descriptors&gt; &lt;outputDirectory&gt;$&#123;assembly.outputDirectory&#125;&lt;/outputDirectory&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;execution&gt; &lt;id&gt;make-tar&lt;/id&gt; &lt;phase&gt;install&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt;&lt;!-- 只运行一次 --&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;skipAssembly&gt;false&lt;/skipAssembly&gt; &lt;appendAssemblyId&gt;false&lt;/appendAssemblyId&gt; &lt;finalName&gt;$&#123;assembly.finalName&#125;&lt;/finalName&gt; &lt;descriptors&gt; &lt;!--描述文件路径--&gt; &lt;descriptor&gt;$&#123;project.basedir&#125;/common_tar.xml&lt;/descriptor&gt; &lt;/descriptors&gt; &lt;outputDirectory&gt;$&#123;assembly.outputDirectory&#125;&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 将依赖打入jar包123456789101112131415161718192021222324&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt; &lt;configuration&gt; &lt;descriptorRefs&gt; &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt; &lt;/descriptorRefs&gt; &lt;archive&gt; &lt;manifest&gt; &lt;mainClass&gt;com.icloud.ICloudApplication&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;make-assembly&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;single&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; 打war包插件12345678910111213141516171819202122&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;addMavenDescriptor&gt;false&lt;/addMavenDescriptor&gt; &lt;/archive&gt; &lt;warName&gt;project_name&lt;/warName&gt; &lt;webResources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources/spring/config/$&#123;config&#125;&lt;/directory&gt; &lt;targetPath&gt;WEB-INF/classes/spring/config&lt;/targetPath&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;targetPath&gt;WEB-INF/classes&lt;/targetPath&gt; &lt;filtering&gt;true&lt;/filtering&gt; &lt;/resource&gt; &lt;/webResources&gt; &lt;/configuration&gt;&lt;/plugin&gt; 编译源代码插件123456789&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt;&lt;/plugin&gt; 测试插件JUnit可以通过@Ignore注解标记忽略测试方法。Java中主流的单元测试框架为JUnit和TestNG。maven-surefire-plugin插件时测试运行器，它所作的只是在构建执行到特定声明周期阶段时，来执行JUnit或者TestNG的测试用例。 default生命周期中的test阶段被定义为使用单元测试框架运行测试。maven-surefire-plugin插件的test目标的内置绑定就是test阶段。 默认情况下，maven-surefire-plugin插件的test目标会自动执行测试源码路径下（默认为src/test/java/）所有符合一组命名模式的测试类: **Test*.java : 任何子目录下所有命名以Test开头的Java类 **/*Test.java：任何子目录下所有命名以Test结尾的Java类 **/*TestCase.java：任何子目录下所有命名以TestCase结尾的Java类 以Tests结尾的测试类时不会得以自动执行的。 mvn package -DskipTests命令或者配置maven-surefire-plugin插件的&lt;skipTests&gt;true&lt;/skipTests&gt;可以跳过测试，但不会跳过测试代码的编译。 mvn package -Dmaven.test.skip=true命令不仅会跳过测试，还会跳过测试代码的编译。maven.test.skip参数同时控制了maven-compiler-plugin和maven-surefire-plugin两个插件的行为。 还可以通过mvn test -Dtest = Random*Test,AccountTest命令指定执行的测试文件。 123456789101112131415161718&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;!-- Sets the VM argument line used when unit tests are run. --&gt; &lt;argLine&gt;$&#123;surefireArgLine&#125;&lt;/argLine&gt; &lt;!-- Maven打包时跳过测试 --&gt; &lt;skipTests&gt;true&lt;/skipTests&gt; &lt;testFailureIgnore&gt;true&lt;/testFailureIgnore&gt; &lt;excludes&gt; &lt;exclude&gt;com.proto.core.services.it.**&lt;/exclude&gt; &lt;/excludes&gt; &lt;includes&gt; &lt;include&gt;com.proto.core.services.ut.*&lt;/include&gt; &lt;include&gt;com.proto.core.services.ut.web.*&lt;/include&gt; &lt;/includes&gt; &lt;/configuration&gt;&lt;/plugin&gt; 依赖复制插件1234567891011121314151617&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;version&gt;2.10&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;copy-dependencies&lt;/id&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;copy-dependencies&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;outputDirectory&gt;$&#123;project.build.directory&#125;/lib&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt; Tomcat插件1234567891011&lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;uriEncoding&gt;utf-8&lt;/uriEncoding&gt; &lt;port&gt;8080&lt;/port&gt; &lt;path&gt;/&lt;/path&gt; &lt;username&gt;admin&lt;/username&gt; &lt;password&gt;admin&lt;/password&gt; &lt;/configuration&gt;&lt;/plugin&gt; Jetty插件12345678910111213141516&lt;plugin&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-maven-plugin&lt;/artifactId&gt; &lt;version&gt;9.2.21.v20170120&lt;/version&gt; &lt;configuration&gt; &lt;webApp&gt; &lt;contextPath&gt;/ccps&lt;/contextPath&gt; &lt;/webApp&gt; &lt;stopKey&gt;exit&lt;/stopKey&gt; &lt;stopPort&gt;9090&lt;/stopPort&gt; &lt;scanIntervalSeconds&gt;1&lt;/scanIntervalSeconds&gt; &lt;httpConnector&gt; &lt;port&gt;28074&lt;/port&gt; &lt;/httpConnector&gt; &lt;/configuration&gt;&lt;/plugin&gt; 资源文件处理插件123456789101112&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-resources-plugin&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt; &lt;configuration&gt; &lt;delimiters&gt; &lt;!-- @符号为结束符号,遇到就表示结束过滤 --&gt; &lt;delimiter&gt;@&lt;/delimiter&gt; &lt;/delimiters&gt; &lt;useDefaultDelimiters&gt;false&lt;/useDefaultDelimiters&gt; &lt;/configuration&gt;&lt;/plugin&gt; 默认主资源文件目录为src/main/resources，需要添加额外的资源文件目录，可通过配置maven-resources-plugin插件来实现 XSD到Java文件的自动生成插件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475&lt;!-- 将XSD文件自动生成POJO对象，每次变更用Maven重新编译一下 --&gt;&lt;plugin&gt; &lt;groupId&gt;org.jvnet.jaxb2.maven2&lt;/groupId&gt; &lt;artifactId&gt;maven-jaxb2-plugin&lt;/artifactId&gt; &lt;version&gt;0.14.0&lt;/version&gt; &lt;configuration&gt; &lt;schemaDirectory&gt;src/main/resources/xsd&lt;/schemaDirectory&gt; &lt;generateDirectory&gt;src/main/java/&lt;/generateDirectory&gt; &lt;packageLevelAnnotations&gt;false&lt;/packageLevelAnnotations&gt; &lt;noFileHeader&gt;true&lt;/noFileHeader&gt; &lt;episode&gt;false&lt;/episode&gt; &lt;readOnly&gt;true&lt;/readOnly&gt; &lt;!-- 如果不加生成的类注释会中文乱码 --&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;!-- 设置生成的类的注解语言en为英文 --&gt; &lt;locale&gt;en&lt;/locale&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;xsd1-generate&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;generate&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;args&gt; &lt;!-- 使用XJC给生成Java类添加注解 --&gt; &lt;arg&gt;-Xannotate&lt;/arg&gt; &lt;!-- 使用XJC给生成Java类添加父类 --&gt; &lt;arg&gt;-Xinheritance&lt;/arg&gt; &lt;!-- 给生成Java类添加equals方法 --&gt; &lt;arg&gt;-Xequals&lt;/arg&gt; &lt;!-- 给生成Java类添加hashCode方法 --&gt; &lt;arg&gt;-XhashCode&lt;/arg&gt; &lt;arg&gt;-Xvalue-constructor&lt;/arg&gt; &lt;arg&gt;-nv&lt;/arg&gt; &lt;/args&gt; &lt;extension&gt;true&lt;/extension&gt; &lt;schemaIncludes&gt; &lt;include&gt;test.xsd&lt;/include&gt; &lt;/schemaIncludes&gt; &lt;bindingIncludes&gt; &lt;include&gt;test.xjb&lt;/include&gt; &lt;/bindingIncludes&gt; &lt;generatePackage&gt;com.test.support.xml&lt;/generatePackage&gt; &lt;plugins&gt; &lt;!-- 基础插件依赖 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.jvnet.jaxb2_commons&lt;/groupId&gt; &lt;artifactId&gt;jaxb2-basics&lt;/artifactId&gt; &lt;version&gt;1.11.1&lt;/version&gt; &lt;/plugin&gt; &lt;!-- -Xequals和-XhashCode参数用于生成equals和hashcode方法使用 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.jvnet.jaxb2_commons&lt;/groupId&gt; &lt;artifactId&gt;jaxb2-value-constructor&lt;/artifactId&gt; &lt;version&gt;3.0&lt;/version&gt; &lt;/plugin&gt; &lt;!-- 使用XJC给生成Java类添加注解 --&gt; &lt;plugin&gt; &lt;groupId&gt;org.jvnet.jaxb2_commons&lt;/groupId&gt; &lt;artifactId&gt;jaxb2-basics-annotate&lt;/artifactId&gt; &lt;version&gt;1.0.2&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.22&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/plugin&gt; 每次变更Schema后通过Maven编译一下即可，若有多个Schema文件且需要将生成的POJO放置不同的目录下，只需要添加多个execution即可。 XSLT转换插件12345678910111213141516171819202122232425262728293031&lt;plugin&gt; &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt; &lt;artifactId&gt;xml-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.0.2&lt;/version&gt; &lt;configuration&gt; &lt;transformationSets&gt; &lt;transformationSet&gt; &lt;dir&gt;src/main/resources/xsd&lt;/dir&gt; &lt;includes&gt;test.xsd&lt;/includes&gt; &lt;outputDir&gt;target/transformed-schema&lt;/outputDir&gt; &lt;stylesheet&gt;src/main/resources/xsl/test.xsl&lt;/stylesheet&gt; &lt;/transformationSet&gt; &lt;transformationSet&gt; &lt;dir&gt;src/main/resources/xsd&lt;/dir&gt; &lt;includes&gt;test.xjb&lt;/includes&gt; &lt;outputDir&gt;target/transformed-jaxb-schema&lt;/outputDir&gt; &lt;stylesheet&gt;src/main/resources/xsl/test-jaxb.xsl&lt;/stylesheet&gt; &lt;/transformationSet&gt; &lt;/transformationSets&gt; &lt;/configuration&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;xslt-generate&lt;/id&gt; &lt;!-- 将该插件的生命周期绑定到compile上 --&gt; &lt;phase&gt;compile&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;transform&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt;&lt;/plugin&gt;","tags":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/tags/Maven/"}],"categories":[{"name":"Maven","slug":"Maven","permalink":"https://yaoyinglong.github.io/categories/Maven/"}]},{"title":"Class文件结构","date":"2018-01-19T16:00:00.000Z","path":"Blog/Java/VM/Class文件结构/","text":"各种不同平台的虚拟机与平台都统一使用的程序存储格式——字节码是构成平台无关性的基石。 虚拟机也是语言无关的，实现语言无关性的基础任然是虚拟机和字节码存储格式。Java虚拟机不和包括Java在内的任何语言绑定，它只与Class文件这种特定的二进制文件格式所关联，Class文件中包含Java虚拟机指令集和符号表以及若干其他辅助信息。 基于安全考虑Java虚拟机规范要求在Class文件中使用许多强制性的语法和结构化约束，任何一门功能性语言都可以表示为一个能被Java虚拟机所接受的有校Class文件。 Java语言中的各种变量、关键字和运算符号的语义最终都是由多条字节码命令组合而成的，因此字节码命令所能提供的语义描述能力肯定会比Java语言本身更强大。 Class类文件的结构任何一个Class文件都对应着唯一一个类或接口的定义信息，但类或接口并不一定都定义在文件中，也可以通过类加载器直接生成。 Class文件是一组以8位字节为基础单位的二进制流，各个数据项目严格按照顺序紧凑地排列在Class文件中无任何分割符，Class文件中存储的内容几乎全部是程序运行的必要数据，当遇到需要占用8位字节以上空间的数据项时，按照高位在前的方式分割成若干8位字节进程存储。 Class文件格式采用一种类似C语言结构体的伪结构来存储数据，这种伪结构中只有无符号数和表两种数据类型。 无符号数属于基本的数据类型，以u1、u2、u4、u8来分别代表1、2、4、8个字节的无符号数，无符号数可以用来描述数字、索引引用、数量值或者按照UTF-8编码构成字符串值。 表是由多个无符号数或者其他表作为数据项构成的符合数据类型，所有表都习惯地以_info结尾。表用于描述有层次关系的复合结构的数据，整个Class文件本质上就是一张表。 无论无符号数还是表，当需要描述同一类型但数量不定的多个数据时，经常会使用一个前置容量计数器加若干个连续数据项的形式，这时称这一系列连续的某一类型的数据为某一类型的集合。 类型 名称 数量 u4 magic 1 u2 minor_version 1 u2 major_version 1 u2 constant_pool_count 1 cp_info constant_pool constant_pool_count - 1 u2 access_flags 1 u2 this_class 1 u2 super_class 1 u2 interfaces_count 1 u2 interfaces interfaces_count u2 fields_count 1 field_info fields fields_count u2 methods_count 1 method_info methods methods_count u2 attribute_count 1 attribute_info attributes attributes_count 魔数与Class文件版本每个Class文件的头4个字节magic称为魔数，它唯一的作用是确定这个文件是否是一个能被虚拟机接受的Class文件。很多文件存储标准中都使用魔数来进行身份识别，譬如图片格式。Class文件的魔数值为0xCAFEBABE。 紧接着的魔数的4个字节minor_version和major_version存储的是Class文件的次版本号和主版本号。Java版本号是从45开始的，每个JDK大版本发布主版本号向上加1，高版本的JDK能向下兼容，但不能运行以后版本的Class文件，即使文件格式未发生变化，虚拟机也拒绝执行超过器版本号的Class文件。 123456public class com.coms.jvm.ClassFileConstantPool.ClassTest SourceFile: \"ClassTest.java\" minor version: 0 major version: 51 flags: ACC_PUBLIC, ACC_SUPERConstant pool: 静态常量池紧接着主次版本号之后的constant_pool_count和constant_pool是常量池入口，常量池可也理解为Class文件中的资源仓库，是Class文件结构中与其他项目关联最多的数据类型，也是Class文件中占用空间最大的数据项目之一，同时它还是在Class文件中第一个出现表类型数据的项目。 常量池中常量不是固定的，所以常量池的入口需要用一个u2类型的constant_pool_count来表示常量池容量计数值。容量计数是从1开始，目的在于满足后面某些指向常量池的索引值的数据在特定情况下需要表达不引用任何常量池项目时可以把索引值设置为0。Class文件结构中只有常量池的容量计数时从1开始，其他集合类型接口索引集合、字段表集合、方法表集合等容量计数都是从0开始。 常量池中主要存放字面量和符号引用两大类常量。字面量比较接近Java层面的常量，如文本字符串、声明为fianl的常量值等。符号引用属于编译原理方面的概念，包括类和接口的全限定名、字段和名称和描述符、方法的名称和描述符三类常量。 如果将ClassTest类放到com.jvm包下，则ClassTest类的全限定名为com.jvm.ClassTest。JVM编译器将类编译成class文件后，此全限定名在class文件中是以二进制形式存储的，它会把全限定符.换成/，即在class文件中存储的ClassTest类的全限定名是com/louis/jvm/ClassTest。 Java代码在进行Javac编译时，在Class文件中不会保存各个方法、字段的内存布局信息，这些字段、方法的符号引用不经过运行期转换无法得到真正的内存入口地址，也无法直接被虚拟机使用，在虚拟机加载Class文件的时候进行动态连接。虚拟机运行时需要从常量池获得对应的符号引用，在类创建时或运行时解析、翻译到具体的内存地址中。 常量池中每一项常量都是一个表，JDK1.7中共14种表，且这14种表各自均有自己的结构，这14种表有一个共同特点开始的第一位是一个u1类型的标志位tag，代表当前常量属于哪种常量类型。下表是14种常量类型所代表的具体含义： 类型 标志 描述 CONSTANT_Utf8_info 1 UTF-8编码的字符串 CONSTANT_Integer_info 3 整形字面量 CONSTANT_Float_info 4 浮点型字面量 CONSTANT_Long_info 5 长整型字面量 CONSTANT_Double_info 6 双精度浮点型字面量 CONSTANT_Class_info 7 类或接口的符号引用 CONSTANT_String_info 8 字符串类型字面量 CONSTANT_Fieldref_info 9 字段的符号引用 CONSTANT_Methodref_info 10 类中方法的符号引用 CONSTANT_InterfaceMethodref_info 11 接口中方法的符号引用 CONSTANT_NameAndType_info 12 字段或方法的部分符号引用 CONSTANT_MethodHandle_info 15 表示方法句柄 CONSTANT_MothodType_info 16 标识方法类型 CONSTANT_InvokeDynamic_info 18 表示一个动态方法调用点 CONSTANT_Class_info型常量的结构如下表所示，tag是标志位用于区分常量类型，name_index是一个索引值，它指向常量池中一个CONSTANT_Utf8_info类型常量，代表该类或接口的全局限定名。 类型 名称 数量 u1 tag 1 u2 name_index 1 CONSTANT_Utf8_info型常量的结构如下表所示，tag是标志位用于区分常量类型，length值表示UTF-8编码的字符串长度的字节数，紧跟着的长度位length字节的连续数据是一个使用UTF-8缩略编码表示的字符串。 UTF-8缩略编码与普通编码的区别是从\\u0001到\\u007f之间的字符的缩略编码使用一个字节表示，从\\u0080到\\u00ff之间的字符的缩略编码使用两个字节表示，从\\u0800到\\uffff之间的字符的缩略编码按照普通UTF-8编码规则使用三个字节表示。 Class文件中方法、字段等都需要引用CONSTANT_Utf8_info型常量来描述名称，所以CONSTANT_Utf8_info型常量的最大长度就是Java中方法、字段名的最大长度，这里的长度就是length的最大值，即u2类型能表达的最大值65535，故Java程序中变量、方法名的定义不能超过64KB英文字符，否则将无法被编译。 类型 名称 数量 u1 tag 1 u2 length 1 u1 bytes length 123456789101112131415161718Constant pool: #1 = Methodref #3.#15 // java/lang/Object.\"&lt;init&gt;\":()V #2 = Class #16 // com/coms/jvm/ClassFileConstantPool/ClassTest #3 = Class #17 // java/lang/Object #4 = Utf8 date #5 = Utf8 Ljava/util/Date; #6 = Utf8 &lt;init&gt; #7 = Utf8 ()V #8 = Utf8 Code #9 = Utf8 LineNumberTable #10 = Utf8 LocalVariableTable #11 = Utf8 this #12 = Utf8 Lcom/coms/jvm/ClassFileConstantPool/ClassTest; #13 = Utf8 SourceFile #14 = Utf8 ClassTest.java #15 = NameAndType #6:#7 // \"&lt;init&gt;\":()V #16 = Utf8 com/coms/jvm/ClassFileConstantPool/ClassTest #17 = Utf8 java/lang/Object 其中&lt;init&gt;为编译器添加的实例构造器。 访问标志紧接着常量池之后的u2类型的access_flags是访问标志，用于识别一些类或接口层次的访问信息，包括该Class是类还是接口，是否定义为public类型，是否定义位abstract类型，如果是类是否被修饰为final等。 标志名 标志值 标志含义 针对的对像 ACC_PUBLIC 0x0001 是否为public类型 所有类型 ACC_FINAL 0x0010 是否为final类型 类 ACC_SUPER 0x0020 是否允许使用invokespecial字节码指令的新语义 类和接口 ACC_INTERFACE 0x0200 标识为接口类型 接口 ACC_ABSTRACT 0x0400 是否为抽象类型 类和接口 ACC_SYNTHETIC 0x1000 标识该类不由用户代码生成 所有类型 ACC_ANNOTATION 0x2000 标识为注解类型 注解 ACC_ENUM 0x4000 标识为枚举类型 枚举 access_flags中一共有16个标志位可以使用，当前只定义了其中8个，没有使用到的标志位要求一律为0。当JVM在编译某个类或者接口的源代码时，JVM会解析出这个类或者接口的访问标志信息，然后将这些标志设置到访问标志。 123456public class com.coms.jvm.ClassFileConstantPool.ClassTest SourceFile: \"ClassTest.java\" minor version: 0 major version: 51 flags: ACC_PUBLIC, ACC_SUPERConstant pool: 索引在Class文件中的索引包括类索引、父类索引、接口索引集合,Class文件中由这三项数据来确定该类的继承关系。类索引和父类索引都是u2类型的数据，接口索引集合是一组u2类型的数据集合。 类索引用于确定该类的全限定名，父类索引用于确定该类的父类的全限定名,接口索引集合用于描述该类实现了哪些接口。 类索引、父类索引和接口索引集合都按顺序排列在访问标志之后，类索引和父类索引他们各自指向一个CONSTANT_Class_info型常量，通过CONSTANT_Class_info类型的常量中的name_index索引值可以找到定义在CONSTANT_Utf8_info类型的常量中的全限定名字符串。 对于接口索引集合，入口的u2类型的数据为接口计数器interfaces_count，表示索引表的容量。如果该类没有实现任何接口，则该计数器值为0，后面接口的索引表不再占用任何字节。 字段表集合字段表用于描述接口或类中声明的变量，包括字段的作用域public、private、protected、是实例变量还是类变量static、可变性final、并发可见性volatile、可否被序列化transient、字段数据类型（基本数据类型、数组、对象）、字段名称，字段包括类变量、实例变量，但是不包括方法内部声明的局部变量。 修饰符都是布尔值使用标志位来表示，放在access_flags项目中，字段名字被定义为什么数据类型引用常量池中的常量来描述，name_index和descriptor_index都是对常量池的引用，分别代表着字段的简单名称以及字段和方法的描述符。简单名称是指没有类型和参数的修饰的方法或字段名称，描述符是用来描述字段的数据类型、方法的参数列表，包括数量、类型、顺序和返回值。 类型 名称 数量 ｕ2 access_flags 1 ｕ2 name_index 1 ｕ2 descriptor_index 1 ｕ2 attributes_count 1 attribute_info attributes attributes_count ACC_PUBLIC、ACC_PRIVATE、ACC_PROTECTED三个标志最多只能选择其一，ACC_FINAL、ACC_VOLATILE不能同时选择，接口中必须有ACC_PUBLIC、ACC_STATIC、ACC_FINAL标志。 标志名称 标志值 含义 ACC_PUBLIC 0x0001 字段是否为public ACC_PRIVATE 0x0002 字段是否为private ACC_PROTECTED 0x0004 字段是否为protected ACC_STATIC 0x0008 字段是否为static ACC_FINAL 0x0010 字段是否为final ACC_VOLATILE 0x0040 字段是否为volatile ACC_TRANSTENT 0x0080 字段是否为transient ACC_SYNCHETIC 0x1000 字段是否为由编译器自动产生 ACC_ENUM 0x4000 字段是否为enum 基本数据类型byte、char、double、float、int、long、short、boolean以及代表无返回值的void类型都用一个大写字符来表示，对象类型用字符L加对象的全限定名来表示。 数组类型每个维度将使用一个前置的[字符来描述，如果定义一个java.lang.String[][]类型的二维数组，将被记录为[[Ljava.lang.String,整形的int[]将被记为[I。用描述符来描述方法时，按照先参数列表后放回值的顺序描述，参数列表按照参数的严格顺序放在一个小括号()内，如方法String desc(char[] a, int b,long[] c)的描述符为([CI[J)Ljava/lang/String;。 标志符 含义 B 基本数据类型byte C 基本数据类型char D 基本数据类型double F 基本数据类型float I 基本数据类型int J 基本数据类型long S 基本数据类型short Z 基本数据类型boolean V 基本数据类型void L 对象类型 字段表集合中不会列出从超类或者父接口中继承而来的字段，但有可能列出Java代码中不存在的字段，譬如在内部类中为了保持对外部类的访问性，会自动添加指向外部类实例的字段。 Java语言字段是无法重载的，两个字段的数据类型、修饰符不管是否相同，都必须使用不一样的名称，但对字节码来说，两个字段的描述符不一致字段的重名是合法的。 方法表集合Class文件存储格式中对方法的描述与对字段的描述几乎采用了完全一致的方法，方法表的结构如同字段表一样，依次是访问标志、名称索引、描述符索引、属性表集合。这些数据项目含义非常类似，仅访问标志和属性表集合的可选项中所有区别。 类型 名称 数量 ｕ2 access_flags 1 ｕ2 name_index 1 ｕ2 descriptor_index 1 ｕ2 attributes_count 1 attribute_info attributes attributes_count 方法里的Java代码经过编译器编译成字节码指令后，存放在方法属性表集合中一个名为Code的属性里，属性表作为Class文件格式中最具扩展性的一种数据项目。 标志名称 标志值 含义 ACC_PUBLIC 0x0001 方法是否为public ACC_PRIVATE 0x0002 方法是否为private ACC_PROTECTED 0x0004 方法是否为protected ACC_STATIC 0x0008 方法是否为static ACC_FINAL 0x0010 方法是否为final ACC_SYHCHRONRIZED 0x0020 方法是否为synchronized ACC_BRIDGE 0x0040 方法是否是有编译器产生的方法 ACC_VARARGS 0x0080 方法是否接受参数 ACC_NATIVE 0x0100 方法是否为native ACC_ABSTRACT 0x0400 方法是否为abstract ACC_STRICTFP 0x0800 方法是否为strictfp ACC_SYNTHETIC 0x1000 方法是否是有编译器自动产生的 如果父类方法在子类中没有被重写，方法表集合中就不会出现来自父类的方法信息，但有可能会出现由编译器自动添加的方法，最典型的就是类构造器&lt;clinit&gt;方法和实例构造器&lt;init&gt;方法。 在Java中要重载一个方法，除了要与原方法具有相同的简单名称之外，还要求必须拥有一个与原方法不同的特征签名，特征签名就是一个方法中各个参数在常量池中字段符号引用的集合，由于返回值不包含在特征签名中，故Java中无法仅仅依靠返回值来重载方法。但在Class文件中，特征签名范围更大，只要描述符不完全一致的两个方法也可以共存，两个方法有相同名称和特征值但返回值不同，就可以合法共存一个Class文件中。 属性表集合","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"内存分配与回收策略","date":"2018-01-16T16:00:00.000Z","path":"Blog/Java/VM/内存非配与回收策略/","text":"Java体系技术中所提倡的自动内存管理最终可以归结为自动化地解决两个问题：给对象分配内存以及回收分配给对象的内存。 对象的内存分配，往大的方向讲就是在堆上分配，但也可能经过JIT编译后被拆散为标量类型并间接地在栈上分配，对象主要分配在新生代的Eden区上，如果启动了本地线程分配缓冲，就按线程优先在TLAB上分配，少数情况下可能直接分配在老年代中。 大对象直接进入老年代一般对象在新生代Eden区中分配，当Eden区没有足够空间时虚拟机将发起一次Minor GC。 -Xms20M -Xmx20M -Xmn10M -XX:+PrintGCDetails -XX:+UseSerialGC -XX:SurvivorRatio=8通过该参数限制Java堆大小为20M且不可扩展，10M为新生代10M为老年代，Eden空间和Survivor空间比例时8：1，Eden空间大小为8192K、From Survivor空间大小为1024K、To Survivor空间大小为1024K，新生代是Eden区加From Survivor区的总容量为9216K。12345678private static final int _1MB = 1024 * 1024;public static void main(String[] args) &#123; byte[] allocation1, allocation2, allocation3, allocation4; allocation1 = new byte[2 * _1MB]; allocation2 = new byte[2 * _1MB]; allocation3 = new byte[2 * _1MB]; allocation4 = new byte[4 * _1MB];&#125; 程序在给allocation4对象分配内存时，发现Eden空间已经被占用了6M，剩余空间已经不足分配给allocation4所需的内存，因此发生了Minor GC，在GC期间发现allocation1、allocation2、allocation3都无法放入Survivor空间，只能通过分配担保机制提前转移到老年代中。所以GC结束后Eden空间被占用4M、Survivor空间空闲、老年代被占用6M。 1234567891011[GC[DefNew: 7669K-&gt;547K(9216K), 0.0048823 secs] 7669K-&gt;6691K(19456K), 0.0049234 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] Heap def new generation total 9216K, used 5136K [0x00000000f9a00000, 0x00000000fa400000, 0x00000000fa400000) eden space 8192K, 56% used [0x00000000f9a00000, 0x00000000f9e7b610, 0x00000000fa200000) from space 1024K, 53% used [0x00000000fa300000, 0x00000000fa388d40, 0x00000000fa400000) to space 1024K, 0% used [0x00000000fa200000, 0x00000000fa200000, 0x00000000fa300000) tenured generation total 10240K, used 6144K [0x00000000fa400000, 0x00000000fae00000, 0x00000000fae00000) the space 10240K, 60% used [0x00000000fa400000, 0x00000000faa00030, 0x00000000faa00200, 0x00000000fae00000) compacting perm gen total 21248K, used 2987K [0x00000000fae00000, 0x00000000fc2c0000, 0x0000000100000000) the space 21248K, 14% used [0x00000000fae00000, 0x00000000fb0eb120, 0x00000000fb0eb200, 0x00000000fc2c0000)No shared spaces configured. 大对象对虚拟机内存分配来说是一个坏消息，经常出现大对象容易导致还有部分内存就提前触发垃圾收集以获得足够的连续空间。 虚拟机可以通过-XX:PretenureSizeThreshold参数设置，大于该参数值的对象直接在老年代中分配内存，目的是为了避免在Eden区和两个Survivor区之间发生大量内存复制。但是该参数只对Serial和ParNew有效。 长期存活的对象将进入老年代虚拟机是通过给每个对象定义一个对象年龄计数器来是被新生代和老年代。 如果对象在Eden出生并经过一次Minor GC后任然存活且能被To Survivor容纳对象年龄将会被设置为1，每熬过一次Minor GC年龄就增加1，当年龄增加到一定程度（默认15岁），对象就会被晋升到老年代中。 对象晋升老年代的年龄法制可以通过-XX:MaxTenuringThreshold参数设置。 动态对象年龄判断虚拟机并不是永远地要求对象的年龄必须到达MaxTenuringThreshold才能晋升老年代，如果Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代。 空间分配担保在发生Minor GC之前，虚拟机会先检查老年代最大可用连续空间是否大于新生代所有对象总空间，如果成立Minor GC确保安全。 如果不成立虚拟机会查看HandlePromotionFailure设置是否允许担保失败。 如果允许会继续检查老年代最大可用连续空间是否大于历次晋升到老年代对象的平均大小，如果大于尝试进行一次Minor GC，如果小于或HandlePromotionFailure设置不允许冒险，这时将进行一次Full GC。 当然如果担保失败，也将在失败后重新发起一次Full GC。","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"理解GC日志","date":"2018-01-16T16:00:00.000Z","path":"Blog/Java/VM/理解GC日志/","text":"阅读GC日志是处理Java虚拟机内存问题的基础技能，每一种收集器的日志形式都是由他们自身的实现所决定的，所以每个收集器的日志格式都可以不一样，但虚拟机设计者为了方便用户阅读，将各个收集器的日志都维持一定的共性。下面是一段GC日志：1234567[GC [PSYoungGen: 23552K-&gt;3581K(27136K)] 23552K-&gt;16249K(88576K), 0.0185611 secs] [Times: user=0.08 sys=0.02, real=0.02 secs] [GC [PSYoungGen: 27133K-&gt;3560K(27136K)] 39801K-&gt;31030K(88576K), 0.0323523 secs] [Times: user=0.11 sys=0.01, real=0.03 secs] [GC [PSYoungGen: 27112K-&gt;3568K(27136K)] 54582K-&gt;54585K(88576K), 0.0363496 secs] [Times: user=0.16 sys=0.02, real=0.04 secs] [Full GC [PSYoungGen: 3568K-&gt;0K(27136K)] [ParOldGen: 51017K-&gt;47268K(61440K)] 54585K-&gt;47268K(88576K) [PSPermGen: 3169K-&gt;3168K(21504K)], 0.5726540 secs] [Times: user=1.78 sys=0.01, real=0.57 secs] [Full GC [PSYoungGen: 23552K-&gt;0K(27136K)] [ParOldGen: 47268K-&gt;60136K(61440K)] 70820K-&gt;60136K(88576K) [PSPermGen: 3168K-&gt;3168K(21504K)], 0.3987444 secs] [Times: user=1.41 sys=0.02, real=0.40 secs] [Full GC [PSYoungGen: 20624K-&gt;19567K(27136K)] [ParOldGen: 60136K-&gt;61132K(61440K)] 80761K-&gt;80700K(88576K) [PSPermGen: 3168K-&gt;3168K(21504K)], 0.8462723 secs] [Times: user=3.38 sys=0.05, real=0.85 secs] [Full GC [PSYoungGen: 19567K-&gt;19567K(27136K)] [ParOldGen: 61132K-&gt;61116K(61440K)] 80700K-&gt;80684K(88576K) [PSPermGen: 3168K-&gt;3168K(21504K)], 0.4721533 secs] [Times: user=2.83 sys=0.03, real=0.47 secs] GC日志开头的[GC和[Full GC说明这次垃圾收集的停顿类型，而不是用来区分新生代GC还是老年代GC。如果是调用System.gc()方法所触发的收集，这里就将显示[Full GC（System）。 接下来的[PSYoungGen、[ParOldGen、[PSPermGen表是GC发生的区域，区域名称与使用的GC收集器是密切相关的。 后面方括号内的23552K-&gt;3581K(27136K)表示GC前该内存区域已使用容量-&gt;GC后该内存区域已使用容量（该内存区域总容量） 方括号外的23552K-&gt;16249K(88576K)表示GC前Java堆已使用容量-&gt;GC后Java堆已使用容量（Java堆总容量） 0.0185611 secs表示该内存区域GC所占用的时间，单位秒。[Times: user=0.08 sys=0.02, real=0.02 secs]更具体的时间数据，这里的user、sys和real与Linux的time命令所输出的时间含义一致，分别代表CPU时间、内核态消耗的CPU事件和操作从开始到结束所经过的墙钟时间。 Serial &amp; Serial Old GC日志123456[GC[DefNew: 24234K-&gt;3072K(27648K), 0.0279728 secs] 24234K-&gt;16411K(89088K), 0.0280186 secs] [Times: user=0.03 sys=0.00, real=0.03 secs] [GC[DefNew: 27648K-&gt;3072K(27648K), 0.0348831 secs] 40987K-&gt;35255K(89088K), 0.0349111 secs] [Times: user=0.03 sys=0.00, real=0.04 secs] [GC[DefNew: 27648K-&gt;3072K(27648K), 0.0420056 secs] 59831K-&gt;59830K(89088K), 0.0420333 secs] [Times: user=0.05 sys=0.00, real=0.04 secs] [GC[DefNew: 27648K-&gt;27648K(27648K), 0.0000186 secs][Tenured: 56758K-&gt;61440K(61440K), 0.1322486 secs] 84406K-&gt;63429K(89088K), [Perm : 3169K-&gt;3169K(21248K)], 0.1323137 secs] [Times: user=0.14 sys=0.00, real=0.13 secs] [Full GC[Tenured: 61440K-&gt;61440K(61440K), 0.1457481 secs] 80851K-&gt;80700K(89088K), [Perm : 3169K-&gt;3169K(21248K)], 0.1457820 secs] [Times: user=0.16 sys=0.00, real=0.14 secs] [Full GC[Tenured: 61440K-&gt;61440K(61440K), 0.1661660 secs] 80700K-&gt;80684K(89088K), [Perm : 3169K-&gt;3168K(21248K)], 0.1661913 secs] [Times: user=0.16 sys=0.00, real=0.17 secs] [DefNew、[Tenured、[Perm分别表示年轻代、老年代和永久代。 ParNew &amp; serial Old GC日志123456[GC[ParNew: 24234K-&gt;3072K(27648K), 0.0240967 secs] 24234K-&gt;16475K(89088K), 0.0241453 secs] [Times: user=0.11 sys=0.00, real=0.02 secs] [GC[ParNew: 27648K-&gt;3072K(27648K), 0.0361463 secs] 41051K-&gt;35736K(89088K), 0.0362102 secs] [Times: user=0.19 sys=0.00, real=0.04 secs] [GC[ParNew: 27648K-&gt;3072K(27648K), 0.0369859 secs] 60312K-&gt;60003K(89088K), 0.0370325 secs] [Times: user=0.23 sys=0.00, real=0.04 secs] [GC[ParNew: 27648K-&gt;27648K(27648K), 0.0000158 secs][Tenured: 56931K-&gt;61440K(61440K), 0.1430511 secs] 84579K-&gt;63429K(89088K), [Perm : 3169K-&gt;3169K(21248K)], 0.1431067 secs] [Times: user=0.14 sys=0.00, real=0.14 secs] [Full GC[Tenured: 61440K-&gt;61440K(61440K), 0.1444908 secs] 80851K-&gt;80700K(89088K), [Perm : 3169K-&gt;3169K(21248K)], 0.1445358 secs] [Times: user=0.14 sys=0.00, real=0.14 secs] [Full GC[Tenured: 61440K-&gt;61440K(61440K), 0.1710500 secs] 80700K-&gt;80684K(89088K), [Perm : 3169K-&gt;3168K(21248K)], 0.1710760 secs] [Times: user=0.17 sys=0.00, real=0.17 secs] [ParNew、[Tenured、[Perm分别表示年轻代、老年代和永久代。 ParNew &amp; CMS（serial old为替补）GC日志1234567[GC[ParNew: 23938K-&gt;3072K(27648K), 0.0849733 secs] 23938K-&gt;21528K(89088K), 0.0850416 secs] [Times: user=0.53 sys=0.02, real=0.09 secs] [GC[ParNew: 27648K-&gt;3072K(27648K), 0.0363515 secs] 46104K-&gt;45931K(89088K), 0.0363863 secs] [Times: user=0.22 sys=0.05, real=0.04 secs] [GC [1 CMS-initial-mark: 42859K(61440K)] 46267K(89088K), 0.0020835 secs] [Times: user=0.00 sys=0.00, real=0.00 secs] [GC[ParNew: 27648K-&gt;27648K(27648K), 0.0000146 secs][CMS[CMS-concurrent-mark: 0.132/0.133 secs] [Times: user=0.17 sys=0.06, real=0.13 secs] (concurrent mode failure): 42859K-&gt;61439K(61440K), 0.2594182 secs] 70507K-&gt;66264K(89088K), [CMS Perm : 3170K-&gt;3169K(21248K)], 0.2594711 secs] [Times: user=0.31 sys=0.06, real=0.26 secs] [Full GC[CMS: 61439K-&gt;61439K(61440K), 0.1218246 secs] 71016K-&gt;70720K(89088K), [CMS Perm : 3169K-&gt;3169K(21248K)], 0.1218598 secs] [Times: user=0.13 sys=0.00, real=0.12 secs] [Full GC[CMS: 61439K-&gt;61440K(61440K), 0.1510773 secs] 70720K-&gt;70709K(89088K), [CMS Perm : 3169K-&gt;3169K(21248K)], 0.1511120 secs] [Times: user=0.14 sys=0.00, real=0.15 secs] [ParNew、[CMS、[Perm分别表示年轻代、老年代和永久代。其中(concurrent mode failure)表示CMS收集器无法处理浮动垃圾，出现了Concurrent Mode Failure失败而导致另一次Full GC产生，这时虚拟机就会启动后备预案，临时使用Serial Old收集器来重新进行老年代的垃圾收集。 Parallel Scavenge &amp; Parallel Old GC日志1234567[GC [PSYoungGen: 23552K-&gt;3581K(27136K)] 23552K-&gt;16249K(88576K), 0.0185611 secs] [Times: user=0.08 sys=0.02, real=0.02 secs] [GC [PSYoungGen: 27133K-&gt;3560K(27136K)] 39801K-&gt;31030K(88576K), 0.0323523 secs] [Times: user=0.11 sys=0.01, real=0.03 secs] [GC [PSYoungGen: 27112K-&gt;3568K(27136K)] 54582K-&gt;54585K(88576K), 0.0363496 secs] [Times: user=0.16 sys=0.02, real=0.04 secs] [Full GC [PSYoungGen: 3568K-&gt;0K(27136K)] [ParOldGen: 51017K-&gt;47268K(61440K)] 54585K-&gt;47268K(88576K) [PSPermGen: 3169K-&gt;3168K(21504K)], 0.5726540 secs] [Times: user=1.78 sys=0.01, real=0.57 secs] [Full GC [PSYoungGen: 23552K-&gt;0K(27136K)] [ParOldGen: 47268K-&gt;60136K(61440K)] 70820K-&gt;60136K(88576K) [PSPermGen: 3168K-&gt;3168K(21504K)], 0.3987444 secs] [Times: user=1.41 sys=0.02, real=0.40 secs] [Full GC [PSYoungGen: 20624K-&gt;19567K(27136K)] [ParOldGen: 60136K-&gt;61132K(61440K)] 80761K-&gt;80700K(88576K) [PSPermGen: 3168K-&gt;3168K(21504K)], 0.8462723 secs] [Times: user=3.38 sys=0.05, real=0.85 secs] [Full GC [PSYoungGen: 19567K-&gt;19567K(27136K)] [ParOldGen: 61132K-&gt;61116K(61440K)] 80700K-&gt;80684K(88576K) [PSPermGen: 3168K-&gt;3168K(21504K)], 0.4721533 secs] [Times: user=2.83 sys=0.03, real=0.47 secs] [PSYoungGen、[ParOldGen、[PSPermGen分别表示年轻代、老年代和永久代。 G1 收集器12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152[GC pause (young) (initial-mark), 0.0089815 secs] [Parallel Time: 8.7 ms, GC Workers: 8] [GC Worker Start (ms): Min: 1992.2, Avg: 1992.3, Max: 1992.3, Diff: 0.1] [Ext Root Scanning (ms): Min: 0.3, Avg: 0.3, Max: 0.3, Diff: 0.1, Sum: 2.5] [Update RS (ms): Min: 2.2, Avg: 2.8, Max: 3.8, Diff: 1.6, Sum: 22.8] [Processed Buffers: Min: 4, Avg: 4.9, Max: 6, Diff: 2, Sum: 39] [Scan RS (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0] [Object Copy (ms): Min: 4.5, Avg: 5.4, Max: 6.0, Diff: 1.6, Sum: 43.0] [Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.1, Diff: 0.1, Sum: 0.3] [GC Worker Other (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.1] [GC Worker Total (ms): Min: 8.6, Avg: 8.6, Max: 8.6, Diff: 0.1, Sum: 68.7] [GC Worker End (ms): Min: 2000.8, Avg: 2000.8, Max: 2000.8, Diff: 0.0] [Code Root Fixup: 0.0 ms] [Clear CT: 0.2 ms] [Other: 0.1 ms] [Choose CSet: 0.0 ms] [Ref Proc: 0.1 ms] [Ref Enq: 0.0 ms] [Free CSet: 0.0 ms] [Eden: 1024.0K(3072.0K)-&gt;0.0B(3072.0K) Survivors: 1024.0K-&gt;1024.0K Heap: 79.0M(90.0M)-&gt;81.8M(90.0M)] [Times: user=0.13 sys=0.00, real=0.01 secs] [GC concurrent-root-region-scan-start][GC pause (young)[GC concurrent-root-region-scan-end, 0.0001366 secs][GC concurrent-mark-start], 0.0030254 secs] [Root Region Scan Waiting: 0.1 ms] [Parallel Time: 2.7 ms, GC Workers: 8] [GC Worker Start (ms): Min: 2001.5, Avg: 2001.5, Max: 2001.5, Diff: 0.0] [Ext Root Scanning (ms): Min: 0.3, Avg: 0.3, Max: 0.4, Diff: 0.1, Sum: 2.7] [SATB Filtering (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0] [Update RS (ms): Min: 1.1, Avg: 1.3, Max: 1.9, Diff: 0.8, Sum: 10.6] [Processed Buffers: Min: 2, Avg: 2.8, Max: 4, Diff: 2, Sum: 22] [Scan RS (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.0] [Object Copy (ms): Min: 0.3, Avg: 0.8, Max: 1.1, Diff: 0.8, Sum: 6.7] [Termination (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.1] [GC Worker Other (ms): Min: 0.0, Avg: 0.0, Max: 0.0, Diff: 0.0, Sum: 0.1] [GC Worker Total (ms): Min: 2.5, Avg: 2.5, Max: 2.6, Diff: 0.0, Sum: 20.3] [GC Worker End (ms): Min: 2004.0, Avg: 2004.0, Max: 2004.0, Diff: 0.0] [Code Root Fixup: 0.0 ms] [Clear CT: 0.1 ms] [Other: 0.2 ms] [Choose CSet: 0.0 ms] [Ref Proc: 0.1 ms] [Ref Enq: 0.0 ms] [Free CSet: 0.0 ms] [Eden: 0.0B(3072.0K)-&gt;0.0B(4096.0K) Survivors: 1024.0K-&gt;0.0B Heap: 81.8M(90.0M)-&gt;81.6M(90.0M)] [Times: user=0.00 sys=0.00, real=0.00 secs] [Full GC 81M-&gt;78M(90M), 0.1786909 secs] [Eden: 0.0B(4096.0K)-&gt;0.0B(4096.0K) Survivors: 0.0B-&gt;0.0B Heap: 81.6M(90.0M)-&gt;78.8M(90.0M)] [Times: user=0.28 sys=0.00, real=0.18 secs] [Full GC 78M-&gt;78M(90M), 0.1693387 secs] [Eden: 0.0B(4096.0K)-&gt;0.0B(4096.0K) Survivors: 0.0B-&gt;0.0B Heap: 78.8M(90.0M)-&gt;78.8M(90.0M)] [Times: user=0.17 sys=0.00, real=0.17 secs] 垃圾收集器参数 参数 描述 UseSerialGC 使用Serial &amp; Serial Old收集器（client模式默认值） UseParNewGC 使用ParNew &amp; Serial Old收集器（不推荐） UseConcMarkSweepGC 使用ParNew &amp; CMS（Serial Old为替补）收集器 UseParallelGC 使用Parallel Scavenge &amp; Parallel Old收集器（Server模式默认值） UseParallelOldGC 在年老代使用Parallel Old收集器 UseG1GC 使用G1收集器","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"Git基本概念","date":"2018-01-15T16:00:00.000Z","path":"Blog/Git/GIt基本概念/","text":"Git文件状态变化周期工作目录下每个文件都只有两种状态：已跟踪和未跟踪。 已跟踪的文件是指那些被纳入了版本控制的文件，在上一次快照中有它们的记录，在工作一段时间后，它们的状态可能处于未修改，已修改或已放入暂存区。 工作目录中除已跟踪文件以外的所有其它文件都属于未跟踪文件，既不存在于上次快照的记录中，也没有放入暂存区。初次克隆某个仓库的时，工作目录中所有文件都属于已跟踪文件，并处于未修改状态。 编辑处于未修改状态的文件后，Git将它们标记为已修改文件。将这些修改过的文件放入暂存区，然后提交所有暂存了的修改，如此反复。","tags":[{"name":"Git","slug":"Git","permalink":"https://yaoyinglong.github.io/tags/Git/"}],"categories":[{"name":"Git","slug":"Git","permalink":"https://yaoyinglong.github.io/categories/Git/"}]},{"title":"Git常用命令","date":"2018-01-15T16:00:00.000Z","path":"Blog/Git/GIt常用命令/","text":"git checkout -b localbranch remotebranch 基于远程分支创建本地分支git reset --head commit_id 撤回提交git push origin HEAD --force 远程提交回退git push origin localbranch:remotebranch 将本地代码提交到远程的指定分支git branch --set-upstream-to=origin/Release_v1.6.4_20170831 将本地分支关联到远程分支上git branch --set-upstream-to=origin/Release_v1.6.4_20170831 localBranchName 切换本地分支关联的远程分支git branch -vv 查看本地分支关联的远程分支之间的对应关系git merge dev 合并指定分支到当前分支(将dev分支合并到当前分支)git branch -d dev 删除本地dev分支git push origin --delete remotebranch 删除远程分支git log --graph 查看分支合并图git clone -b remotebranch https://github.com/apache/struts-examples.git 克隆远程指定的分支git branch -a 查看远程分支git remote -v 查看远程仓库地址git rm test.txt 删除文件git reset HEAD readme.txt 把暂存区的修改撤销掉（unstage），重新放回工作区git checkout -- readme.txt 让这个文件回到最近一次git commit或git add时的状态,没有-- ，就变成了切换分支的命令git reflog 查看所有分支的所有操作记录 git init 初始化本地仓库git pull https://github.com/youraccount/yourproject.git 将远程仓库代码拉取到本地git remote add origin https://github.com/youraccount/yourproject.git 为版本库添加名为origin的远程版本库git push -u origin master -u参数，在推送成功后自动建立本地分支与远程版本库分支的追踪 git remote update origin --prune 更新远程分支列表 强制覆盖本地文件git fetch –allgit reset –hard origin/mastergit pull","tags":[{"name":"Git","slug":"Git","permalink":"https://yaoyinglong.github.io/tags/Git/"}],"categories":[{"name":"Git","slug":"Git","permalink":"https://yaoyinglong.github.io/categories/Git/"}]},{"title":"Minor&Major&Full GC","date":"2018-01-14T16:00:00.000Z","path":"Blog/Java/VM/Minor&Major&Full GC/","text":"Minor GC新生代通常存活时间比较短，是基于复制算法进行回收的。从年轻代空间（包括Eden和两个Survivor区域）回收内存被称为Minor GC。 当JVM无法为一个新的对象分配空间时会触发Minor GC，比如当Eden区满了。所以分配率越高，越频繁执行Minor GC。 内存池被填满的时候，其中的内容全部会被复制，指针会从0开始跟踪空闲内存。Eden 和 Survivor 区进行了标记和复制操作，取代了经典的标记、扫描、压缩、清理操作。所以 Eden 和 Survivor 区不存在内存碎片。写指针总是停留在所使用内存池的顶部。 执行Minor GC操作时，不会影响到永久代。从永久代到年轻代的引用被当成GC Roots，从年轻代到永久代的引用在标记阶段被直接忽略掉。 所有的Minor GC都会触发Stop-The-World，这个过程非常短暂。大部分Eden区中的对象都能被认为是垃圾，永远也不会被复制到Survivor区或者老年代空间。如果正好相反，Eden区大部分新生对象不符合GC条件，Minor GC执行时暂停的时间将会长很多。 Major GC &amp; Full GC老年代与新生代不同，老年代对象存活的时间比较长、比较稳定，因此一般采用标记整理算法来进行回收，当然这也跟垃圾收集器相关。 Major GC是清理老年代。Full GC是清理整个堆空间包括年轻代和老年代。出现Major GC经常会伴随至少一次的Minor GC，且Major GC的速度一般会比Minor GC慢10倍以上。 许多Major GC是由Minor GC触发的，所以很多情况下将这两种GC分离是不太可能的。另一方面，许多现代垃圾收集机制会清理部分永久代空间。 Full GC触发条件： 调用System.gc()时，系统建议执行Full GC，但是不必然执行。 老年代空间不足。 方法去空间不足。 通过Minor GC后进入老年代的平均大小大于老年代的可用内存。 由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小。","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"JVM内存池","date":"2018-01-05T16:00:00.000Z","path":"Blog/Java/VM/JVM内存池/","text":"JVM内存池JVM共享内存区域或者叫内存池分堆和方法区或者称为永久代（Permgen）两块，其中堆内存分为年轻代（Young）和老年代（Tenured），而年轻代又被划分为三个区域Eden、Survivor 1、Survivor 2。 Eden空间对象被创建时通常被分配到Eden空间。为了解决对象分配内存时的线程安全问题，为每个线程在Eden空间中预先分配一小块内存TLAB（本地线程分配缓冲），线程给对像分配内存时在TLAB上分配，当TLAB中没有足够的内存时会将数据同步到Common Area中，如果Common Area中也没有足够的内存那么Minor GC将会被触发释放内存空间，如果任然没有足够的内存对象将会被直接通过分配担保机制进入老年代。 是否使用TLAB可以通过-XX:+/-UseTLAB参数来控制。 Survivor空间当每次Minor GC时JVM会将还存活的对象进行标记，标记完成后在Eden空间和From Survivor空间中所有存活的对象将会被复制到To Survivor空间中，当然第一次Minor GC时From Survivor应该是空的，之后To Survivor空间和From Survivor空间角色互换，该过程就是使用的复制算法。在对象头中的运行时数据中存放了对象的GC分代年龄，每一次对象从GC中存活下来后都将会对GC分代年龄加一，当GC分代年龄超过一定的阈值时，该对象将会将不会复制到To Survivor空间中而是直接复制到Tenured（老年代）中，直到该对象变为不可达被回收。 JVM内存池实际工作监控情况由于我的JDK是1.8所以该图中显示是的Mataspace空间，如果是用的JDK1.7该处应该是PermGen。 由此图可以明显的看出每当一个Eden空间达到某个值时，就会触发一次GC将Eden空间中的部分存活对象复制到To Survivor中，并将Eden清空。还可以明显的看出Survivor 1 和 Survivor 2 是交替作为From Survivor和To Survivor空间角色。 HotSpot虚拟机默认Eden：From Survivor：To Survivor的大小比例是8：1：1实际的阈值可以通过JVM参数-XX:MaxTenuringThreshold动态指定，HotSpot中默认的阀值为15个GC周期","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"HotSpot收集算法实现","date":"2018-01-03T16:00:00.000Z","path":"Blog/Java/VM/HotSpot收集算法实现/","text":"枚举根节点主流的Java虚拟机都是采用可达性分析算法来管理内存的。在可达性分析法中对象能被回收的条件是对象到GC Roots是否存在引用链，可作为GC Roots的节点主要是在全局性引用（e.g.常量或静态属性）和执行上下文（e.g.栈帧中本地变量表）。现在很多应用方法区都很大，如果逐个检查非常耗费时间。 而可达性分析算法的分析工作必须在一个能确保一致性的快照中进行，整个分析期间整个执行系统对象引用关系必须保持不变，就像被冻结在某个时间点上。这是导致GC执行时必须停顿所有Java执行线程的一个重要原因，Sun将该事件称为Stop-The-World。在枚举根节点的过程中耗费的时间越多GC停顿时间越长。 目前主流的Java虚拟机使用的都是准确式GC，当执行系统停顿后，并不需要一个不漏地检查完所有执行上下文和全局变量的引用位置，在HotSpot虚拟机实现中，使用一组称为OopMap的数据结构来记录所有执行上下文和全局变量的引用位置，在类加载完成时HotSpot就把对象内偏移量上对应的类型数据计算出来，在JIT编译过程中，也会在特定位置记录下栈和寄存器中哪些位置时引用。 安全点在OopMap的协助下，HotSpot可以快速且准确地完成GC Roots枚举，但是可能导致引用关系变化或者说OopMap内容变化的指令非常多，如果每条命令都生成对应的OopMap，将会需要大量额外空间，GC空间成本将会变得很高。 HotSpot只是在特定的位置记录生成的OopMap信息，这些位置称为安全点（Safepoint），程序执行时并非在所有地方都能停顿下来开始GC，只有在达到安全点时才能暂停。安全点的选定既不能太少以至于让GC等待时间太长，也不能过于频繁以至于过分增大运行时的负荷。安全点的选定基本上是以程序是否具有让程序长时间执行的特征为标准进行选定的，但是程序不太可能因为指令流太长而过长时间运行，这里的长时间执行实际上是指指令序列复用，例如方法调用、循环跳转、异常跳转等功能的指令才会产生安全点。 如何让所有线程（除执行JNI调用的线程）在GC发生时都运行到最近的安全点停顿下来。有抢占式中断和主动式中断两种方案可供选择。 抢占式中断——GC发生时，首先中断所有线程，如果发现有线程中断地方不在安全点上，就恢复线程让其运行到安全点。抢占式中断不需要线程的执行代码主动区配合，但是目前几乎没有虚拟机实现采用抢占式中断来暂停线程从而响应GC事件。 主动式中断——当GC需要中断线程的时候，不直接对线程操作，仅简单地设置一个轮询标志，各个线程执行时主动轮询整个标志，发现中断标志为真时就自己中断挂起。轮询标志、安全点和创建对象需要分配的内存三个地方是重合的。 安全区域安全点保证了程序执行时，在不太长时间内就会遇到可进入GC的安全点，但是程序不执行时（没有分配到CPU时间），例如线程处于Sleep状态或Blocked状态时，线程无法响应JVM中断请求并运行到安全的地方中断挂起，针对这种情况就需要安全区来解决。 安全区域时指在一段代码片段中，引用关系不会发生变化，整个区域中的任意地方开始GC都是安全的。线程在执行到安全区域中的代码时，首先标识自己进入了安全区域，当在这段时间里JVM要发起GC时，就不用管标识自己进入安全区域状态的线程了。在线程要离开安全区域时，先检查系统是否已经完成根节点枚举或是整个GC过程，如果没完成就必须等待直到收到可以安全离开安全区域的信号为止。","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"垃圾收集算法","date":"2018-01-02T16:00:00.000Z","path":"Blog/Java/VM/垃圾收集算法/","text":"标记清除算法标记清除算法是最基础的收集算法，分为标记和清除两个阶段，标记阶段标记出所有需要回收的对象，清除阶段统一回收所有被标记的对象。之所以说标记清除算法是最基础的收集算法，是因为后续的收集算法都是基于这种思路并对其不足进行改进而得到的。 标记清除算法主要有两个不足，一是效率问题，标记和清除两个过程的效率都不高；二是空间问题，标记清除后会产生大量不连续的内存碎片，空间碎片太多可能会导致以后再程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发垃圾收集动作。 复制算法复制算法的出现是为了解决效率问题，它将可用内存按容量划分为大小相等的两块，每次只使用其中一块。当这一块使用完了，就将还存活着的对象复制到另一块上面，然后再把已使用过的内存空间一次清理掉。每次都是对整个半区进行内存回收，内存分配时不用考虑内存碎片等复杂情况，只要移动堆顶指针按顺序分配内存即可，实现简单运行高效。但是代价是将内存缩小为原来的一半。 现在商用虚拟机都采用复制算法来回收新生代，因为新生代对象98%是朝生夕死，所以不需要按1：1来划分内存空间。而是将内存空间分为一块较大的Eden空间和两块较小的Survivor空间（From Survior和To Survovor），HotSpot虚拟机默认Eden：From Survivor：To Survivor的大小比例是8：1：1，每次使用Eden和From Survivor空间。当Eden空间执行Minor GC时会将Eden和From Survivor空间中还存活的对象复制到To Survivor空间中（如果To Survivor空间没有足够空间存放上一次新生代收集下来存活的对象时，这些对象将直接通过分配担保机制进入老年代。），然后清理掉Eden和From Survivor空间，最后将To Survivor空间和From Survivor空间角色互换。 复制算法在对象存活率较高时就要进行较多的复制操作，效率将会变低，老年代一般不能直接选用复制算法。 标记整理算法根据老年代的特点，提出了标记整理算法，标记过程任然与标记清除算法一样，整理阶段让所有存活的对象都向一端移动，然后直接清理掉边界以外的内存。 分代收集算法目前商业虚拟机的垃圾收集都采用分代收集算法，这种算法并没有新思想，只是根据对象存活周期将内存分为几块，一般把堆内存分为新生代和老年代，新生代采用复制算法，老年代采用标记清除算法或标记整理算法进行回收。","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"垃圾收集器","date":"2018-01-02T16:00:00.000Z","path":"Blog/Java/VM/垃圾收集器/","text":"垃圾收集器是内存回收的具体实现。Java虚拟机规范中对垃圾收集器应该如何实现并没有任何规定。 两者之间存在连线的收集器可以相互搭配使用，收集器所处区域表示其属于新生代收集器还是老年代收集器。 Serial收集器Serial收集器是最基本、发展历史最有悠久、基于复制算法、单线程的新生代收集器。单线程的意义并不仅仅是使用一个CPU或一条收集线程去完成垃圾收集工作，更重要的是在垃圾收集时必须暂停其他所有工作线程。Serial收集器到目前为止，依然是JAVA虚拟机运行在Client模式下的默认新生代收集器。与其他收集器的单线程比Serial收集器简单高效，对于限定单个CPU的环境来说，Serial收集器由于没有线程交互开销，可以获得最高的单线程收集效率。可能会产生较长时间的停顿。使用-XX:+UseSerialGC参数指定虚拟机使用Serial收集器。 ParNew收集器ParNew收集器其实就是Serial收集器的多线程版本，除了使用多线程进行垃圾收集之外，其余行为包括Serial收集器可用的所有控制参数、收集算法、Stop-The-World、对象分配规整、回收策略等都与Serial收集器完全一样，两者也共用了相当多的代码。 ParNew收集器是许多运行在Server模式下的虚拟机中首选的新生代收集器，除了Serial收集外，目前只有ParNew收集器能与CMS收集器配合工作。但ParNew收集器在单CPU环境中绝对不会比Serial收集器效果好，甚至由于存在线程交互开销，两个CPU环境中都不能百分百保证可以超越Serial收集器。 ParNew收集器也是使用-XX:+UseConcMarkSweepGC选项后默认的新生代收集器，也可以使用-XX:+UseParNewGC选项来强制指定它。 Parallel Scavenge收集器Parallel Scavenge是一个使用复制算法、并行的多线程的新生代收集器。CMS等收集器关注点是尽可能地缩短垃圾收集时用户线程的停顿时间，而Parallel Scavenge收集器的目的是达到一个可控的吞吐量。自适应调节策略是Parallel Scavenge与ParNew收集器的一个重要区别。 Parallel Scavenge收集器通过使用-XX:UseAdaptiveSizePolicy开关参数来设置是否使用自适应调节策略，当该参数打开时，就不需要手工通过-Xmn参数指定新生代的大小、-XX:SurvivorRatio参数指定Eden与Servivor区的比例、-XX:PretenureSizeThreshold参数直接晋升到老年代的对象大小（大于这个参数的对象将直接在老年代分配）等细节，虚拟机会根据当前系统运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或最大吞吐量。只需要把基本的最大堆内存设置好，然后使用-XX:MaxGCPauseMillis参数或者-XX:GCTimeRatio参数给虚拟机设立一个优化目标，具体细节参数调节工作就由虚拟机自动完成了。 -XX:MaxGCPauseMillis控制最大垃圾收集停顿时间。该参数允许的值是一个大于0的毫秒数，收集器将尽可能地保证内存回收花费的时间不超过设定值，但并不是把该参数设置得小就能使得系统的垃圾收集速度变快，GC停顿时间缩短是以牺牲吞吐量和新生代空间来换取的（e.g.把新生代调小，原来10秒收集一次，每次停顿100毫秒，现在5秒收集一次，每次停顿70毫秒）； -XX:GCTimeRatio垃圾收集时间占总时间的比率，相当于吞吐量的倒数，该参数允许的值是一个大于0且小于100的整数，默认为99允许最大1%的垃圾收集时间。 吞吐量 = 运行用户代码时间 / （运行用户代码时间 + 垃圾收集时间） 也就是CPU用于运行用户代码的时间与CPU总消耗时间的比值。 Serial Old收集器Serial Old是Serial收集器的老年代版本，它是一个使用标记整理算法的单线程的收集器，主要也是给Client模式下的虚拟机使用。 如果在Service模式下，主要有两种用途：一是在JDK1.5之前版本中与Parallel Scavenge收集器搭配使用，二是作为CMS收集器的后备预案，在CMS发生Concurrent Mode Failure时使用。 Parallel Old收集器Parallel Old是Parallel Scavenge收集器的老年代版本，它是一个使用标记整理算法的多线程的收集器。 该收集器在JDK1.6中提供，在此之前如果新生代选择了Parallel Scavenge收集器老年代只能选择Serial Old收集器。由于Serial Old收集器是单线程的即使使用了Parallel Scavenge收集器也未必能在整体应用上获得吞吐量最大化，在老年代很大且硬件条件比较高级的环境中，这种组合吞吐量甚至还不一定有ParNew加CMS的组合好。 在注重吞吐量以及CPU资源敏感的场合，优先考虑Parallel Scavenge加Parallel Old收集器的组合。 CMS收集器CMS(Concurrent Mark Sweep)收集器是一种以获取最短回收停顿时间为目标的且基于标记清除算法的收集器。且它是HotSpot虚拟机中第一款真正意义上的并发收集器，它第一次实现了让垃圾收集线程与用户线程基本上同时工作。 CMS收集器运作过程相对于前面几种收集器来说更复杂一些，整个过程分为初始标记、并发标记、重新标记、并发清除4个步骤。其中初始标记、重新标记两个步骤需要Stop-The-world。初始标记仅仅只是标记一下GC Roots能直接关联到的对象，速度很快，并发标记阶段就是进行GC Roots Tracing的过程，重新标记阶段是为了修正并发标记期间因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，整个阶段停顿时间一般比初始标记稍长但比并发标记时间短。整个过程耗时最长的是并发标记和并发清理过程收集器线程都可以与用户线程一起工作，总体上CMS收集器的内存回收过程是与用户线程一起并发执行的。 CMS收集器对CPU资源非常敏感。在并发阶段它虽然不会导致用户线程停顿，但会占用一部分线程而导致应用程序变慢，总吞吐量降低。CMS默认启动的回收线程数是：（CPU数量 + 3）/ 4。当CPU不足4个时CMS对用户程序的影响可能变得很大。为了应付这种情况虚拟机提供了一种称为增量式并发收集器，和使用抢占式来模拟多任务机制的思想一样，在并发标记、整理时让GC线程与用户线程交替运行，尽量减少GC线程的独占资源的时间，垃圾收集过程会更长，但对用户程序影响会显得少一些，但实践证明这种方式效果一般目前已经不提倡使用。 CMS收集器无法处理浮动垃圾，可能出现Concurrent Mode Failure失败而导致另一次Full GC产生。由于垃圾收集阶段用户线程还在运行，也就需要留有足够内存空间给用户线程使用，因此CMS收集器不能像其他收集器等到老年代几乎完全被填满再进行收集。当CMS运行期间预留内存无法满足程序需要，就会出现一次Concurrent Mode Failure失败，这时虚拟机就会启动后备预案，临时使用Serial Old收集器来重新进行老年代的垃圾收集，这样停顿时间就很长。可以通过参数-XX:CMSInitiatingOccupancyFraction来设置触发百分比。 CMS收集器是基于标记清除算法实现的，收集结束时会产生大量空间碎片。空间碎片过多时，在老年代还有很大空间剩余时，给大对象分配内存空间时无法找到足够大的连续的内存空间，而不得不提前触发一次Full GC。为了解决整个问题CMS提供-XX:+UseCMSCompactAtFullCollection开关参数，默认开启，用于在Full GC时开启内存碎片的合并整理，但内存整理过程无法并发故停顿时间将变长。CMS还提供-XX:CMSFullGCsBeforeCompaction参数来设置执行多少次不压缩Full GC后执行一次压缩的GC，默认为0。 浮动垃圾是指由于CMS并发清理阶段用户线程还在运行故会产生新的垃圾，但这部分垃圾出现在标记过程之后，CMS无法在当次收集中处理掉他们，只好留待下一次GC时再清理。 G1收集器G1时一款面向服务端应用的垃圾收集器，其他收集器收集的范围都是整个新生代或者老年代，而G1收集器将整个Java堆划分为多个大小相等的独立区域（Region），虽然保留了老年代和新生代的概念，但老年代和新生代不再被物理隔离，它们都是一部分Region（不需要连续）的集合。 G1收集器会跟踪各个Region里面的垃圾堆积的价值大小，即回收所获得的空间大小以及回收所需时间经验值，在后台维护一个优先列表，每次根据允许收集的时间，优先回收价值最大的Region，这也是Garbage-First名称的由来。 与其他收集器相比G1收集器具备并行与并发、分代收集、空间整合、可预测停顿4个特点： G1收集器可以使用并行的方式来缩短Stop-The-World停顿时间，且可以通过并发的方式让Java程序继续执行。 G1收集器可以不用其他收集器的配合独立管理整个GC堆，任然保留分代的概念，采用不用的方式去处理新建的对象和已经存活了一段时间、熬过多次GC的旧对象以获得更好的收集效果。 G1收集器整体来看是基于标记整理算法实现的收集器，从局部（两个Region之间）来看是基于复制算法来实现的，这意味着G1运作期间不会产生内存碎片。 G1收集器除了追求低停顿外，还能建立可预测的停顿时间模型，能让使用者明确指定一个长度为M毫秒的时间片段内，消耗再垃圾收集上的时间不得超过N毫秒。之所以能建立可预测的停顿时间模型，是因为它可以有计划地避免在整个Java堆中进行全区域的垃圾收集。 一个对象分配在某个Region中，它并非只能被本Region中的其他对象引用，而是可以与整个Java堆任意的对象发生引用关系。在G1收集器中Region之间的对象引用以及其他收集器中的新生代与老年代之间的对象引用，都是使用Rememberd Set来避免全堆扫描。每个Region都有一个与之对应的Rememberd Set，虚拟机发现程序在对Reference类型的数据进行写操作时，会产生一个Write Barrier暂时中断写操作，检查Reference引用的对象是否处于不同的Region之中，在分代中就检查是否老年代中的对象引用了新生代中的对象，如果是便通过CardTable把相关引用信息记录到被引用对象所属的Region的Rememberd Set中，当进行内存回收时，在进行GC根节点枚举范围中加入Rememberd Set即可保证不对全堆扫描也不会遗漏。 G1收集器的的运作大致分为初始标记、并发标记、最终标记、筛选回收4个步骤。 初始标记阶段仅仅标记一下GC Roots能直接关联到的对象，并且修改TAMS（Next Top at Mark Start）的值，让下一阶段用户程序并发运行时，能在正确可用的Region中创建对象，需要停顿线程，但耗时很短。 并发标记阶段是从GC Roots开始对堆中对象进行可达性分析找出存活对象，耗时较长但可与用户程序并发执行。 最终标记阶段是为了修正在并发标记期间因用户程序继续运作而导致标记产生变动的那一部分标记记录，虚拟机将这段时间对象变化记录在线程Rememberd Set Logs里面,最终标记阶段需要把Rememberd Set Logs的数据合并到Rememberd Set中，这个阶段需要停顿线程但可并行执行。 筛选回收阶段首先对各个Region的回收价值和成本进行排序，根据用户所期望的GC停顿时间来制定回收计划，这个阶段也可以做到与用户程序并发执行，但因为只回收一部分Region时间是用户可控的，，而且停顿用户线程将大幅提高收集小路。 总结 收集器 串并行/并发 新生代/老年代 算法 目标 适用场景 Serial 串行 新生代 复制算法 响应速度优先 单CPU环境Client模式 Serial Old 串行 老年代 标记-整理 响应速度优先 单CPU环境Client模式、CMS后备预案 ParNew 并行 新生代 复制算法 响应速度优先 多CPU环境Server模式与CMS配合 Parallel Scavenge 并行 新生代 复制算法 吞吐量优先 在后台运算而不需要太多交互的任务 Parallel Old 并行 老年代 标记-整理 吞吐量优先 在后台运算而不需要太多交互的任务 CMS 并发 老年代 标记-清除 响应速度优先 互联网站或B/S系统服务端 G1 并发 新生代&amp;老年代 标记-整理复制算法 响应速度优先 面向服务端应用，将来替换CMS","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"对象是否存活","date":"2017-12-31T16:00:00.000Z","path":"Blog/Java/VM/对象是否存活/","text":"Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的“高墙”，墙外面的人想进去，墙里面的人想出来。 了解GC和内存非配的目的是：当需要排查各种内存溢出、内存泄露问题时，当垃圾收集成为系统达到更高并发量的瓶颈时，为了更好的对这些自动化技术实施必要的监控和调节。 程序计数器、虚拟机栈、本地方法栈这三个区域是线程私有的方法结束或线程结束内存就跟着回收了；但在堆和方法区中，一个接口中的多个实现类需要的内存可能不一样，一个方法中的多个分支需要的内存也可能不一样，只有在程序处于运行期间才会知道会创建哪些对象，这部分的内存是动态的，也是垃圾收集器所关注的。 堆里面存放了几乎所有的对象实例，垃圾收集器在对堆进行回收前，首先确定对象是否存活（是否还有可能再被任何途径使用）。而判断对象是否存活的算法有引用计数算法和可达性分析算法两种，但目前主流的实现是通过可达性分析来判断对象是否存活的。 引用计数算法给对象中添加一个引用计数器，每当有一个地方引用它时，计数器值就加1；当引用失效时，计数器值就减1；任何时刻计数器值为0的对象就是不可能再被使用的。 引用计数算法实现简单，判定效率很高，在大部分情况下它都是一个不错的算法，Python就是是使用的引用计数算法进行的内存管理。但是主流的Java虚拟机里面没有选用引用计数算法来管理内存，其中最主要的原因是它很难解决对象之间相互引用的问题。 可达性分析算法通过一系列的称为GC Roots的对象作为起始点，从这些节点开始向下搜索，搜索所走过的路径称为引用链，当一个对象到GC Roots没有任何引用链相连时，则证明此对象时不可用的。 在Java中可作为GC Roots的对象包括下面几种： 虚拟机栈（栈帧中的局部变量表）中引用的对象。 方法区中类静态属性引用的对象。 方法区中常量引用的对象。 本地方法栈中JNI（本地方法）引用的对象。 引用无论时通过引用计数算法还是通过可达性分析算法判断对象是否存都与引用有关。 在JDK 1.2以前，如果reference类型的数据中存储的数值代表的是另外一块内存的起始地址，就称这块内存代表着一个引用；在JDK 1.2之后，Java对引用的概念进行了扩充，将引用分为强引用、软引用、弱引用、虚引用4种，这4种引用强度依次逐渐减弱。 强引用在程序代码中普遍存在的，类似Object obj = new Object()这类的引用，只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象。 软引用是用来描述一些还有用但并非必要的对象。软引用关联着的对象，在系统将要发送内存溢出异常之前，将会把这些对象列进回收范围之中进行二次回收。JDK提供了SoftReference类来实现软引用。 弱引用也是用来描述非必要对象，且比软引用更弱，被弱引用关联的对象只能生存到下一次垃圾收集发生之前。JDK提供了WeakReference类来实现弱引用。 虚引用最弱的一种引用关系，也被称为幽灵引用或幻影引用。一个对象是否有虚引用存在完全不影响其生存时间，也无法通过虚引用来获取对象的实例。为一个对象设置虚引用关联的唯一目的是能在这个对象被收集器回收时收到一个系统通知。JDK提供了Phantomeference类来实现虚引用。 finalize方法即使对象不可达，也并非立即将该对象GC掉，真正宣告一个对象死亡至少需要经历两次标记过程，若果对象在进行可达性分析后发现没有与GC Roots相连接的引用链，那它将会被第一次标记并且进行一次筛选，筛选条件是此对象是否有必要执行finalize()方法。 如果对象没有覆盖finalize()方法或者finalize()方法已经被虚拟机调用过了，虚拟机将这两种情况视为没有必要执行，那么在下一个回收周期对象将会被回收。 如果对象被判定为有必要执行finalize()方法，该对象会被放置在一个叫做F-Queue的队列中，并在稍后由一个虚拟机自动建立的、低优先级的Finalizer线程去执行。虚拟机会触发这个方法但是不会等待它运行结束，因为如果有的finalize()方法执行缓慢甚至发送死循环，很可能导致F-Queue队列中其他对象永远处于等待，从而导致整个内存回收系统奔溃。稍后GC将对F-Queue中的对象进行二次小规模标记，被二次标记的对象在下一个回收周期将会被回收。 如果对象在finalize()方法中重新与引用链上的任何对象建立关联，在二次标记时它将被移除即将回收的集合。且任何对象的finalize()方法只会被系统自动调用一次。 有很多地方说finalize()方法适合做关闭外部资源之类的工作，但是finalize()方法运行的代价高昂、不确定性大，无法保证各个对象的调用顺序。且finalize()方法能做的所有工作，使用try-finally或者其他方式都可以做到而且可以做得更好跟及时，所以尽量不要使用finalize()方法。 回收方法区很多人认为方法区（HotSpot中的永久代）没有垃圾收集，虚拟机规范中确实说过可以不要求虚拟机在方法区实现垃圾收集，且方法区垃圾收集性价比很低，是否对方法区进行垃圾收集HotSpot通过-Xnoclassgc参数来控制。 方法区的垃圾收集主要回收废弃的常量和无用的类两部分。回收废弃的常量与回收堆中的对象非常类似。判断一个类是否是无用的类的条件非常苛刻，需要同时满足下面3个条件： 该类所有的实例都已经被回收，也就是堆中不存在该类的任何实例。 加载该类的ClassLoader已经被回收。 该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 通常在大量使用反射、动态代理、CGLib等ByteCode框架、动态生成JSP以及OSGi这类频繁自定义ClassLoader的场景需要虚拟机具备类卸载功能，以保证方法区不会溢出。","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"Java内存区域","date":"2017-12-23T16:00:00.000Z","path":"Blog/Java/VM/Java内存区域/","text":"Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的“高墙”，墙外面的人想进去，墙里面的人想出来。 运行时数据区域Java虚拟机在执行Java程序的过程中会把它所管理的内存划分为若干个不同的数据区域。 程序计数器程序计数器是一块较小的内存空间，它可以看作是当前线程所执行的字节码的行号指示器。在虚拟机概念模型里，字节码解释器工作时就是通过改变程序计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。 Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间计数器互不影响，独立存储，是线程私有的内存区域。 如果线程正在执行一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Native方法，这个计数器值则为空（Undefined）。 程序计数器的内存区域是唯一一个在Java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 Java虚拟机栈Java虚拟机栈也是线程私有的，它的生命周期与线程相同。 虚拟机栈描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个栈帧（Stack Frame）用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每个方法从调用到执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。每一个栈帧中分配多少内存基本上是在类结构确定下来时就已知的，尽管在运行期会由JIT编译器进行一些优化，但大体上可以认为时编译期可知的。 局部变量表存放了编译期可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、对象的引用（reference类型，它可能是一个指向对象的起始地址的引用指针，也可能是指向一个代表对象的句柄或其他与此对象相关的位置）和returnAddress类型（指向了一条字节码指令的地址）。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在栈帧中分配多大的局部变量空间是完全确定的，在方法运行期间不会改变局部变量表的大小。 虚拟机栈中如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常；如果虚拟机栈可以动态扩展（当前大部分虚拟机都可以动态扩展，只是虚拟机规范中允许固定长度的虚拟机栈），如果扩展时无法申请到足够的内存，就会抛出OutOfMemoryError异常。 本地方法栈本地方法栈与虚拟机栈所发挥的作用非常相似，它们之间的区别不过是虚拟机栈为虚拟机执行Java方法（字节码）服务，而本地方法栈则为虚拟机使用到的Native方法服务。本地方法栈与虚拟机栈一样也会抛出StackOverflowError和OutOfMemoryError异常。 注：HotSpot虚拟机直接把本地方法栈和虚拟机栈合二为一 Java堆对于大多数应用来说，Java堆是Java虚拟机所管理的内存中最大的一块。Java堆是被所有线程共享的一块内存区域，在虚拟机启动时创建。Java虚拟机规范中的描述是：所有的对象实例和数组都要在堆上分配，但是随着JIT（Just In Time，即时编译）编译器的发展与逃逸分析技术逐渐成熟，栈上分配、标量替换优化技术导致所有对象都在堆上分配逐渐变得不那么绝对。 Java堆是垃圾收集器管理的主要区域，因此很多时候也被称做GC堆。从内存回收的角度来看，现在的收集器基本都采用分代收集算法，所以Java堆中还可以细分为：新生代和老年代；再细致一点有Eden空间、From Survior空间、To Survovor空间等。 Java堆可以处于物理上不连续的内存空间中，只要逻辑上连续即可。主流的虚拟机都是按照可扩展来实现的，通过-Xmx（JVM最大允许分配的堆内存）和-Xms（JVM初始分配堆内存）来控制。如果堆中没有内存完成实例分配，且堆也无法再扩展时，将抛出OutOfMemoryError异常。 方法区和Java堆一样是线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。Java虚拟机规范把方法区描述为堆的一个逻辑部分。 对于习惯在HotSpot虚拟机上开发、部署程序的开发者来说，很多人把方法区称为永久代，但是本质上两者并不等价，仅仅因为HotSpot的设计团队选择把GC分代收集扩展至方法区，或者说使用永久代来实现方法区而已，这样HotSpot的垃圾收集器可以像管理Java堆一样管理方法区内存，能节省为方法区编写内存管理代码，但对于其他虚拟机来说并不存在永久代的概念。使用永久代来实现方法区并非是一个好主意，这样更容易遇到内存溢出问题，因为永久代有-XX:MaxPermSize的设置上限，现在HotSpot也有放弃永久代并逐步采用Native Memory来实现方法区的规划，在HotSpot的JDK1.7中，已经把原本放在永久代的字符串常量池移除。 方法区不需要连续内存、可选择固定大小、可扩展、可选择不实现垃圾收集。方法区内存回收的目标主要是针对常量池的回收和对类型的卸载。当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。 运行时常量池是方法区的一部分。Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。除了保存Class文件中描述的符号引用外，还会把翻译出来的直接引用也存储在运行时常量池。运行时常量池相对于Class文件常量池的另外一个重要特征是具备动态性，常量并非只有编译期才能产生，并非预置入Class文件中常量池的内容才能进入方法区运行时常量池，运行期间也可以将新的常量放入池中，当常量池无法再申请到内存时会抛出OutOfMemoryError异常。 直接内存直接内存并不是虚拟机运行时数据区域的一部分，也不是Java虚拟机规范中定义的内存区域。但是这部分内存也被频繁使用，也可能导致OutOfMemoryError异常。本地直接内存的分配不会受Java堆大小的限制，但既然是内存，肯定受本地主机总内存和处理器寻址空间限制。再配置虚拟机参数时，会根据实际内存设置-Xmx等参数信息，但经常忽略直接内存，使得各个内存区域总和大于物理内存限制，从而导致动态扩展时出现OutOfMemoryError异常。","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"OOM异常实验","date":"2017-12-23T16:00:00.000Z","path":"Blog/Java/VM/OutOfMemoryError异常/","text":"Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的“高墙”，墙外面的人想进去，墙里面的人想出来。 堆溢出堆中存储的是对象的实例，只要不断的创建对象，并保证GC Roots到对象之间有可达路径来避免垃圾回收机制清除这些对象，当对象数量达到最大堆的通量限制后就会产生内存溢出异常。本次测试中通过限制堆内存的大小且将其限制为不可扩展（将堆的最小值-Xms和最大值-Xmx参数设置为一样）来进行堆内存溢出测试。 测试使用的示例代码：123456789101112public class HeapOOM &#123; static class OOMObject&#123;&#125; public static void main(String[] args)&#123; List&lt;OOMObject&gt; list = new ArrayList&lt;OOMObject&gt;(); while(true)&#123; list.add(new OOMObject()); &#125; &#125;&#125; 使用的VM Args：-Xms50m -Xmx50m -XX:+HeapDumpOnOutOfMemoryError；我使用的IDEA通过Edit Configurations在VM options对虚拟机参数进行设置。 在测试过程中发现一个非常有趣的问题，当将堆内存大小限制为50m、80m时（是否还有其他的数值会导致该现象就没有具体去深究了），运行的程序会被一直Full GC导致Stop-the-world从而导致程序一直不会被执行结束，而且发现当前使用的是Parallel Scavenge收集器。更有趣的是当使用其他的收集器时不会出现这样的问题，目前还未找到具体的原因。 正常情况下Java堆内存溢出时，溢出堆栈信息java.lang.OutOfMemoryError: Java heap space如下图： 栈溢出12345678910111213141516171819public class JavaVMStackSOF &#123; private int stackLength = 1; public void stackLack()&#123; stackLength++; stackLack(); &#125; public static void main(String[] args) throws Exception &#123; JavaVMStackSOF oom = new JavaVMStackSOF(); try &#123; oom.stackLack(); &#125; catch (Exception e) &#123; System.out.println(\"stack length:\" + oom.stackLength); throw e; &#125; &#125;&#125; 方法区和运行时常量池溢出本地直接内存溢出","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"堆中对象分配&布局&访问","date":"2017-12-23T16:00:00.000Z","path":"Blog/Java/VM/堆中对象分配&布局&访问/","text":"Java与C++之间有一堵由内存动态分配和垃圾收集技术所围成的“高墙”，墙外面的人想进去，墙里面的人想出来。 对象的创建Java中创建对象（例如克隆、反序列化）通常仅仅是一个new关键字。当虚拟机遇到一条new指令时，首先将去检查这个指令的参数是否能在运行时常量池中定位到一个类的符号引用，并检查这个符号引用代表的类是否已被加载、解析、和初始化过。如果没有必须先执行相应的类加载过程。 在类加载检查通过后，虚拟机将为新生对象分配内存，对象所需内存的大小在类加载完成后便可完全确定。对象内存的分配方式有指针碰撞和空闲列表两种，选择哪种分配方式由Java堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定，或者说所采用的垃圾收集器采用的哪种或哪几种垃圾收集算法决定。 指针碰撞，假设堆内存绝对规整，使用过的内存放在一边空闲内存放在另一边，中间放着一个指针作为分界点的指示器，给对象分配内存时将该指针向空闲空间那边挪一段与对象大小相等的距离。 空闲列表，堆内存不规则，已使用的内存和空闲内存相互交错，这时虚拟机就必须维护一个列表，用于记录哪些内存是可用的，在分配内存时从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录。 对象的创建在虚拟机中是非常频繁的行为，在并发情况下是非线程安全的。解决线程安全问题有两种方案： 对分配内存空间的动作进行同步处理——实际上虚拟机采用CAS配上失败重试的方式保证更新操作的原子性。 把内存分配的动作按照线程划分在不同的空间中进行，为每个线程在堆中预先分配一小块内存TLAB（本地线程分配缓冲），线程分配内存时在TLAB上分配，当TLAB用完并分配新的TLAB时才需要进行同步锁定。虚拟机通过-XX:+/-UseTLAB参数来设置是否使用TLAB。 内存分配完成后，虚拟机需要将分配到的内存空间都初始化为零值，但不包括对象头。如果使用TLAB该过程可以提前至TLAB分配时进行。该操作保证了对象的实例字段在Java代码中可以不赋初始值就直接使用。接下来虚拟机要对对象进行必要的设置，类如对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄、是否使用偏向锁等这些存在对象头中的信息。执行new指令后会接着执行&lt;init&gt;方法，把对象按照开发着的意愿进行初始化。 对象的内存布局在HotSpot虚拟机中对象在内存中存储布局分为对象头、实例数据和对齐填充3块区域。 对象头包括用于存储对象自身的运行时数据和类型指针。运行时数据包括哈希码、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳；类型指针——对象指向它的类元数据的指针，虚拟机通过该指针来确定这个对象是哪个类的实例。但并不是所有虚拟机在对象数据上保留类型指针，或者做查找对象的元数据信息不一定要经过对象本身。另外如果对象是一个数组，在对象头中必须有一块用于记录数组长度的数据，这样虚拟机可以通过对象元数据信息确定Java对象大小，但从数组的元数据中却无法确定数组的大小。 实例数据是对象真正存储有效信息，也是程序代码中所定义的各种类型的字段内容。从父类继承的和在子类中定义的都需要记录。存储顺序会受到虚拟机分配策略参数（FieldsAllocationStyle）和字段在Java源码中的定义顺序影响。HotSpot默认分配策略是相同宽度的字段总是被分到一起。在满足该条件的情况下父类中定义的变量会出现在子类之前。如果CompactFields参数值为true，子类中较窄的变量也可能会插入到父类变量的空隙之中。 对齐填充并不是必然存在的，仅仅起占位符的作用。HotSpot VM自动内存管理系统要求对象的起始地址必须是8字节的整倍数，当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。 对象的访问定位对象的访问需要通过栈上的引用对象（reference）数据来操作堆上的具体对象。由于reference类型在虚拟机规范中只定义了一个指向对象的引用，并没有定义这个引用应该通过何种方式去定位、访问堆中的对象的具体位置，对象的访问方式由虚拟机实现而定，目前主要的访问方式有使用句柄和直接指针两种。 使用句柄访问的话，在堆中将会划分出一块内存来作为句柄池，reference中存储的就是对象的句柄地址，句柄中包含了对象实例数据与对象类型数据各自的具体地址信息。 使用直接指针访问的话，堆中对象的布局就必须考虑如何放置访问类型数据的相关信息，而reference中存储的直接就是对象的地址。 两种对象访问方式各有优势，使用句柄访问的最大好处就是reference中存储的是稳定的句柄地址，在对象被移动时只会改变句柄中的实例数据指针，而reference本身不需要修改；使用直接指针访问方式的最大好处就是速度更快，节省了一次指针定位的时间开销，HotSpot虚拟机使用的直接指针方式进行对象的访问； 暂时理解为上一节对象的内存布局中讲的对象头中的类型指针就是对象类型数据的指针，当然这是使用直接指针访问对象的情况；在通过句柄访问对象的情况下就不存在对象头中的类型指针了。","tags":[{"name":"JVM","slug":"JVM","permalink":"https://yaoyinglong.github.io/tags/JVM/"}],"categories":[{"name":"Java","slug":"Java","permalink":"https://yaoyinglong.github.io/categories/Java/"},{"name":"VM","slug":"Java/VM","permalink":"https://yaoyinglong.github.io/categories/Java/VM/"}]},{"title":"地址解析协议ARP","date":"2017-12-19T16:00:00.000Z","path":"Blog/协议族/地址解析协议/","text":"对于TCP/IP网络在网络通信过程中，通常数据从应用层到数据链路层会被层层封装加上各层的报头，在数据链路层会加上以太网的报头，而以太网的报头中包含目标MAC地址、源MAC地址等数据。其中的目标MAC地址就是通过地址解析协议ARP来获取的。 ARP基础ARP仅用于IPv4，IPv6使用邻居发现协议。 地址解析是发现两个地址之间的映射关系的过程。 ARP高效运行的关键是维护每个主机和路由器上的ARP缓存，该缓存使用地址解析为每个接口维护从网络层到硬件地址的最新映射。 ARP地址解析过程当主机A向主机B发送数据时，首先将主机B的地址跟主机A的地址进行一个与运算来确认两主机是否处于同一个网段（通过网络地址来区分）。 当确认处于同一网段时，首先主机A会查自己的ARP高速缓存表中是否存在主机B的IP地址和其MAC地址的映射关系。如果存在，就直接把IP数据封装成帧进行通信，如果不存在，则先缓存该数据报文，然后主机A就使用链路层广播帧向在同一个共享链路层网段上的所有主机广播ARP请求。该网段上的所以主机都会收到该ARP请求广播包，所有收到ARP请求的主机先比较自己IP地址跟请求中的目的IP地址是否匹配，如果不匹配主动丢弃该ARP查询。如果匹配，把该ARP请求中的源IP地址和源MAC地址存入自己的ARP高速缓存表中，然后填充自己的MAC地址，将两个发送方地址和接收方地址互换，然后向主机A发送生成的应答，应答通常不是广播，而是仅直接发送给请求的发送方。当主机A收到该ARP应答后后，把主机B的IP地址和MAC地址添加到ARP高速缓存表中，然后把IP数据封装成帧与主机B进行通信。 当两主机处于不同网段时。主机A先向网关发送ARP请求报文，当收到网关ARP应答时，先把网关的MAC地址和IP地址记录的ARP高速缓存表中，然后把IP数据包封装成帧发送给网关，然后网关再查看自己的ARP高速缓存表中有没有主机B的IP地址和其MAC地址的映射关系，如果有，就直接封装再发送，如果没有就发送广播，再获取主机B的MAC地址，再封装发送。 ARP帧格式 DST：目的MAC地址，对于ARP请求目的MAC地址全为1为广播地址。SRC：源MANC地址，MAC地址为48位即6个字节。长度或类型：在以太网帧中，对于ARP请求或应答，2字节的长度或类型字段必须为0x0806硬件类型：指硬件地址类型，对于以太网该值为1协议类型：指映射的协议地址类型，对于IPv4地址改值为0x0800。硬件大小：硬件地址的字节数协议大小：协议地址的字节数Op：指ARP请求类型。 1：ARP请求；2：ARP应答；3：RARP请求；4：RARP应答 ARP请求或ARP应答的大小是42字节（ARP消息为28字节，以太网头部为14字节） 对于一个ARP请求，除了目的硬件地址设为0之外，其他字段都需要填充。当一个系统接收到一个ARP请求，它填充自己的硬件地址，将两个发送方地址和接收方地址互换，将Op字段设置为2，然后发送生成的应答。 ARP命令1arp -a # 显示ARP缓存中的所有条目 通过该命令能够查出动态和静态的映射关系条目。 在大多数实现中，完整条目的超时未20分钟，而不完整的条目的超为3分钟（例如：强迫执行一次到不存在主机的ARP请求）。","tags":[{"name":"TCP/IP","slug":"TCP-IP","permalink":"https://yaoyinglong.github.io/tags/TCP-IP/"}],"categories":[{"name":"协议族","slug":"协议族","permalink":"https://yaoyinglong.github.io/categories/协议族/"}]},{"title":"分支管理理解","date":"2017-11-29T16:00:00.000Z","path":"Blog/Git/分支管理理解/","text":"在经历了持续不断的需求，通常多个需求会同时开发，以及发布情况复杂很多时候需求上不了，需要回退代码且版本管理混乱后，通过别人的建议和自己的思考，总结了一些自己觉得对版本管理比较安全的方式方法。 一般的项目种都有主分支master、开发分支develop、上线分支Release。通常我们是在develop分支上进行开发，当要上线时会从develop分支上拉取上线分支Release，当上线完成后将Release分支合并到master和develop分支上。 每一个需求都拉一个新的分支，且根据需求的复杂程度以及周期长短决定从哪一个分支上进行新分支的拉取，建议所有需求都从master分支上拉取新分支。以及是否有必要新建立一个对应的远程分支。建议分支名称最好是以自己的名字/需求编号的形式进行命名。 当开发一个简单且周期短的的需求时，可以直接从master分支上拉取新分支，也可以从develop分支上拉取，可以不必建立对应的远程分支。当开发完成时直接push到develop分支上，如果是需要上线直接push到Release分支上。即使需求上不了线，将关键代码存下来，等上线完成合完分支很快就能恢复代码。 当开发一个比较复杂的需求时，从master或develop分支上拉取新分支1，并创建对应的远程分支2，开发过程中提交到对应的远程分支2上。当开发完成需要联调或者上线时，从联调分或者上线分支上拉一个新分支3，在分支3上拉取远程分支2进行merge。后面调试过程中的调整可以直接在分支3上进行，并直接提交到联调或上线分支。这样即使你的需求不上线了，打开分支1将分支1该需求对应的代码compare with联调或上线分支,将修改的部分写入分支1并push到远程分支2。然后打开分支3与compare with master分支删掉该需求对应的代码。等上线完成Release分支合并master分支后直接在master分支上拉一个新分支4compare with远程分支2，将需求代码快速写入分支4，然后直接将分支4push到develop或者新的上线分支上。所有的push操作之前必须进行pull操作。","tags":[{"name":"Git","slug":"Git","permalink":"https://yaoyinglong.github.io/tags/Git/"}],"categories":[{"name":"Git","slug":"Git","permalink":"https://yaoyinglong.github.io/categories/Git/"}]},{"title":"以太网","date":"2017-11-29T16:00:00.000Z","path":"Blog/协议族/以太网/","text":"以太网属于TCP/IP协议族四层概念模型的最底层数据链路层，以太网网络通信信号的基本单元是以太网帧，帧的最小长度是64字节。以太网帧的基本机构如下图所示： 前导码表示一个以太网帧的开始，其作用是使目的主机接收器时钟与源主机发送器时钟同步。以太网帧是不含前导码的，以太网帧是由以太网首部、数据、以太网尾部FCS（帧检验序列）组成。 以太网首部包含目标MAC地址、源MAC地址以及类型组成，MAC地址的长度是48比特，类型占2字节，故以太网的首部总共占14个字节，类型用于存储帧数据字段的协议。 数据最小长度为46字节，不足46字节填充至46字节，数据是由IP首部、TCP首部和应用数据组成。","tags":[{"name":"TCP/IP","slug":"TCP-IP","permalink":"https://yaoyinglong.github.io/tags/TCP-IP/"}],"categories":[{"name":"协议族","slug":"协议族","permalink":"https://yaoyinglong.github.io/categories/协议族/"}]},{"title":"网络基础知识","date":"2017-11-27T16:00:00.000Z","path":"Blog/协议族/网络基础知识/","text":"搭建网络的主要设备及其作用 设备 作用 网卡 使计算机联网的设备 中继器 从物理层上延长网络的设备 网桥/2层交换机 从数据链路层上延长网络的设备 路由器/3层交换机 通过网络层转发分组数据的设备 4~7层交换机 处理传输层以上各层网络传输的设备 网关 转换协议的设备 各种数据链路：以太网、无线、ATM、FDDI、帧中继、ISDN 中继器 中继器是对减弱信号进行放大和发送的设备 中继器是通过物理层的连接延长网络 即使数据链路层出现某些错误，中继器仍然转发数据 中继器无法改变传输速度 通过中继器进行网路延长并非无线延长，10Mbps的以太网最多可用四个中继器，100Mbps以太网最多只能连两个中继器","tags":[{"name":"TCP/IP","slug":"TCP-IP","permalink":"https://yaoyinglong.github.io/tags/TCP-IP/"}],"categories":[{"name":"协议族","slug":"协议族","permalink":"https://yaoyinglong.github.io/categories/协议族/"}]},{"title":"TCP/IP四层&五层模型","date":"2017-11-24T16:00:00.000Z","path":"Blog/协议族/TCPIP四层&五层模型/","text":"再看一些书或者是在一些博客时，会发现有的地方将TCP/IP协议族定义为一个四层参考模型，而有的地方又将其定义为五层参考模型。 四层参考模型主要包括：应用层、传输层、网际层、网络接口层。 五层参考模型主要包括：应用层、传输层、网络层、数据链路层、物理层。 这里不得不说一下OSI的七层参考模型，这里讲的TCP/IP的四层参考模型和五层参考模型都是会与OSI的七层参考模型对应起来的。 OSI七层协议模型主要是：应用层、表示层、会话层、传输层、网络层、数据链路层、物理层。 他们的对应关系如表所示： OSI七层网络模型TCPIP四层概念模型TCPIP五层概念模型应用层应用层应用层表示层会话层传输层传输层传输层网络层网际层网络层数据链路层网络接口层数据链路层物理层物理层 理想化的交换机（网桥）实现实现数据链路层和物理层，而理想化的路由器则实现网络层、数据链路层和物理层","tags":[{"name":"TCP/IP","slug":"TCP-IP","permalink":"https://yaoyinglong.github.io/tags/TCP-IP/"}],"categories":[{"name":"协议族","slug":"协议族","permalink":"https://yaoyinglong.github.io/categories/协议族/"}]},{"title":"IDEA的快捷使用","date":"2017-11-23T16:00:00.000Z","path":"Blog/杂记/IDEA快捷的使用/","text":"刚开始学习Java时使用的是Eclipse和MyEclipse，但是自从使用了IDEA后感觉打开了新世界的大门，反正就是各种吊打。 随着深入的使用，对于快捷键的熟练使用对于开发效率的提高不是一点半点。 Ctrl + C 快速复制当前行Ctrl + D 复制当前行到下一行Ctrl + E 最近的文件Ctrl + G 定位行和列，很多时候通过行号找东西非常方便Ctrl + I 打开选择实现方法列表CTRL + J 自动代码，打开模板代码提示CTRL + K 版本管理提交代码CTRL + T 版本管理更新代码Ctrl + N 查找类Ctrl + O 打开选择重写方法列表CTRL + P 方法参数提示，当调用一个方法忘记参数该怎么填，不必打开具体的实现地方CTRL + Q 查看当前字段的文档详情Ctrl + R 当前文件替换特定内容Ctrl + W 扩展选择Ctrl + X 剪切当前行Ctrl + Z 撤销Ctrl + Y 移除整行代码Ctrl + F4 关闭活动的编辑标签Ctrl + F7 高亮显示，按F3可以选择Ctrl + F12 可以显示当前文件的结构Ctrl + Tab 打开Switcher界面，选择切换页面Ctrl + &#39;+/-&#39; 当前方法展开、折叠Ctrl + [/] 移动光标到块的初/末括号地方Ctrl + Backspace 按单词删除Ctrl + Insert 快速复制当前行 Ctrl + Alt + B 跳到具体的实现方法，查找抽象方法的具体实现很好用CTRL + ALT + I 自动缩进CTRL + ALT + L 格式化代码Ctrl + Alt + O 优化导入类和包Ctrl + Alt + T Live Templete模板提示，代码环绕Ctrl + Alt + V 提取变量Ctrl + Alt + 鼠标左键 直接打开实现类中的方法，而不是打开接口中的方法Ctrl + Alt + Left/Right 在访问历史中进行导航 Ctrl + Shift + A 搜索功能和操作Ctrl + Shift + E 最近修改的文件Ctrl + Shift + J 整合两行为一行Ctrl + Shift + U 大小写转化Ctrl + Shift + Z 取消撤销Ctrl + Shift + R 当前项目替换特定内容Ctrl + Shift + F 当前项目查找包含特定内容的文件Ctrl + Shift + N 查找文件Ctrl + Shift + V 访问历史粘贴板Ctrl + Shift + W 缩小扩展选择Ctrl + Shift + Up/Down 上下移动整块代码Ctrl + Shift + &#39;+/-&#39; 全部展开、折叠Ctrl + Shift + F7 高亮显示所有该选中文本，按Esc高亮消失。Ctrl + Shift + Del 删除环绕的标签Ctrl + Shift + [/] 选中从光标所在位置到它的父级区域Ctrl + Shift + Enter 完成表达式，例如：语句最后加上分号 双击Shift 在项目的所有目录查找 Shift + Enter 另起一行Shift + F6可以重命名你的类、方法、变量等等，而且这个重命名甚至可以选择替换掉注释中的内容Shift + Esc 把焦点移到编辑器上，而且隐藏当前（或最后活动的）工具窗口Shift + Click，可以关闭文件Shift + Insert 快速粘贴 Alt + 1 切换Project栏的打开和关闭Alt + 4 切换Run栏的打开和关闭Alt + 5 切换Debug栏的打开和关闭Alt + F3 逐个往下查找相同文本，并高亮显示Alt + F7 找到函数或者变量或者类的所有引用到的地方Alt + Insert 在类中使用自动生成构造器、getter/setter等方法,在项目目录上使用新建各种文件Alt + Left/Right 切换打开标签上的文件,切换代码视图Alt + Up/Down 在方法间快速移动定位Alt + Q 可以看到当前方法的声明Alt + Shift + Up/Down 上/下移一行代码Alt + 鼠标选取 可以直接方块区域选择（很有用）,列选取Alt + Enter 选择Inject language or reference后回车选择语言（例如，选择正则表达式，有测试正则表达式的能力）Alt + Home 打开快速导航，定位到指定文件 批操作Ctrl + F3 从光标开始查找下一个出现的地方，包括变量和字符串Alt + J 添加选择下一个出现的字符串或变量Ctrl + Alt + Shift + J 选择字符串或变量所有出现的地方Alt + Shift + J 反选字符串或变量 常规操作Ctrl + Tab 选择两个打开的标签或工具窗口Ctrl + Shift + A 查找功能Alt + Shift + F 将方法或某一行添加到收藏夹Ctrl + Shift + F12 切换最大编辑窗口 重构Alt + Delete 安全删除Shift + F6可以重命名你的类、方法、变量等等，而且这个重命名甚至可以选择替换掉注释中的内容Ctrl + F6 改变方法的参数Ctrl + Alt + N 内联Ctrl + Alt + M 抽取方法Ctrl + Alt + V 抽取局部变量Ctrl + Alt + F 抽取成员变量Ctrl + Alt + C 抽取常量Ctrl + Alt + P 抽取为当前方法参数 F12 把焦点从编辑器移到最近使用的工具窗口","tags":[{"name":"IDEA","slug":"IDEA","permalink":"https://yaoyinglong.github.io/tags/IDEA/"}],"categories":[{"name":"杂记","slug":"杂记","permalink":"https://yaoyinglong.github.io/categories/杂记/"}]},{"title":"Welcome YingLong's Blog","date":"2017-11-21T16:00:00.000Z","path":"Blog/index/","text":"前言首先需要说明的是，该博客系统使用的主题是Wikitten，这个主题是由一个很厉害的学弟写的。本来想自己搭建一个完全属于我自己的博客系统的，虽然会一些蹩脚的前端，真的要去做的话相信也能做出来，但是搭建这个很费时间和精力，由于现在工作了空余时间本来就少，而且我从事的是后台的开发工作，也比较喜欢做后台开发，所以不想本末倒置，再者这个主题我也比较喜欢，反正就是一大堆借口，最终使用了这个模板。 版面上之所以使用的是英文，不是为了装逼，恩~~，好吧，不仅仅是为了装逼。其实个人英语很烂，虽然在Nokia实习过半年，但还是改变不了英语烂的这个事实。虽然烂但是却一值想把这个东西学好，客观的讲对于编程来说这个东西真的很重要，很多有用的文档都是英文的，比如说Spring。我发现有很大一部分人英语很差的人，总是很害怕它。老实说我以前也害怕它，但是在Nokia的全英文环境中逐渐克服了。越畏惧就要越接触越差就要越去使用，这样才会有进步，所以说使用英文版面，仅仅是为了让自己尽量多的处于英文环境中，哪怕产生一丝丝潜移默化的影响那也是好的。 目的其实很早就有搭建一个博客系统的打算，先前也搭建过一个，但是觉得以前那个不怎么样，也没有怎么用了。最近看了一些书，但是总是很难融会贯通，仔细想了一下没有去对某个知识点进行深入得理解学习，或者说没有将书上的东西有效的串联起来，很零散。如果没有进行系统化的整理，你会发现很快这个东西在你的记忆力越来越模糊。 为了方便记录，为了方便将自己总结的东西管理起来，甚至说将自己的知识库管理起来。深有体会的一点就是，梳理前后那就不是一个量级的东西了，甚至更夸张的有可能给你的感觉那就不是一个东西。最重要的一点也是最主要的一个目的，就是为了督促自己去学习总结和提高，永远保持一个努力前行的心，坚定目标，尽可能的降低外界环境对自己的干扰。 虽奔放不羁，但也束缚自我，努力前行。","tags":[],"categories":[]}]}